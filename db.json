{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0},{"_id":"source/uploads/alipay-reward.jpg","path":"uploads/alipay-reward.jpg","modified":0,"renderable":0},{"_id":"source/uploads/avatar.jpeg","path":"uploads/avatar.jpeg","modified":0,"renderable":0},{"_id":"source/uploads/wechat-reward.jpg","path":"uploads/wechat-reward.jpg","modified":0,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1}],"Cache":[{"_id":"source/CNAME","hash":"3f32184e29e4454d1d273e852ad006485880a07f","modified":1506332390000},{"_id":"source/.DS_Store","hash":"acb00ac5e1bf689a994061da4f376c9f34d3e85f","modified":1506392691000},{"_id":"themes/next/.DS_Store","hash":"b4031ca706d0e344ab2ab686d4decf4474d9e602","modified":1504774657000},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1504618963000},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1504618963000},{"_id":"themes/next/.gitignore","hash":"32ea93f21d8693d5d8fa4eef1c51a21ad0670047","modified":1504618963000},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1504618963000},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1504618963000},{"_id":"themes/next/.javascript_ignore","hash":"8a224b381155f10e6eb132a4d815c5b52962a9d1","modified":1504618963000},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1504618963000},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1504618963000},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1504618963000},{"_id":"themes/next/.travis.yml","hash":"d60d4a5375fea23d53b2156b764a99b2e56fa660","modified":1504618963000},{"_id":"themes/next/README.cn.md","hash":"6d9177e7dad87e6129760e4b559bd3f7a15429d7","modified":1504618963000},{"_id":"themes/next/README.md","hash":"950ca6e9c0fa607d290a5b1fd883df44725b36b2","modified":1504618963000},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1504618963000},{"_id":"themes/next/bower.json","hash":"7d7938f9da896fe710aa0e9120140e528bf058df","modified":1504618963000},{"_id":"themes/next/_config.yml","hash":"a19e708b3851a731c9ae09a547da020bd7df97a6","modified":1506429507000},{"_id":"themes/next/package.json","hash":"193dad6f59a588908fac082cc46fe067dac1b84d","modified":1504618963000},{"_id":"source/_drafts/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1506392765000},{"_id":"source/_drafts/about-ofo.md","hash":"80337facfc99516082accdd117e9020584cad42d","modified":1506423043000},{"_id":"source/_posts/ARKit-Face.md","hash":"b3ae5eecf6dd71b3e8da0c033d7b3733a804104b","modified":1506341281000},{"_id":"source/_posts/ARKit-Add-3d-Content.md","hash":"f586b2e670de194be2f0ee3eaf27b47841e63454","modified":1506341279000},{"_id":"source/_posts/ARKit-Plane-Detector.md","hash":"338702ace0ecee8b29bb18e3c25907faa3918d9b","modified":1506341283000},{"_id":"source/_posts/ARKit-startup.md","hash":"36a081a1a3f010b0d54d97bd14ad7e1c1b7b92a7","modified":1506341285000},{"_id":"source/_posts/iOS-nfc.md","hash":"1375ea259c20ec0f1238c60e862670e7bf1bce33","modified":1506422642000},{"_id":"source/_posts/hello-world.md","hash":"4ccb240961ac2d1579058c0e17f90f43db44ba60","modified":1506341729000},{"_id":"source/_posts/iOS-bonjour.md","hash":"81f6ee0dcad482ffa485e95c0f913a470d3fbf32","modified":1506419804000},{"_id":"source/_posts/iOS-code-obfuscate.md","hash":"f4766c076164129649dd909cba91ae7a58233f4c","modified":1506419770000},{"_id":"source/_posts/iOS11-UI-adjust.md","hash":"ffdca0bf8c666f64d6f6cb731282b519b1f85405","modified":1506341299000},{"_id":"source/_posts/ollvm-in-iOS.md","hash":"c140500dc820781f3677ab318fe1a94b1006554d","modified":1506342119000},{"_id":"source/_posts/ollvm-with-StringObfuscate.md","hash":"0c8633acb29e242d193f76e8e8ecf5d9eb1e836a","modified":1506341315000},{"_id":"source/about/index.md","hash":"a8c215281e9c7efc92744adb74d2006c1333afcf","modified":1506071757000},{"_id":"source/categories/index.md","hash":"be4362deb3836c537d6158e308df48311cf741a4","modified":1506341684000},{"_id":"source/tags/index.md","hash":"f48685968c69fe32fbca1d0a26e8fa569a453131","modified":1506342126000},{"_id":"source/uploads/alipay-reward.jpg","hash":"c9359108d463395019b749d866e55076180bf161","modified":1504852377000},{"_id":"source/uploads/avatar.jpeg","hash":"e037a566ae5dfb2addca349a3c7ae82e6cda242f","modified":1504617508000},{"_id":"themes/next/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1504618963000},{"_id":"themes/next/.git/config","hash":"bf7d1df65cf34d0f25a7184a58c37a09f72e4be7","modified":1504618963000},{"_id":"themes/next/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1504618943000},{"_id":"themes/next/.git/packed-refs","hash":"df65a6b11e726128d093c69306bfcb033bd09c82","modified":1504618963000},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"3b5eafd32abb718e56ccf8d1cee0607ad8ce611d","modified":1504618963000},{"_id":"themes/next/.git/index","hash":"bde1aa4ae790488fd6c21b4a6df6ffc312243921","modified":1504666099000},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"213d0f6c9c7ed9b035d84486b540a57e24869909","modified":1504618963000},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"5d34ae00d5478526664969d0f1fd2cd5d5556e64","modified":1504618963000},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1504618963000},{"_id":"themes/next/languages/de.yml","hash":"057e7df11ddeb1c8c15a5d7c5ff29430d725ec6b","modified":1504618963000},{"_id":"themes/next/languages/default.yml","hash":"44ef3f26917f467459326c2c8be2f73e4d947f35","modified":1504618963000},{"_id":"themes/next/languages/en.yml","hash":"44ef3f26917f467459326c2c8be2f73e4d947f35","modified":1504618963000},{"_id":"themes/next/languages/fr-FR.yml","hash":"7e4eb7011b8feee641cfb11c6e73180b0ded1c0f","modified":1504618963000},{"_id":"themes/next/languages/id.yml","hash":"b5de1ea66dd9ef54cac9a1440eaa4e3f5fc011f5","modified":1504618963000},{"_id":"themes/next/languages/pt-BR.yml","hash":"b1694ae766ed90277bcc4daca4b1cfa19cdcb72b","modified":1504618963000},{"_id":"themes/next/languages/ja.yml","hash":"3c76e16fd19b262864475faa6854b718bc08c4d8","modified":1504618963000},{"_id":"themes/next/languages/ko.yml","hash":"ea5b46056e73ebcee121d5551627af35cbffc900","modified":1504618963000},{"_id":"themes/next/languages/pt.yml","hash":"44b61f2d085b827b507909a0b8f8ce31c6ef5d04","modified":1504618963000},{"_id":"themes/next/languages/ru.yml","hash":"98ec6f0b7183282e11cffc7ff586ceb82400dd75","modified":1504618963000},{"_id":"themes/next/languages/zh-hk.yml","hash":"a4dba8c94bdefd130391054eb3a9572cf0ab5b16","modified":1504618963000},{"_id":"themes/next/languages/zh-Hans.yml","hash":"b342544b715da19d982349017bd56c5aaca11f71","modified":1504618963000},{"_id":"themes/next/languages/zh-tw.yml","hash":"6b3040a82cbe501457c09c0fdb038d2e61f2be9a","modified":1504618963000},{"_id":"themes/next/layout/.DS_Store","hash":"47a5cfe872daad16675c7021ed34c1a09c70555d","modified":1504774738000},{"_id":"themes/next/layout/_layout.swig","hash":"ada7ffc71cf05e7236a19e0648bce6d6d6cbc7dc","modified":1504618963000},{"_id":"themes/next/layout/archive.swig","hash":"f0a8225feafd971419837cdb4bcfec98a4a59b2f","modified":1504618963000},{"_id":"themes/next/layout/category.swig","hash":"4472255f4a3e3dd6d79201523a9526dcabdfbf18","modified":1504618963000},{"_id":"themes/next/layout/index.swig","hash":"783611349c941848a0e26ee2f1dc44dd14879bd1","modified":1504618963000},{"_id":"themes/next/layout/page.swig","hash":"37c874cd720acf0eda8d26e063278f2b6ae8d3a6","modified":1504618963000},{"_id":"themes/next/layout/post.swig","hash":"2d5f8d7f0a96b611e2d5a5e4d111fc17726a990f","modified":1504618963000},{"_id":"themes/next/scripts/merge-configs.js","hash":"13c8b3a2d9fce06c2488820d9248d190c8100e0a","modified":1504618963000},{"_id":"themes/next/layout/schedule.swig","hash":"d86f8de4e118f8c4d778b285c140474084a271db","modified":1504618963000},{"_id":"themes/next/layout/tag.swig","hash":"7e0a7d7d832883eddb1297483ad22c184e4368de","modified":1504618963000},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1504618963000},{"_id":"themes/next/scripts/.DS_Store","hash":"2ecca5dd0b7260968763bb4ded8695e5748d3d0e","modified":1504774649000},{"_id":"themes/next/source/.DS_Store","hash":"ae68ad86174e27e648d36b9541cb40a15a403687","modified":1504774691000},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1504618963000},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1504618963000},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1504618963000},{"_id":"source/uploads/wechat-reward.jpg","hash":"8e38ba5c0c981e28a9f4b204b92e4c1b14c90bb7","modified":1504766941000},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1504618963000},{"_id":"themes/next/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1504618943000},{"_id":"themes/next/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1504618943000},{"_id":"themes/next/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1504618943000},{"_id":"themes/next/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1504618943000},{"_id":"themes/next/.git/hooks/pre-rebase.sample","hash":"5885a56ab4fca8075a05a562d005e922cde9853b","modified":1504618943000},{"_id":"themes/next/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1504618943000},{"_id":"themes/next/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1504618943000},{"_id":"themes/next/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1504618943000},{"_id":"themes/next/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1504618943000},{"_id":"themes/next/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1504618943000},{"_id":"themes/next/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1504618943000},{"_id":"themes/next/.git/logs/HEAD","hash":"240cee7b61e34ca7dc7885c453e5b34982113709","modified":1504618963000},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1504618963000},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1504618963000},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1504618963000},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"53d4f83b2b7fb4387dfc9fe81519abd56fbce4ae","modified":1504618963000},{"_id":"themes/next/layout/_macro/reward.swig","hash":"56e8d8556cf474c56ae1bef9cb7bbd26554adb07","modified":1504618963000},{"_id":"themes/next/layout/_macro/post.swig","hash":"767e1d5503ecce85f577c8fb673a3503b65484ce","modified":1504618963000},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"3e01900762d889a04379abba37b419972e366698","modified":1504618963000},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"39852700e4084ecccffa6d4669168e5cc0514c9e","modified":1504618963000},{"_id":"themes/next/layout/_partials/comments.swig","hash":"010ef8c42d2e1a95abc60caf757293ca8eb4a68b","modified":1504618963000},{"_id":"themes/next/layout/_partials/footer.swig","hash":"fb02c81273d5897ebb98b50f4c10f7edc34f9240","modified":1504618963000},{"_id":"themes/next/layout/_partials/header.swig","hash":"ed042be6252848058c90109236ec988e392d91d4","modified":1504618963000},{"_id":"themes/next/layout/_partials/head.swig","hash":"2cbeae795c9929ec1966b8a1fb9c058a0b547fa9","modified":1504618963000},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1504618963000},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1504618963000},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1504618963000},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1504618963000},{"_id":"themes/next/layout/_scripts/.DS_Store","hash":"d228539aa9818b24ca53b6467d3e848d273868b8","modified":1504774744000},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1504618963000},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"9baf90f7c40b3b10f288e9268c3191e895890cea","modified":1504618963000},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1504618963000},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1504618963000},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1504618963000},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1504618963000},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1504618963000},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1504618963000},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1504618963000},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1504618963000},{"_id":"themes/next/scripts/tags/button.js","hash":"62e6dbeb53d07627a048132c79630b45d9a8f2cc","modified":1504618963000},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1504618963000},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1504618963000},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1504618963000},{"_id":"themes/next/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1504618963000},{"_id":"themes/next/scripts/tags/tabs.js","hash":"5786545d51c38e8ca38d1bfc7dd9e946fc70a316","modified":1504618963000},{"_id":"themes/next/scripts/tags/label.js","hash":"2f8f41a7316372f0d1ed6b51190dc4acd3e16fff","modified":1504618963000},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1504618963000},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1504618963000},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1504618963000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1504618963000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1504618963000},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1504618963000},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1504618963000},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1504618963000},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1504618963000},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1504618963000},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1504618963000},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1504618963000},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1504618963000},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1504618963000},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1504618963000},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1504618963000},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1504618963000},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1504618963000},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1504618963000},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1504618963000},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1504618963000},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1504618963000},{"_id":"themes/next/.git/refs/heads/master","hash":"f51e1af76aa6bcfedf1b029c4cc5d809da80d926","modified":1504618963000},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1504618963000},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1504618963000},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1504618963000},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1504618963000},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1504618963000},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1504618963000},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1504618963000},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"048fd5e98149469f8c28c21ba3561a7a67952c9b","modified":1504618963000},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1504618963000},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1504618963000},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1504618963000},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1504618963000},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"98df9d72e37dd071e882f2d5623c9d817815b139","modified":1504618963000},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1504618963000},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1504618963000},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1504618963000},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1504618963000},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1504618963000},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1504618963000},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"5e9bb24c750b49513d9a65799e832f07410002ac","modified":1504618963000},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"fc65b9c98a0a8ab43a5e7aabff6c5f03838e09c8","modified":1504618963000},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1504618963000},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1504618963000},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1504618963000},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1504618963000},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1504618963000},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1504618963000},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"576e716893153a855eaf6d136fad7cb6d4065e09","modified":1504618963000},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1504618963000},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"9f4ed36c73e890909b8ebbe601fb60e13d048288","modified":1504618963000},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"8a2e393d2e49f7bf560766d8a07cd461bf3fce4f","modified":1504618963000},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1504618963000},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"8b6650f77fe0a824c8075b2659e0403e0c78a705","modified":1504618963000},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1504618963000},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"385c066af96bee30be2459dbec8aae1f15d382f5","modified":1504618963000},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1504618963000},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1504618963000},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1504618963000},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"9ab65361ba0a12a986edd103e56492644c2db0b8","modified":1504618963000},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"82f9055955920ed88a2ab6a20ab02169abb2c634","modified":1504618963000},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"6359c84aaa02c90be60b22abe638b737ddd69c9c","modified":1504618963000},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"c8d35a6b9e3bff6d8fdb66de853065af9d37562d","modified":1504618963000},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"cfee25d790e4f9b7d57f0dc7e2ea9c1649f08f11","modified":1504618963000},{"_id":"themes/next/source/css/_variables/base.styl","hash":"d477196c5699c8261b08e993a77ef67054d86166","modified":1504618963000},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1504618963000},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1504618963000},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1504618963000},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1504618963000},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1504618963000},{"_id":"themes/next/source/js/src/motion.js","hash":"da146caf488078a634d961debf2a71ce4106018c","modified":1504618963000},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1504618963000},{"_id":"themes/next/source/js/src/post-details.js","hash":"0693695a9512641daff63d99da772625a058ab18","modified":1504618963000},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1504618963000},{"_id":"themes/next/source/js/src/utils.js","hash":"2917c39c75b14b6dab7e1c46ab4d87b4df9fcd5d","modified":1504618963000},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1504618963000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1504618963000},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"7fd2f3e2773555392ef40df40cae3bedb884f17a","modified":1504618963000},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1504618963000},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1504618963000},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1504618963000},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1504618963000},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1504618963000},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1504618963000},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1504618963000},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1504618963000},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1504618963000},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1504618963000},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1504618963000},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1504618963000},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1504618963000},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1504618963000},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1504618963000},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1504618963000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1504618963000},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1504618963000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1504618963000},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1504618963000},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1504618963000},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1504618963000},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1504618963000},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1504618963000},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1504618963000},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1504618963000},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1504618963000},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1504618963000},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1504618963000},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1504618963000},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1504618963000},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1504618963000},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1504618963000},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1504618963000},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1504618963000},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1504618963000},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1504618963000},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1504618963000},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1504618963000},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1504618963000},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1504618963000},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1504618963000},{"_id":"themes/next/.git/logs/refs/heads/master","hash":"240cee7b61e34ca7dc7885c453e5b34982113709","modified":1504618963000},{"_id":"themes/next/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1504618963000},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1504618963000},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"d026c8489f66ab6c12ad04bd37f1d5b6f2f3f0d1","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"0dfb4b3ba3180d7285e66f270e1d3fa0f132c3d2","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"711c8830886619d4f4a0598b0cde5499dce50c62","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1504618963000},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"f7c44b0ee46cf2cf82a4c9455ba8d8b55299976f","modified":1504618963000},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"86b6fd7f1b1be3ae98f8af6b23a6b1299c670ce9","modified":1504618963000},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1504618963000},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1504618963000},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1504618963000},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1504618963000},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"f2030fa436c47791d1a42358cc0ef6f9809f212c","modified":1504618963000},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1504618963000},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"bc8c388553bbcf95897459a466ba35bffd5ec5f0","modified":1504618963000},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1504618963000},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1504618963000},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1504618963000},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"fda14bc35be2e1b332809b55b3d07155a833dbf4","modified":1504618963000},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1504618963000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1504618963000},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1504618963000},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1504618963000},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"82bbaa6322764779a1ac2e2c8390ce901c7972e2","modified":1504618963000},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1504618963000},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1504618963000},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1504618963000},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"0af5a9322156c4c21d3c7d38f5ee48de5286f523","modified":1504618963000},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1504618963000},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1504618963000},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1504618963000},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"264a52c0a7877381f9a6a87d495757a0ba7e29d6","modified":1504618963000},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"79da92119bc246fe05d1626ac98426a83ec90a94","modified":1504618963000},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1504618963000},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1504618963000},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1504618963000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1504618963000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1504618963000},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1504618963000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1504618963000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1504618963000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1504618963000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1504618963000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1504618963000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1504618963000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1504618963000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1504618963000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1504618963000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1504618963000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1504618963000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1504618963000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1504618963000},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1504618963000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1504618963000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1504618963000},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1504618963000},{"_id":"themes/next/.git/logs/refs/remotes/origin/HEAD","hash":"240cee7b61e34ca7dc7885c453e5b34982113709","modified":1504618963000},{"_id":"themes/next/.git/objects/pack/pack-544d4aa2e5dbfdc3d323d39698a94bd61ba35e0d.idx","hash":"451d898b91b2a431daaac0cafb38cacf2dd95a41","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"7905a7f625702b45645d8be1268cb8af3f698c70","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"740d37f428b8f4574a76fc95cc25e50e0565f45e","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"f5aa2ba3bfffc15475e7e72a55b5c9d18609fdf5","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"beccb53dcd658136fb91a0c5678dea8f37d6e0b6","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"88c7d75646b66b168213190ee4cd874609afd5e3","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"aea21141015ca8c409d8b33e3e34ec505f464e93","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"36332c8a91f089f545f3c3e8ea90d08aa4d6e60c","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"963105a531403d7aad6d9e5e23e3bfabb8ec065a","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"08a500b2984f109b751f3697ca33172d1340591a","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"67c357ddc16b31e7dfd8f956a77f984662c06fc2","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"0a6c0efffdf18bddbc1d1238feaed282b09cd0fe","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"89dd4f8b1f1cce3ad46cf2256038472712387d02","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"77c92a449ce84d558d26d052681f2e0dd77c70c9","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"57d2c8a060f5e4e1a0aef9aae11a0016cf7ac5ba","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"b8969e1654eec89a0fd10d88b337fee9cb03cd44","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"45df0cf4c97b47e05573bcd41028ee50f3fdf432","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"ead0d0f2321dc71505788c7f689f92257cf14947","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"aeff0e6e23725e8baea27c890ccbbf466024f767","modified":1504618963000},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1504618963000},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1504618963000},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1504618963000},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1504618963000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1504618963000},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1504618963000},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1504618963000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1504618963000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1504618963000},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1504618963000},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1504618963000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1504618963000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1504618963000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1504618963000},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1504618963000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1504618963000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1504618963000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1504618963000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1504618963000},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1504618963000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1504618963000},{"_id":"themes/next/.git/objects/pack/pack-544d4aa2e5dbfdc3d323d39698a94bd61ba35e0d.pack","hash":"54d7037a710cbefa495be1232fa2f076146d404c","modified":1504618963000},{"_id":"public/about/index.html","hash":"17bf0f932f12769beb03ad4524d277785c8bf026","modified":1506429519892},{"_id":"public/categories/index.html","hash":"ce576c458e4f60cb60d80f45ea82244f8369e5b5","modified":1506429519892},{"_id":"public/tags/index.html","hash":"b1dea45d08c7e9a07101c2cc976d80d449c7f1cb","modified":1506429519892},{"_id":"public/tags/ARKit/index.html","hash":"5ac7e61ef2a876d17c29815e87b32a310c3dfc05","modified":1506429519893},{"_id":"public/tags/iOS/index.html","hash":"9919284fab720ec5ad49ec08ebc66bf8a4907bde","modified":1506429519893},{"_id":"public/tags/Core-NFC/index.html","hash":"747a8b12031c85e12196722a7a21720afea26b72","modified":1506429519893},{"_id":"public/tags/blog/index.html","hash":"338694b6a4662362b59b115682ebad1b114655e7","modified":1506429519893},{"_id":"public/tags/Bonjour/index.html","hash":"61aaecd742b48d86c445323c909eae3466b9ef0c","modified":1506429519893},{"_id":"public/tags/安全/index.html","hash":"c0e6fb7611628181ba74b14820e16c1960c3643a","modified":1506429519893},{"_id":"public/tags/iOS-11/index.html","hash":"935a0663d024e741c2a44d8de6f1277075d48583","modified":1506429519893},{"_id":"public/archives/page/2/index.html","hash":"f6ed08e4fa968c9a145f4afcea2b44957b267f0a","modified":1506429519892},{"_id":"public/archives/2017/page/2/index.html","hash":"8b4eb361dc9891f8fca78fae0024705336b50695","modified":1506429519892},{"_id":"public/archives/2017/03/index.html","hash":"c0fc89ca3deefe483b5f30dd83e1634ba4ef8d67","modified":1506429519892},{"_id":"public/archives/2017/04/index.html","hash":"036783bc708d8ab06d9c576b2648f478f914e97e","modified":1506429519892},{"_id":"public/archives/2017/06/index.html","hash":"8e46eafb028689b6b356a9c17463f04cfbac6799","modified":1506429519892},{"_id":"public/archives/2017/07/index.html","hash":"aa4439ac6b171ca204a9c5e8083d54795c545c22","modified":1506429519892},{"_id":"public/archives/2017/08/index.html","hash":"333e84b6b0131f4fe0f9f8963767c103722dd846","modified":1506429519892},{"_id":"public/archives/2017/09/index.html","hash":"26ef5df9ebe664c69d8719651903a6316c562478","modified":1506429519893},{"_id":"public/categories/tools/index.html","hash":"1e06a7d55b49fda5630b1e7034c638d63c2db0ef","modified":1506429519893},{"_id":"public/categories/LLVM/index.html","hash":"750425c916825b71eca4fd7ec6624d0f88fe08c6","modified":1506429519893},{"_id":"public/2017/09/18/ollvm-with-StringObfuscate/index.html","hash":"7e39b8dc39d604517a157b57947ee9affc81dadf","modified":1506429519893},{"_id":"public/2017/09/14/iOS11-UI-adjust/index.html","hash":"f1cb104ef44ebe272eafe366ccc05b7c3b157de9","modified":1506429519894},{"_id":"public/2017/09/13/ARKit-Face/index.html","hash":"5078eb35814016b5e16dcd7c41f9a4a8521d9ab7","modified":1506429519894},{"_id":"public/2017/09/12/ARKit-Plane-Detector/index.html","hash":"d740609c88ee46a3089b6f00b8f6bd98e8a9b055","modified":1506429519894},{"_id":"public/2017/09/08/ARKit-Add-3d-Content/index.html","hash":"5dc50bd3323b9cf177f69755d8a566c868ab541e","modified":1506429519895},{"_id":"public/2017/09/07/ollvm-in-iOS/index.html","hash":"cce2da78d239d6e8f92f6107320c21a680ae5cbd","modified":1506429519897},{"_id":"public/2017/08/22/iOS-nfc/index.html","hash":"de71fe55c1c58c026c0666aebacf0eaf6a51ba91","modified":1506429519897},{"_id":"public/2017/07/21/iOS-bonjour/index.html","hash":"a274ddbe77b98af7d2870970442b4c7803cf6773","modified":1506429519897},{"_id":"public/2017/06/28/ARKit-startup/index.html","hash":"f4dcc928a56d8c2957de6fd88f2bcb37b2923897","modified":1506429519897},{"_id":"public/2017/04/01/iOS-code-obfuscate/index.html","hash":"8903612d3a7d5cb06c8a52c12d161eda6a3aa90d","modified":1506429519897},{"_id":"public/2017/03/28/hello-world/index.html","hash":"7595053fd8dc251863095da51690e3a90ea73ff6","modified":1506429519897},{"_id":"public/archives/index.html","hash":"9bb03a08a595a4690a0719e471c9fd86d87f8ed5","modified":1506429519897},{"_id":"public/archives/2017/index.html","hash":"81dc2f536607938676c972f89fafe2b95c2b1ceb","modified":1506429519898},{"_id":"public/categories/iOS/index.html","hash":"60cafc3c4c1457a06df13834827d01bb55f65163","modified":1506429519898},{"_id":"public/index.html","hash":"0350357c6fabb295cfaa1b25ef2555947d7bddfc","modified":1506429519898},{"_id":"public/page/2/index.html","hash":"849c0139a15e578c9dbd5c81405ca7bede168c33","modified":1506429519898},{"_id":"public/CNAME","hash":"3f32184e29e4454d1d273e852ad006485880a07f","modified":1506429355818},{"_id":"public/uploads/alipay-reward.jpg","hash":"c9359108d463395019b749d866e55076180bf161","modified":1506429355818},{"_id":"public/uploads/avatar.jpeg","hash":"e037a566ae5dfb2addca349a3c7ae82e6cda242f","modified":1506429355818},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1506429355818},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1506429355818},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1506429355818},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1506429355818},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1506429355818},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1506429355818},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1506429355818},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1506429355818},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1506429355818},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1506429355818},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1506429355818},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1506429355818},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1506429355818},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1506429355819},{"_id":"public/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1506429355819},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1506429355819},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1506429355819},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1506429355819},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1506429355819},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1506429355819},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1506429355819},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1506429355819},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1506429355819},{"_id":"public/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1506429355819},{"_id":"public/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1506429355819},{"_id":"public/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1506429355819},{"_id":"public/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1506429355820},{"_id":"public/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1506429355820},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1506429355820},{"_id":"public/uploads/wechat-reward.jpg","hash":"8e38ba5c0c981e28a9f4b204b92e4c1b14c90bb7","modified":1506429356556},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1506429356557},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1506429356577},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1506429356584},{"_id":"public/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1506429356584},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1506429356585},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1506429356585},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1506429356585},{"_id":"public/js/src/motion.js","hash":"da146caf488078a634d961debf2a71ce4106018c","modified":1506429356585},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1506429356585},{"_id":"public/js/src/post-details.js","hash":"0693695a9512641daff63d99da772625a058ab18","modified":1506429356585},{"_id":"public/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1506429356585},{"_id":"public/js/src/utils.js","hash":"2917c39c75b14b6dab7e1c46ab4d87b4df9fcd5d","modified":1506429356585},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1506429356585},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"7fd2f3e2773555392ef40df40cae3bedb884f17a","modified":1506429356585},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1506429356585},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1506429356585},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1506429356585},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1506429356585},{"_id":"public/lib/fastclick/README.html","hash":"da3c74d484c73cc7df565e8abbfa4d6a5a18d4da","modified":1506429356585},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"a6358170d346af13b1452ac157b60505bec7015c","modified":1506429356585},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1506429356585},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1506429356585},{"_id":"public/lib/jquery_lazyload/README.html","hash":"bde24335f6bc09d8801c0dcd7274f71b466552bd","modified":1506429356585},{"_id":"public/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1506429356585},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1506429356586},{"_id":"public/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1506429356586},{"_id":"public/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1506429356586},{"_id":"public/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1506429356586},{"_id":"public/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1506429356586},{"_id":"public/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1506429356586},{"_id":"public/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1506429356586},{"_id":"public/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1506429356586},{"_id":"public/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1506429356586},{"_id":"public/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1506429356586},{"_id":"public/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1506429356586},{"_id":"public/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1506429356586},{"_id":"public/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1506429356586},{"_id":"public/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1506429356586},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1506429356586},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1506429356586},{"_id":"public/js/src/schemes/pisces.js","hash":"79da92119bc246fe05d1626ac98426a83ec90a94","modified":1506429356586},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1506429356586},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1506429356586},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1506429356586},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1506429356586},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1506429356586},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1506429356586},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1506429356586},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1506429356586},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1506429356586},{"_id":"public/css/main.css","hash":"e13bedd742e96ef7003e007844e9ce62f04fdb20","modified":1506429356587},{"_id":"public/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1506429356587},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1506429356587},{"_id":"public/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1506429356587},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1506429356587},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1506429356587},{"_id":"public/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1506429356587},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1506429356587},{"_id":"public/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1506429356587},{"_id":"public/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1506429356587},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1506429356587},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1506429356587},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1506429356587},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1506429356588},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1506429356589},{"_id":"public/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1506429356589},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1506429356589},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1506429356589},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1506429356589},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1506429356590},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1506429356591},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1506429356591},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1506429356605}],"Category":[{"name":"iOS","_id":"cj81l545g0006wluvqm55tnr8"},{"name":"tools","_id":"cj81l545z000pwluvj8c7zemo"},{"name":"LLVM","_id":"cj81l5468000xwluvl48hhahh"}],"Data":[],"Page":[{"title":"about","date":"2017-09-22T07:58:01.000Z","_content":"","source":"about/index.md","raw":"---\ntitle: about\ndate: 2017-09-22 15:58:01\n---\n","updated":"2017-09-22T09:15:57.000Z","path":"about/index.html","comments":1,"layout":"page","_id":"cj81l54570001wluvnhpogedq","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"categories","date":"2017-09-25T12:12:02.000Z","type":"categories","comments":0,"_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2017-09-25 20:12:02\ntype: \"categories\"\ncomments: false\n---\n","updated":"2017-09-25T12:14:44.000Z","path":"categories/index.html","layout":"page","_id":"cj81l545b0003wluvu4tn6moc","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"tags","date":"2017-09-07T06:38:45.000Z","type":"tags","comments":0,"_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2017-09-07 14:38:45\ntype: \"tags\"\ncomments: false\n---\n","updated":"2017-09-25T12:22:06.000Z","path":"tags/index.html","layout":"page","_id":"cj81l545e0005wluvrpo6nkt1","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"关于摩拜、ofo的一些思考","date":"2017-09-26T10:50:12.000Z","_content":"","source":"_drafts/about-ofo.md","raw":"---\ntitle: 关于摩拜、ofo的一些思考  \ndate: 2017-09-26 18:50:12\ntags:\n---\n","slug":"about-ofo","published":0,"updated":"2017-09-26T10:50:43.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj81l54520000wluvgumjfv2f","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"ARKit-基于Face的AR体验","date":"2017-09-13T03:58:19.000Z","_content":"\nApple昨晚发布了强大但是死贵无比的iPhoneX，惊呆了我们。然后只能默默去刷了下API，发现ARKit新添了基于Face的API。\n之前的版本中前置摄像头是不支持AKKit模块的，幸而新发布的版本中添加了对Face识别的支持，然而新的API需要原前置深感摄像头(TrueDepth Camera)的支持，所以看来还得入手一台iPhone X呐。\n\n![iPhoneX](http://ojca2gwha.bkt.clouddn.com/ARKit-iPhoneX.jpg)  \n\n#### 新增API\n首先新增了ARFaceTrackingConfiguration，以用于追踪用户脸部的运动和表情，并在界面中渲染虚拟内容。此外你还可以设置lightEstimationEnabled为true，来启用脸部扫描并提供预估的定向/环境光。\n\n其次还新增了ARFaceAnchor，这两个新API与之前的ARWorldTrackingConfiguration和ARPlaneAnchor类似，只是基于平面的检测改为了基于Face的检测，恶趣味下Apple会不会继续扩展他的检测API。。。当使用ARFaceTrackingConfiguration时，ARSession会检测用户面部并且用ARFaceAnchor保存面部信息，包括位置、方向、拓扑结构以及表情特征点。\n\nARFaceAnchor的transform属性描述了面部在世界坐标系中的所在位置和方向，该世界坐标系可以在ARSessionConfiguration的wordlAlignment中设置。可以使用该transform在ARScene检测到的面部上添加虚拟物体。坐标系如下图所示：\n\n![ARKit Face coordinate](http://ojca2gwha.bkt.clouddn.com/ARKit-face-Coordinate.png)\n\n该坐标系为右手坐标系，x轴只想观察者的右边(即face自己的左边)，y轴指向上边(与face绑定)，z轴指向了观察者。\n\nARFaceAnchor的blendShapes属性提供了当前面部表情的高级数据，通过一系列表示面部特征的系数来描述面部表情。你可以使用这些系数跟随用户的面部表情来做2D/3D动画。\n\n<!--more-->\n#### 开始面部跟踪\n\n和ARKit的其他用法一样，面部追踪需要ARSessionConfiguration并运行一个ARSession来渲染相机屏幕，这部分可以参考[之前分享的文章](httpbai.ducom)，流程一致，只是这部分需要使用到新加的API。\n如前面所说，面部检测只支持配置了原前置深感摄像头(TrueDepth Camera)的iPhone，所以首先需要判断当前设备是否支持ARFaceTrackingConfiguration。\n\n```    \n    // 如果设备支持的判断通过 然后配置Session Configuration\n    guard ARFaceTrackingConfiguration.isSupported else { return }\n    let configuration = ARFaceTrackingConfiguration()\n    configuration.isLightEstimationEnabled = true\n    session.run(configuration, options: [.resetTracking, .removeExistingAnchors])\n```\n\n#### 跟踪脸部位置和方向  \n当面部跟踪启用后，ARKit会自动的添加ARFaceAnchor到ARSession中，包括其位置和方向。  \n\n> 注意ARKit目前只能追踪单个用户的面部，如果多个用户同时出现在镜头中，则取最大或者最清晰的可识别面部\n\n你可以在代理方法`renderer:didAddNode:forAnchor:`(ARSCNViewDelegate协议)中给一个face锚点添加相应3D内容。他会跟随用户的面部动作做相应的位置和方向调整。  \n\n```\nfunc renderer(_ renderer: SCNSceneRenderer, didAdd node: SCNNode, for anchor: ARAnchor) {\n    let device = sceneView.device!\n    let maskGeometry = ARSCNFaceGeometry(device: device)!\n    let content = SCNNode(geometry:maskGeometry)\n    node.addChildNode(content)\n}\n```\n\n##### 使用Face Geometry来模拟用户面部\n\nARKit提供了粗粒度的3D网状几何体，来匹配用户的面部大小、形态、拓扑结构以及当前面部表情，当然ARKit还提供了ARSCNFaceGeometry类来快捷的初始化该网格。你可以在用户的皮肤上通过给网状模型添加材质来绘制虚拟的刺青或者面具等。\n\n```\nlet device = sceneView.device!\nlet maskGeometry = ARSCNFaceGeometry(device: device)!\n```\n\n为了让屏幕中面部模型匹配用户的脸部，甚至跟随用户的眨眼、说话或者更多的表情动作，需要在代理方法中更新该面部模型的数据。\n```\nfunc renderer(_ renderer: SCNSceneRenderer, didUpdate node: SCNNode, for anchor: ARAnchor) {\n    guard let faceAnchor = anchor as? ARFaceAnchor else { return }\n\n    let faceGeometry = content.geometry as! ARSCNFaceGeometry\n    faceGeometry.update(from: anchor.geometry)\n}\n\n```\n\n#####  在面部呈现3D内容\n\nARKit提供的面部网格的另一个用途是在场景中创建遮挡几何体。遮挡几何体是不会呈现任何可见内容（允许相机图像显示）的3D模型，但会阻碍相机对场景中其他虚拟内容的视图。这种技术创造出真实面对与虚拟对象交互的错觉，即使脸部是2D摄像机图像，虚拟内容是渲染的3D对象。例如，如果您将遮挡几何图形和虚拟眼镜放置在用户的脸部上，则脸部可能会眼镜框架遮挡。\n要创建面部的遮挡几何，首先创建一个ARSCNFaceGeometry对象，如前面的例子所示。但是，不要使用可见的外观来配置该对象的SceneKit材质，而是在渲染期间将材质设置为渲染深度而不是颜色：\n\n```\n    let geometry = SCNGeometry()\n    geometry.firstMaterial!.colorBufferWriteMask = []\n    occlusionNode = SCNNode(geometry: geometry)\n    occlusionNode.renderingOrder = -1\n```\n\n##### 让你的形象动起来  \n要获取当前用户的面部表情，需要在代理方法renderer:didUpdateNode:forAnchor:中从ARFaceAnchor的blendShapes中读取数据 。\n\n```\nfunc renderer(_ renderer: SCNSceneRenderer, didUpdate node: SCNNode, for anchor: ARAnchor) {\n    blendShapes = faceAnchor.blendShapes\n}\n```\n然后，查看该字典中的键值对以计算模型的动画参数。该字典中有52个独特的ARBlendShapeLocation系数。你可以使用尽可能少的或很多的必要条件来创建想要的艺术效果。在此示例中，RobotHead类执行此计算，映射ARBlendShapeLocationEyeBlinkLeft和ARBlendShapeLocationEyeBlinkRight参数到机器人眼睛的scale参数，用ARBlendShapeLocationJawOpen参数以计算机器人上颌所在的位置。\n```\nvar blendShapes: [ARFaceAnchor.BlendShapeLocation: Any] = [:] {\n    didSet {\n        guard let eyeBlinkLeft = blendShapes[.eyeBlinkLeft] as? Float,\n            let eyeBlinkRight = blendShapes[.eyeBlinkRight] as? Float,\n            let jawOpen = blendShapes[.jawOpen] as? Float\n            else { return }\n        eyeLeftNode.scale.z = 1 - eyeBlinkLeft\n        eyeRightNode.scale.z = 1 - eyeBlinkRight\n        jawNode.position.y = originalJawY - jawHeight * jawOpen\n    }\n}\n```\n\n先简单介绍到这儿，真正要看到效果还得公司的土豪们入手iPhone X之后啦，不过基本用法很简单，维持了ARKit易用的特性。\n\n![致敬Jobs](http://ojca2gwha.bkt.clouddn.com/ARKit-Jobs.jpg)\n\n###### 参考文档\n1. https://developer.apple.com/documentation/arkit/arfacetrackingconfiguration?language=objc\n2. https://developer.apple.com/documentation/arkit/creating_face_based_ar_experiences?language=objc\n","source":"_posts/ARKit-Face.md","raw":"---\ntitle: ARKit-基于Face的AR体验\ndate: 2017-09-13 11:58:19\ntags:\n  ARKit\ncategories: iOS\n---\n\nApple昨晚发布了强大但是死贵无比的iPhoneX，惊呆了我们。然后只能默默去刷了下API，发现ARKit新添了基于Face的API。\n之前的版本中前置摄像头是不支持AKKit模块的，幸而新发布的版本中添加了对Face识别的支持，然而新的API需要原前置深感摄像头(TrueDepth Camera)的支持，所以看来还得入手一台iPhone X呐。\n\n![iPhoneX](http://ojca2gwha.bkt.clouddn.com/ARKit-iPhoneX.jpg)  \n\n#### 新增API\n首先新增了ARFaceTrackingConfiguration，以用于追踪用户脸部的运动和表情，并在界面中渲染虚拟内容。此外你还可以设置lightEstimationEnabled为true，来启用脸部扫描并提供预估的定向/环境光。\n\n其次还新增了ARFaceAnchor，这两个新API与之前的ARWorldTrackingConfiguration和ARPlaneAnchor类似，只是基于平面的检测改为了基于Face的检测，恶趣味下Apple会不会继续扩展他的检测API。。。当使用ARFaceTrackingConfiguration时，ARSession会检测用户面部并且用ARFaceAnchor保存面部信息，包括位置、方向、拓扑结构以及表情特征点。\n\nARFaceAnchor的transform属性描述了面部在世界坐标系中的所在位置和方向，该世界坐标系可以在ARSessionConfiguration的wordlAlignment中设置。可以使用该transform在ARScene检测到的面部上添加虚拟物体。坐标系如下图所示：\n\n![ARKit Face coordinate](http://ojca2gwha.bkt.clouddn.com/ARKit-face-Coordinate.png)\n\n该坐标系为右手坐标系，x轴只想观察者的右边(即face自己的左边)，y轴指向上边(与face绑定)，z轴指向了观察者。\n\nARFaceAnchor的blendShapes属性提供了当前面部表情的高级数据，通过一系列表示面部特征的系数来描述面部表情。你可以使用这些系数跟随用户的面部表情来做2D/3D动画。\n\n<!--more-->\n#### 开始面部跟踪\n\n和ARKit的其他用法一样，面部追踪需要ARSessionConfiguration并运行一个ARSession来渲染相机屏幕，这部分可以参考[之前分享的文章](httpbai.ducom)，流程一致，只是这部分需要使用到新加的API。\n如前面所说，面部检测只支持配置了原前置深感摄像头(TrueDepth Camera)的iPhone，所以首先需要判断当前设备是否支持ARFaceTrackingConfiguration。\n\n```    \n    // 如果设备支持的判断通过 然后配置Session Configuration\n    guard ARFaceTrackingConfiguration.isSupported else { return }\n    let configuration = ARFaceTrackingConfiguration()\n    configuration.isLightEstimationEnabled = true\n    session.run(configuration, options: [.resetTracking, .removeExistingAnchors])\n```\n\n#### 跟踪脸部位置和方向  \n当面部跟踪启用后，ARKit会自动的添加ARFaceAnchor到ARSession中，包括其位置和方向。  \n\n> 注意ARKit目前只能追踪单个用户的面部，如果多个用户同时出现在镜头中，则取最大或者最清晰的可识别面部\n\n你可以在代理方法`renderer:didAddNode:forAnchor:`(ARSCNViewDelegate协议)中给一个face锚点添加相应3D内容。他会跟随用户的面部动作做相应的位置和方向调整。  \n\n```\nfunc renderer(_ renderer: SCNSceneRenderer, didAdd node: SCNNode, for anchor: ARAnchor) {\n    let device = sceneView.device!\n    let maskGeometry = ARSCNFaceGeometry(device: device)!\n    let content = SCNNode(geometry:maskGeometry)\n    node.addChildNode(content)\n}\n```\n\n##### 使用Face Geometry来模拟用户面部\n\nARKit提供了粗粒度的3D网状几何体，来匹配用户的面部大小、形态、拓扑结构以及当前面部表情，当然ARKit还提供了ARSCNFaceGeometry类来快捷的初始化该网格。你可以在用户的皮肤上通过给网状模型添加材质来绘制虚拟的刺青或者面具等。\n\n```\nlet device = sceneView.device!\nlet maskGeometry = ARSCNFaceGeometry(device: device)!\n```\n\n为了让屏幕中面部模型匹配用户的脸部，甚至跟随用户的眨眼、说话或者更多的表情动作，需要在代理方法中更新该面部模型的数据。\n```\nfunc renderer(_ renderer: SCNSceneRenderer, didUpdate node: SCNNode, for anchor: ARAnchor) {\n    guard let faceAnchor = anchor as? ARFaceAnchor else { return }\n\n    let faceGeometry = content.geometry as! ARSCNFaceGeometry\n    faceGeometry.update(from: anchor.geometry)\n}\n\n```\n\n#####  在面部呈现3D内容\n\nARKit提供的面部网格的另一个用途是在场景中创建遮挡几何体。遮挡几何体是不会呈现任何可见内容（允许相机图像显示）的3D模型，但会阻碍相机对场景中其他虚拟内容的视图。这种技术创造出真实面对与虚拟对象交互的错觉，即使脸部是2D摄像机图像，虚拟内容是渲染的3D对象。例如，如果您将遮挡几何图形和虚拟眼镜放置在用户的脸部上，则脸部可能会眼镜框架遮挡。\n要创建面部的遮挡几何，首先创建一个ARSCNFaceGeometry对象，如前面的例子所示。但是，不要使用可见的外观来配置该对象的SceneKit材质，而是在渲染期间将材质设置为渲染深度而不是颜色：\n\n```\n    let geometry = SCNGeometry()\n    geometry.firstMaterial!.colorBufferWriteMask = []\n    occlusionNode = SCNNode(geometry: geometry)\n    occlusionNode.renderingOrder = -1\n```\n\n##### 让你的形象动起来  \n要获取当前用户的面部表情，需要在代理方法renderer:didUpdateNode:forAnchor:中从ARFaceAnchor的blendShapes中读取数据 。\n\n```\nfunc renderer(_ renderer: SCNSceneRenderer, didUpdate node: SCNNode, for anchor: ARAnchor) {\n    blendShapes = faceAnchor.blendShapes\n}\n```\n然后，查看该字典中的键值对以计算模型的动画参数。该字典中有52个独特的ARBlendShapeLocation系数。你可以使用尽可能少的或很多的必要条件来创建想要的艺术效果。在此示例中，RobotHead类执行此计算，映射ARBlendShapeLocationEyeBlinkLeft和ARBlendShapeLocationEyeBlinkRight参数到机器人眼睛的scale参数，用ARBlendShapeLocationJawOpen参数以计算机器人上颌所在的位置。\n```\nvar blendShapes: [ARFaceAnchor.BlendShapeLocation: Any] = [:] {\n    didSet {\n        guard let eyeBlinkLeft = blendShapes[.eyeBlinkLeft] as? Float,\n            let eyeBlinkRight = blendShapes[.eyeBlinkRight] as? Float,\n            let jawOpen = blendShapes[.jawOpen] as? Float\n            else { return }\n        eyeLeftNode.scale.z = 1 - eyeBlinkLeft\n        eyeRightNode.scale.z = 1 - eyeBlinkRight\n        jawNode.position.y = originalJawY - jawHeight * jawOpen\n    }\n}\n```\n\n先简单介绍到这儿，真正要看到效果还得公司的土豪们入手iPhone X之后啦，不过基本用法很简单，维持了ARKit易用的特性。\n\n![致敬Jobs](http://ojca2gwha.bkt.clouddn.com/ARKit-Jobs.jpg)\n\n###### 参考文档\n1. https://developer.apple.com/documentation/arkit/arfacetrackingconfiguration?language=objc\n2. https://developer.apple.com/documentation/arkit/creating_face_based_ar_experiences?language=objc\n","slug":"ARKit-Face","published":1,"updated":"2017-09-25T12:08:01.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj81l54580002wluvhp43jb7w","content":"<p>Apple昨晚发布了强大但是死贵无比的iPhoneX，惊呆了我们。然后只能默默去刷了下API，发现ARKit新添了基于Face的API。<br>之前的版本中前置摄像头是不支持AKKit模块的，幸而新发布的版本中添加了对Face识别的支持，然而新的API需要原前置深感摄像头(TrueDepth Camera)的支持，所以看来还得入手一台iPhone X呐。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/ARKit-iPhoneX.jpg\" alt=\"iPhoneX\">  </p>\n<h4 id=\"新增API\"><a href=\"#新增API\" class=\"headerlink\" title=\"新增API\"></a>新增API</h4><p>首先新增了ARFaceTrackingConfiguration，以用于追踪用户脸部的运动和表情，并在界面中渲染虚拟内容。此外你还可以设置lightEstimationEnabled为true，来启用脸部扫描并提供预估的定向/环境光。</p>\n<p>其次还新增了ARFaceAnchor，这两个新API与之前的ARWorldTrackingConfiguration和ARPlaneAnchor类似，只是基于平面的检测改为了基于Face的检测，恶趣味下Apple会不会继续扩展他的检测API。。。当使用ARFaceTrackingConfiguration时，ARSession会检测用户面部并且用ARFaceAnchor保存面部信息，包括位置、方向、拓扑结构以及表情特征点。</p>\n<p>ARFaceAnchor的transform属性描述了面部在世界坐标系中的所在位置和方向，该世界坐标系可以在ARSessionConfiguration的wordlAlignment中设置。可以使用该transform在ARScene检测到的面部上添加虚拟物体。坐标系如下图所示：</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/ARKit-face-Coordinate.png\" alt=\"ARKit Face coordinate\"></p>\n<p>该坐标系为右手坐标系，x轴只想观察者的右边(即face自己的左边)，y轴指向上边(与face绑定)，z轴指向了观察者。</p>\n<p>ARFaceAnchor的blendShapes属性提供了当前面部表情的高级数据，通过一系列表示面部特征的系数来描述面部表情。你可以使用这些系数跟随用户的面部表情来做2D/3D动画。</p>\n<a id=\"more\"></a>\n<h4 id=\"开始面部跟踪\"><a href=\"#开始面部跟踪\" class=\"headerlink\" title=\"开始面部跟踪\"></a>开始面部跟踪</h4><p>和ARKit的其他用法一样，面部追踪需要ARSessionConfiguration并运行一个ARSession来渲染相机屏幕，这部分可以参考<a href=\"httpbai.ducom\">之前分享的文章</a>，流程一致，只是这部分需要使用到新加的API。<br>如前面所说，面部检测只支持配置了原前置深感摄像头(TrueDepth Camera)的iPhone，所以首先需要判断当前设备是否支持ARFaceTrackingConfiguration。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">// 如果设备支持的判断通过 然后配置Session Configuration</div><div class=\"line\">guard ARFaceTrackingConfiguration.isSupported else &#123; return &#125;</div><div class=\"line\">let configuration = ARFaceTrackingConfiguration()</div><div class=\"line\">configuration.isLightEstimationEnabled = true</div><div class=\"line\">session.run(configuration, options: [.resetTracking, .removeExistingAnchors])</div></pre></td></tr></table></figure>\n<h4 id=\"跟踪脸部位置和方向\"><a href=\"#跟踪脸部位置和方向\" class=\"headerlink\" title=\"跟踪脸部位置和方向\"></a>跟踪脸部位置和方向</h4><p>当面部跟踪启用后，ARKit会自动的添加ARFaceAnchor到ARSession中，包括其位置和方向。  </p>\n<blockquote>\n<p>注意ARKit目前只能追踪单个用户的面部，如果多个用户同时出现在镜头中，则取最大或者最清晰的可识别面部</p>\n</blockquote>\n<p>你可以在代理方法<code>renderer:didAddNode:forAnchor:</code>(ARSCNViewDelegate协议)中给一个face锚点添加相应3D内容。他会跟随用户的面部动作做相应的位置和方向调整。  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">func renderer(_ renderer: SCNSceneRenderer, didAdd node: SCNNode, for anchor: ARAnchor) &#123;</div><div class=\"line\">    let device = sceneView.device!</div><div class=\"line\">    let maskGeometry = ARSCNFaceGeometry(device: device)!</div><div class=\"line\">    let content = SCNNode(geometry:maskGeometry)</div><div class=\"line\">    node.addChildNode(content)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h5 id=\"使用Face-Geometry来模拟用户面部\"><a href=\"#使用Face-Geometry来模拟用户面部\" class=\"headerlink\" title=\"使用Face Geometry来模拟用户面部\"></a>使用Face Geometry来模拟用户面部</h5><p>ARKit提供了粗粒度的3D网状几何体，来匹配用户的面部大小、形态、拓扑结构以及当前面部表情，当然ARKit还提供了ARSCNFaceGeometry类来快捷的初始化该网格。你可以在用户的皮肤上通过给网状模型添加材质来绘制虚拟的刺青或者面具等。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">let device = sceneView.device!</div><div class=\"line\">let maskGeometry = ARSCNFaceGeometry(device: device)!</div></pre></td></tr></table></figure>\n<p>为了让屏幕中面部模型匹配用户的脸部，甚至跟随用户的眨眼、说话或者更多的表情动作，需要在代理方法中更新该面部模型的数据。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">func renderer(_ renderer: SCNSceneRenderer, didUpdate node: SCNNode, for anchor: ARAnchor) &#123;</div><div class=\"line\">    guard let faceAnchor = anchor as? ARFaceAnchor else &#123; return &#125;</div><div class=\"line\"></div><div class=\"line\">    let faceGeometry = content.geometry as! ARSCNFaceGeometry</div><div class=\"line\">    faceGeometry.update(from: anchor.geometry)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h5 id=\"在面部呈现3D内容\"><a href=\"#在面部呈现3D内容\" class=\"headerlink\" title=\"在面部呈现3D内容\"></a>在面部呈现3D内容</h5><p>ARKit提供的面部网格的另一个用途是在场景中创建遮挡几何体。遮挡几何体是不会呈现任何可见内容（允许相机图像显示）的3D模型，但会阻碍相机对场景中其他虚拟内容的视图。这种技术创造出真实面对与虚拟对象交互的错觉，即使脸部是2D摄像机图像，虚拟内容是渲染的3D对象。例如，如果您将遮挡几何图形和虚拟眼镜放置在用户的脸部上，则脸部可能会眼镜框架遮挡。<br>要创建面部的遮挡几何，首先创建一个ARSCNFaceGeometry对象，如前面的例子所示。但是，不要使用可见的外观来配置该对象的SceneKit材质，而是在渲染期间将材质设置为渲染深度而不是颜色：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">let geometry = SCNGeometry()</div><div class=\"line\">geometry.firstMaterial!.colorBufferWriteMask = []</div><div class=\"line\">occlusionNode = SCNNode(geometry: geometry)</div><div class=\"line\">occlusionNode.renderingOrder = -1</div></pre></td></tr></table></figure>\n<h5 id=\"让你的形象动起来\"><a href=\"#让你的形象动起来\" class=\"headerlink\" title=\"让你的形象动起来\"></a>让你的形象动起来</h5><p>要获取当前用户的面部表情，需要在代理方法renderer:didUpdateNode:forAnchor:中从ARFaceAnchor的blendShapes中读取数据 。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">func renderer(_ renderer: SCNSceneRenderer, didUpdate node: SCNNode, for anchor: ARAnchor) &#123;</div><div class=\"line\">    blendShapes = faceAnchor.blendShapes</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>然后，查看该字典中的键值对以计算模型的动画参数。该字典中有52个独特的ARBlendShapeLocation系数。你可以使用尽可能少的或很多的必要条件来创建想要的艺术效果。在此示例中，RobotHead类执行此计算，映射ARBlendShapeLocationEyeBlinkLeft和ARBlendShapeLocationEyeBlinkRight参数到机器人眼睛的scale参数，用ARBlendShapeLocationJawOpen参数以计算机器人上颌所在的位置。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">var blendShapes: [ARFaceAnchor.BlendShapeLocation: Any] = [:] &#123;</div><div class=\"line\">    didSet &#123;</div><div class=\"line\">        guard let eyeBlinkLeft = blendShapes[.eyeBlinkLeft] as? Float,</div><div class=\"line\">            let eyeBlinkRight = blendShapes[.eyeBlinkRight] as? Float,</div><div class=\"line\">            let jawOpen = blendShapes[.jawOpen] as? Float</div><div class=\"line\">            else &#123; return &#125;</div><div class=\"line\">        eyeLeftNode.scale.z = 1 - eyeBlinkLeft</div><div class=\"line\">        eyeRightNode.scale.z = 1 - eyeBlinkRight</div><div class=\"line\">        jawNode.position.y = originalJawY - jawHeight * jawOpen</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>先简单介绍到这儿，真正要看到效果还得公司的土豪们入手iPhone X之后啦，不过基本用法很简单，维持了ARKit易用的特性。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/ARKit-Jobs.jpg\" alt=\"致敬Jobs\"></p>\n<h6 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h6><ol>\n<li><a href=\"https://developer.apple.com/documentation/arkit/arfacetrackingconfiguration?language=objc\" target=\"_blank\" rel=\"external\">https://developer.apple.com/documentation/arkit/arfacetrackingconfiguration?language=objc</a></li>\n<li><a href=\"https://developer.apple.com/documentation/arkit/creating_face_based_ar_experiences?language=objc\" target=\"_blank\" rel=\"external\">https://developer.apple.com/documentation/arkit/creating_face_based_ar_experiences?language=objc</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>Apple昨晚发布了强大但是死贵无比的iPhoneX，惊呆了我们。然后只能默默去刷了下API，发现ARKit新添了基于Face的API。<br>之前的版本中前置摄像头是不支持AKKit模块的，幸而新发布的版本中添加了对Face识别的支持，然而新的API需要原前置深感摄像头(TrueDepth Camera)的支持，所以看来还得入手一台iPhone X呐。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/ARKit-iPhoneX.jpg\" alt=\"iPhoneX\">  </p>\n<h4 id=\"新增API\"><a href=\"#新增API\" class=\"headerlink\" title=\"新增API\"></a>新增API</h4><p>首先新增了ARFaceTrackingConfiguration，以用于追踪用户脸部的运动和表情，并在界面中渲染虚拟内容。此外你还可以设置lightEstimationEnabled为true，来启用脸部扫描并提供预估的定向/环境光。</p>\n<p>其次还新增了ARFaceAnchor，这两个新API与之前的ARWorldTrackingConfiguration和ARPlaneAnchor类似，只是基于平面的检测改为了基于Face的检测，恶趣味下Apple会不会继续扩展他的检测API。。。当使用ARFaceTrackingConfiguration时，ARSession会检测用户面部并且用ARFaceAnchor保存面部信息，包括位置、方向、拓扑结构以及表情特征点。</p>\n<p>ARFaceAnchor的transform属性描述了面部在世界坐标系中的所在位置和方向，该世界坐标系可以在ARSessionConfiguration的wordlAlignment中设置。可以使用该transform在ARScene检测到的面部上添加虚拟物体。坐标系如下图所示：</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/ARKit-face-Coordinate.png\" alt=\"ARKit Face coordinate\"></p>\n<p>该坐标系为右手坐标系，x轴只想观察者的右边(即face自己的左边)，y轴指向上边(与face绑定)，z轴指向了观察者。</p>\n<p>ARFaceAnchor的blendShapes属性提供了当前面部表情的高级数据，通过一系列表示面部特征的系数来描述面部表情。你可以使用这些系数跟随用户的面部表情来做2D/3D动画。</p>","more":"<h4 id=\"开始面部跟踪\"><a href=\"#开始面部跟踪\" class=\"headerlink\" title=\"开始面部跟踪\"></a>开始面部跟踪</h4><p>和ARKit的其他用法一样，面部追踪需要ARSessionConfiguration并运行一个ARSession来渲染相机屏幕，这部分可以参考<a href=\"httpbai.ducom\">之前分享的文章</a>，流程一致，只是这部分需要使用到新加的API。<br>如前面所说，面部检测只支持配置了原前置深感摄像头(TrueDepth Camera)的iPhone，所以首先需要判断当前设备是否支持ARFaceTrackingConfiguration。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">// 如果设备支持的判断通过 然后配置Session Configuration</div><div class=\"line\">guard ARFaceTrackingConfiguration.isSupported else &#123; return &#125;</div><div class=\"line\">let configuration = ARFaceTrackingConfiguration()</div><div class=\"line\">configuration.isLightEstimationEnabled = true</div><div class=\"line\">session.run(configuration, options: [.resetTracking, .removeExistingAnchors])</div></pre></td></tr></table></figure>\n<h4 id=\"跟踪脸部位置和方向\"><a href=\"#跟踪脸部位置和方向\" class=\"headerlink\" title=\"跟踪脸部位置和方向\"></a>跟踪脸部位置和方向</h4><p>当面部跟踪启用后，ARKit会自动的添加ARFaceAnchor到ARSession中，包括其位置和方向。  </p>\n<blockquote>\n<p>注意ARKit目前只能追踪单个用户的面部，如果多个用户同时出现在镜头中，则取最大或者最清晰的可识别面部</p>\n</blockquote>\n<p>你可以在代理方法<code>renderer:didAddNode:forAnchor:</code>(ARSCNViewDelegate协议)中给一个face锚点添加相应3D内容。他会跟随用户的面部动作做相应的位置和方向调整。  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">func renderer(_ renderer: SCNSceneRenderer, didAdd node: SCNNode, for anchor: ARAnchor) &#123;</div><div class=\"line\">    let device = sceneView.device!</div><div class=\"line\">    let maskGeometry = ARSCNFaceGeometry(device: device)!</div><div class=\"line\">    let content = SCNNode(geometry:maskGeometry)</div><div class=\"line\">    node.addChildNode(content)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h5 id=\"使用Face-Geometry来模拟用户面部\"><a href=\"#使用Face-Geometry来模拟用户面部\" class=\"headerlink\" title=\"使用Face Geometry来模拟用户面部\"></a>使用Face Geometry来模拟用户面部</h5><p>ARKit提供了粗粒度的3D网状几何体，来匹配用户的面部大小、形态、拓扑结构以及当前面部表情，当然ARKit还提供了ARSCNFaceGeometry类来快捷的初始化该网格。你可以在用户的皮肤上通过给网状模型添加材质来绘制虚拟的刺青或者面具等。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">let device = sceneView.device!</div><div class=\"line\">let maskGeometry = ARSCNFaceGeometry(device: device)!</div></pre></td></tr></table></figure>\n<p>为了让屏幕中面部模型匹配用户的脸部，甚至跟随用户的眨眼、说话或者更多的表情动作，需要在代理方法中更新该面部模型的数据。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">func renderer(_ renderer: SCNSceneRenderer, didUpdate node: SCNNode, for anchor: ARAnchor) &#123;</div><div class=\"line\">    guard let faceAnchor = anchor as? ARFaceAnchor else &#123; return &#125;</div><div class=\"line\"></div><div class=\"line\">    let faceGeometry = content.geometry as! ARSCNFaceGeometry</div><div class=\"line\">    faceGeometry.update(from: anchor.geometry)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h5 id=\"在面部呈现3D内容\"><a href=\"#在面部呈现3D内容\" class=\"headerlink\" title=\"在面部呈现3D内容\"></a>在面部呈现3D内容</h5><p>ARKit提供的面部网格的另一个用途是在场景中创建遮挡几何体。遮挡几何体是不会呈现任何可见内容（允许相机图像显示）的3D模型，但会阻碍相机对场景中其他虚拟内容的视图。这种技术创造出真实面对与虚拟对象交互的错觉，即使脸部是2D摄像机图像，虚拟内容是渲染的3D对象。例如，如果您将遮挡几何图形和虚拟眼镜放置在用户的脸部上，则脸部可能会眼镜框架遮挡。<br>要创建面部的遮挡几何，首先创建一个ARSCNFaceGeometry对象，如前面的例子所示。但是，不要使用可见的外观来配置该对象的SceneKit材质，而是在渲染期间将材质设置为渲染深度而不是颜色：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">let geometry = SCNGeometry()</div><div class=\"line\">geometry.firstMaterial!.colorBufferWriteMask = []</div><div class=\"line\">occlusionNode = SCNNode(geometry: geometry)</div><div class=\"line\">occlusionNode.renderingOrder = -1</div></pre></td></tr></table></figure>\n<h5 id=\"让你的形象动起来\"><a href=\"#让你的形象动起来\" class=\"headerlink\" title=\"让你的形象动起来\"></a>让你的形象动起来</h5><p>要获取当前用户的面部表情，需要在代理方法renderer:didUpdateNode:forAnchor:中从ARFaceAnchor的blendShapes中读取数据 。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">func renderer(_ renderer: SCNSceneRenderer, didUpdate node: SCNNode, for anchor: ARAnchor) &#123;</div><div class=\"line\">    blendShapes = faceAnchor.blendShapes</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>然后，查看该字典中的键值对以计算模型的动画参数。该字典中有52个独特的ARBlendShapeLocation系数。你可以使用尽可能少的或很多的必要条件来创建想要的艺术效果。在此示例中，RobotHead类执行此计算，映射ARBlendShapeLocationEyeBlinkLeft和ARBlendShapeLocationEyeBlinkRight参数到机器人眼睛的scale参数，用ARBlendShapeLocationJawOpen参数以计算机器人上颌所在的位置。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">var blendShapes: [ARFaceAnchor.BlendShapeLocation: Any] = [:] &#123;</div><div class=\"line\">    didSet &#123;</div><div class=\"line\">        guard let eyeBlinkLeft = blendShapes[.eyeBlinkLeft] as? Float,</div><div class=\"line\">            let eyeBlinkRight = blendShapes[.eyeBlinkRight] as? Float,</div><div class=\"line\">            let jawOpen = blendShapes[.jawOpen] as? Float</div><div class=\"line\">            else &#123; return &#125;</div><div class=\"line\">        eyeLeftNode.scale.z = 1 - eyeBlinkLeft</div><div class=\"line\">        eyeRightNode.scale.z = 1 - eyeBlinkRight</div><div class=\"line\">        jawNode.position.y = originalJawY - jawHeight * jawOpen</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>先简单介绍到这儿，真正要看到效果还得公司的土豪们入手iPhone X之后啦，不过基本用法很简单，维持了ARKit易用的特性。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/ARKit-Jobs.jpg\" alt=\"致敬Jobs\"></p>\n<h6 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h6><ol>\n<li><a href=\"https://developer.apple.com/documentation/arkit/arfacetrackingconfiguration?language=objc\" target=\"_blank\" rel=\"external\">https://developer.apple.com/documentation/arkit/arfacetrackingconfiguration?language=objc</a></li>\n<li><a href=\"https://developer.apple.com/documentation/arkit/creating_face_based_ar_experiences?language=objc\" target=\"_blank\" rel=\"external\">https://developer.apple.com/documentation/arkit/creating_face_based_ar_experiences?language=objc</a></li>\n</ol>"},{"title":"ARKit上手指南 01 添加3D物体","date":"2017-09-08T04:56:22.000Z","_content":"\nARKit是2017年6月6日，苹果发布的iOS11系统所新增的框架,它能够帮助我们以最简单快捷的方式实现AR技术功能。而且ARKit框架对基于3D场景(SceneKit)和2D场景(SpriteKit)的增强现实都提供了支持。\n\n#### 开发环境  \n1. Xcode版本： Xcode9以上   \nXcode 9 Beta：[https://developer.apple.com/download/](https://developer.apple.com/download/)\n下载最新的beta版本就可以了，不过Xcode需要Mac 10.12.4及以上的版本。  \n2. iOS系统： iOS11以上\n3. iOS设备： A9/A10处理器的iOS设备，即iPhone6s、iPad2017及以上的设备\n\n#### 创建项目\n\n首先打开Xcode，选择ARKit模板，如下所示：  \n\n![AR项目创建](http://ojca2gwha.bkt.clouddn.com/ARKit_1Project.png)\n\n之后，填写完项目信息后，选择Content Technology为SceneKit，当然也可以选择SpriteKit，不过在3D空间中就不是那么立体了。\n开发语言选择Swift，Swift天然亲和ARKit，很多网上的Demo都是用Swift写的，这样也方便移植和借鉴。   \n<!--more-->\n然后连接你的测试设备并运行，app就可以运行了。该模版APP会在实施摄像头镜头中展示一架飞机的3D模型。如下图所示：  \n\n![3D飞机](http://ojca2gwha.bkt.clouddn.com/AR-Plane.jpg)\n\n实际项目中，你也可以不使用该模版来创建项目，直接引入相关库也可以进行开发。\n\n在项目中可以看到`viewWillAppear `方法中已经初始化了ARWorldTrackingConfiguration实例。\n\n```\noverride func viewWillAppear(_ animated: Bool) {\n      super.viewWillAppear(animated)  \n\n      // Create a session configuration\n      let configuration = ARWorldTrackingConfiguration()\n\n      // Run the view's session\n      sceneView.session.run(configuration)\n}\n```\n#### 放置3D物体\n\nSceneKit有一些基础类，SCNScene是所有3D内容的容器，可以在其中添加多个3D物体。\n要向scene中添加内容，要创建SCNGeometry，然后将其包装为SCNNode并添加到SCNScene中。\n\n首先注释掉`let scene = SCNScene(named: \"art.scnassets/ship.scn\")! sceneView.scene = scene`，然后添加代码如下：\n\n```\noverride func viewDidLoad() {\n\tsuper.viewDidLoad()\n\t// 存放所有3D几何体的容器\n\tlet scene = SCNScene()\n\n\t// 想要绘制的 3D 立方体\n\tlet boxGeometry = SCNBox(width: 0.1, height: 0.1, length: 0.1, chamferRadius: 0.0)\n\n\t// 将几何体包装为node以便添加到scene\n\tlet boxNode = SCNNode(geometry: boxGeometry)\n\n\t// 把box放在摄像头正前方\n\tboxNode.position = SCNVector3Make(0, 0, -0.5)\n\n\t// rootNode是一个特殊的node，它是所有node的起始点\n\tscene.rootNode.addChildNode(boxNode)\n\n\t// 将 scene 赋给 view\n\tsceneView.scene = scene\n}\n\n```\n\n现在运行该项目，就会看到有3D立方体悬浮在空中，并且全方位无死角。\n\n此外还可以增加一些调试信息\n```\n\t// ARKit统计信息例如fps等\n\tsceneView.showsStatistics = YES;\n\n\tsceneView.debugOptions = [ARSCNDebugOptions.showFeaturePoints];\n\t// 调整摄像头属性 当前摄像头有效直径在10m范围内\n\tif let camera = sceneView.pointOfView?.camera {\n\t\tcamera.wantsHDR = true\n       camera.wantsExposureAdaptation = true\n       camera.exposureOffset = -1\n       camera.minimumExposure = -1\n       camera.zFar = 10\n\t}\n\n```\n\n\n之前简单体验了ARKit的功能，下面简单介绍ARKit的工作原理：   \n\n#### ARKit工作原理\n在ARKit中，创建虚拟3D模型其实可以分为两个步骤：   \n1. 相机捕捉现实世界图像--由ARKit实现   \n2. 在图像中显示虚拟3D模型/2D模型--由SceneKit/SpriteKit实现     \n\nARKit中ARSCNView用于显示3D虚拟AR的视图，它的作用是管理一个ARSession，一个ARSCNView实例默认持有一个ARSession。\n在一个完整的AR体验中，ARKit框架只负责将真实世界画面转变为一个3D场景，这一个转变的过程主要分为两个环节：由ARCamera负责捕捉摄像头画面，由ARSession负责搭建3D场景，而将虚拟物体显示在3D场景中则是由SceneKit框架来完成，每个虚拟物体都是一个节点SCNNode，每个节点构成一个场景SCNScene。  \nARCamera只负责捕捉图像，不参与数据的处理。它属于3D场景中的一个环节，每一个3D Scene都会有一个Camera，它决定了我们看物体的视野。\n下图是ARKit与SceneKit的框架关系图:   \n\n![ARKit class结构](http://ojca2gwha.bkt.clouddn.com/ARKit-class.png)\n\nARSessionConfiguration的主要目的就是负责追踪相机在3D世界中的位置以及一些特征场景的捕捉（例如平面捕捉），这个类本身比较简单却作用巨大。ARSessionConfiguration是一个父类，为了更好的看到增强现实的效果，苹果官方建议我们使用它的子类ARWorldTrackingSessionConfiguration，该类只支持A9芯片之后的机型，也就是iPhone6s之后的机型。\n\n当ARWorldTrackingSessionConfiguration计算出相机在3D世界中的位置时，它本身并不持有这个位置数据，而是将其计算出的位置数据交给ARSession去管理，而相机的位置数据对应的类就是ARFrame。ARSession类一个属性叫做currentFrame，维护的就是ARFrame这个对象。  \n\n![ARFrame](http://ojca2gwha.bkt.clouddn.com/AR-Session.png)\n\nARKit的完整运行流程可以参考下图：\n1. ARSCNView加载场景SCNScene  \n2. SCNScene启动ARCamera开始捕捉图像  \n3. ARSCNView开始将SCNScene的场景数据交给ARSession  \n4. ARSession通过管理ARSessionConfiguration实现场景的追踪并且返回一个ARFrame(添加3D物体模型时计算3D模型相对于相机的真实矩阵位置时需要使用)\n5. 给ARSCNView的SCNScene添加一个子节点(SCNNode)\n\n![ARKit工作流程](http://ojca2gwha.bkt.clouddn.com/AR-flow.png)\n\n本文将会使用ARKit创建一个简单的app，结束时就可以在AR世界里放置3D物体，并且可以用iOS设备绕着它移动。虽然这是一个非常简单的app，我们会在之后的文章中继续为其编写更多功能，包括平面检测、3D物理效果等其他东西。   \n","source":"_posts/ARKit-Add-3d-Content.md","raw":"---\ntitle: ARKit上手指南 01 添加3D物体\ndate: 2017-09-08 12:56:22\ntags:\n   ARKit\ncategories: iOS\n---\n\nARKit是2017年6月6日，苹果发布的iOS11系统所新增的框架,它能够帮助我们以最简单快捷的方式实现AR技术功能。而且ARKit框架对基于3D场景(SceneKit)和2D场景(SpriteKit)的增强现实都提供了支持。\n\n#### 开发环境  \n1. Xcode版本： Xcode9以上   \nXcode 9 Beta：[https://developer.apple.com/download/](https://developer.apple.com/download/)\n下载最新的beta版本就可以了，不过Xcode需要Mac 10.12.4及以上的版本。  \n2. iOS系统： iOS11以上\n3. iOS设备： A9/A10处理器的iOS设备，即iPhone6s、iPad2017及以上的设备\n\n#### 创建项目\n\n首先打开Xcode，选择ARKit模板，如下所示：  \n\n![AR项目创建](http://ojca2gwha.bkt.clouddn.com/ARKit_1Project.png)\n\n之后，填写完项目信息后，选择Content Technology为SceneKit，当然也可以选择SpriteKit，不过在3D空间中就不是那么立体了。\n开发语言选择Swift，Swift天然亲和ARKit，很多网上的Demo都是用Swift写的，这样也方便移植和借鉴。   \n<!--more-->\n然后连接你的测试设备并运行，app就可以运行了。该模版APP会在实施摄像头镜头中展示一架飞机的3D模型。如下图所示：  \n\n![3D飞机](http://ojca2gwha.bkt.clouddn.com/AR-Plane.jpg)\n\n实际项目中，你也可以不使用该模版来创建项目，直接引入相关库也可以进行开发。\n\n在项目中可以看到`viewWillAppear `方法中已经初始化了ARWorldTrackingConfiguration实例。\n\n```\noverride func viewWillAppear(_ animated: Bool) {\n      super.viewWillAppear(animated)  \n\n      // Create a session configuration\n      let configuration = ARWorldTrackingConfiguration()\n\n      // Run the view's session\n      sceneView.session.run(configuration)\n}\n```\n#### 放置3D物体\n\nSceneKit有一些基础类，SCNScene是所有3D内容的容器，可以在其中添加多个3D物体。\n要向scene中添加内容，要创建SCNGeometry，然后将其包装为SCNNode并添加到SCNScene中。\n\n首先注释掉`let scene = SCNScene(named: \"art.scnassets/ship.scn\")! sceneView.scene = scene`，然后添加代码如下：\n\n```\noverride func viewDidLoad() {\n\tsuper.viewDidLoad()\n\t// 存放所有3D几何体的容器\n\tlet scene = SCNScene()\n\n\t// 想要绘制的 3D 立方体\n\tlet boxGeometry = SCNBox(width: 0.1, height: 0.1, length: 0.1, chamferRadius: 0.0)\n\n\t// 将几何体包装为node以便添加到scene\n\tlet boxNode = SCNNode(geometry: boxGeometry)\n\n\t// 把box放在摄像头正前方\n\tboxNode.position = SCNVector3Make(0, 0, -0.5)\n\n\t// rootNode是一个特殊的node，它是所有node的起始点\n\tscene.rootNode.addChildNode(boxNode)\n\n\t// 将 scene 赋给 view\n\tsceneView.scene = scene\n}\n\n```\n\n现在运行该项目，就会看到有3D立方体悬浮在空中，并且全方位无死角。\n\n此外还可以增加一些调试信息\n```\n\t// ARKit统计信息例如fps等\n\tsceneView.showsStatistics = YES;\n\n\tsceneView.debugOptions = [ARSCNDebugOptions.showFeaturePoints];\n\t// 调整摄像头属性 当前摄像头有效直径在10m范围内\n\tif let camera = sceneView.pointOfView?.camera {\n\t\tcamera.wantsHDR = true\n       camera.wantsExposureAdaptation = true\n       camera.exposureOffset = -1\n       camera.minimumExposure = -1\n       camera.zFar = 10\n\t}\n\n```\n\n\n之前简单体验了ARKit的功能，下面简单介绍ARKit的工作原理：   \n\n#### ARKit工作原理\n在ARKit中，创建虚拟3D模型其实可以分为两个步骤：   \n1. 相机捕捉现实世界图像--由ARKit实现   \n2. 在图像中显示虚拟3D模型/2D模型--由SceneKit/SpriteKit实现     \n\nARKit中ARSCNView用于显示3D虚拟AR的视图，它的作用是管理一个ARSession，一个ARSCNView实例默认持有一个ARSession。\n在一个完整的AR体验中，ARKit框架只负责将真实世界画面转变为一个3D场景，这一个转变的过程主要分为两个环节：由ARCamera负责捕捉摄像头画面，由ARSession负责搭建3D场景，而将虚拟物体显示在3D场景中则是由SceneKit框架来完成，每个虚拟物体都是一个节点SCNNode，每个节点构成一个场景SCNScene。  \nARCamera只负责捕捉图像，不参与数据的处理。它属于3D场景中的一个环节，每一个3D Scene都会有一个Camera，它决定了我们看物体的视野。\n下图是ARKit与SceneKit的框架关系图:   \n\n![ARKit class结构](http://ojca2gwha.bkt.clouddn.com/ARKit-class.png)\n\nARSessionConfiguration的主要目的就是负责追踪相机在3D世界中的位置以及一些特征场景的捕捉（例如平面捕捉），这个类本身比较简单却作用巨大。ARSessionConfiguration是一个父类，为了更好的看到增强现实的效果，苹果官方建议我们使用它的子类ARWorldTrackingSessionConfiguration，该类只支持A9芯片之后的机型，也就是iPhone6s之后的机型。\n\n当ARWorldTrackingSessionConfiguration计算出相机在3D世界中的位置时，它本身并不持有这个位置数据，而是将其计算出的位置数据交给ARSession去管理，而相机的位置数据对应的类就是ARFrame。ARSession类一个属性叫做currentFrame，维护的就是ARFrame这个对象。  \n\n![ARFrame](http://ojca2gwha.bkt.clouddn.com/AR-Session.png)\n\nARKit的完整运行流程可以参考下图：\n1. ARSCNView加载场景SCNScene  \n2. SCNScene启动ARCamera开始捕捉图像  \n3. ARSCNView开始将SCNScene的场景数据交给ARSession  \n4. ARSession通过管理ARSessionConfiguration实现场景的追踪并且返回一个ARFrame(添加3D物体模型时计算3D模型相对于相机的真实矩阵位置时需要使用)\n5. 给ARSCNView的SCNScene添加一个子节点(SCNNode)\n\n![ARKit工作流程](http://ojca2gwha.bkt.clouddn.com/AR-flow.png)\n\n本文将会使用ARKit创建一个简单的app，结束时就可以在AR世界里放置3D物体，并且可以用iOS设备绕着它移动。虽然这是一个非常简单的app，我们会在之后的文章中继续为其编写更多功能，包括平面检测、3D物理效果等其他东西。   \n","slug":"ARKit-Add-3d-Content","published":1,"updated":"2017-09-25T12:07:59.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj81l545c0004wluvlry474dl","content":"<p>ARKit是2017年6月6日，苹果发布的iOS11系统所新增的框架,它能够帮助我们以最简单快捷的方式实现AR技术功能。而且ARKit框架对基于3D场景(SceneKit)和2D场景(SpriteKit)的增强现实都提供了支持。</p>\n<h4 id=\"开发环境\"><a href=\"#开发环境\" class=\"headerlink\" title=\"开发环境\"></a>开发环境</h4><ol>\n<li>Xcode版本： Xcode9以上<br>Xcode 9 Beta：<a href=\"https://developer.apple.com/download/\" target=\"_blank\" rel=\"external\">https://developer.apple.com/download/</a><br>下载最新的beta版本就可以了，不过Xcode需要Mac 10.12.4及以上的版本。  </li>\n<li>iOS系统： iOS11以上</li>\n<li>iOS设备： A9/A10处理器的iOS设备，即iPhone6s、iPad2017及以上的设备</li>\n</ol>\n<h4 id=\"创建项目\"><a href=\"#创建项目\" class=\"headerlink\" title=\"创建项目\"></a>创建项目</h4><p>首先打开Xcode，选择ARKit模板，如下所示：  </p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/ARKit_1Project.png\" alt=\"AR项目创建\"></p>\n<p>之后，填写完项目信息后，选择Content Technology为SceneKit，当然也可以选择SpriteKit，不过在3D空间中就不是那么立体了。<br>开发语言选择Swift，Swift天然亲和ARKit，很多网上的Demo都是用Swift写的，这样也方便移植和借鉴。<br><a id=\"more\"></a><br>然后连接你的测试设备并运行，app就可以运行了。该模版APP会在实施摄像头镜头中展示一架飞机的3D模型。如下图所示：  </p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/AR-Plane.jpg\" alt=\"3D飞机\"></p>\n<p>实际项目中，你也可以不使用该模版来创建项目，直接引入相关库也可以进行开发。</p>\n<p>在项目中可以看到<code>viewWillAppear</code>方法中已经初始化了ARWorldTrackingConfiguration实例。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">override func viewWillAppear(_ animated: Bool) &#123;</div><div class=\"line\">      super.viewWillAppear(animated)  </div><div class=\"line\"></div><div class=\"line\">      // Create a session configuration</div><div class=\"line\">      let configuration = ARWorldTrackingConfiguration()</div><div class=\"line\"></div><div class=\"line\">      // Run the view&apos;s session</div><div class=\"line\">      sceneView.session.run(configuration)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h4 id=\"放置3D物体\"><a href=\"#放置3D物体\" class=\"headerlink\" title=\"放置3D物体\"></a>放置3D物体</h4><p>SceneKit有一些基础类，SCNScene是所有3D内容的容器，可以在其中添加多个3D物体。<br>要向scene中添加内容，要创建SCNGeometry，然后将其包装为SCNNode并添加到SCNScene中。</p>\n<p>首先注释掉<code>let scene = SCNScene(named: &quot;art.scnassets/ship.scn&quot;)! sceneView.scene = scene</code>，然后添加代码如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\">override func viewDidLoad() &#123;</div><div class=\"line\">\tsuper.viewDidLoad()</div><div class=\"line\">\t// 存放所有3D几何体的容器</div><div class=\"line\">\tlet scene = SCNScene()</div><div class=\"line\"></div><div class=\"line\">\t// 想要绘制的 3D 立方体</div><div class=\"line\">\tlet boxGeometry = SCNBox(width: 0.1, height: 0.1, length: 0.1, chamferRadius: 0.0)</div><div class=\"line\"></div><div class=\"line\">\t// 将几何体包装为node以便添加到scene</div><div class=\"line\">\tlet boxNode = SCNNode(geometry: boxGeometry)</div><div class=\"line\"></div><div class=\"line\">\t// 把box放在摄像头正前方</div><div class=\"line\">\tboxNode.position = SCNVector3Make(0, 0, -0.5)</div><div class=\"line\"></div><div class=\"line\">\t// rootNode是一个特殊的node，它是所有node的起始点</div><div class=\"line\">\tscene.rootNode.addChildNode(boxNode)</div><div class=\"line\"></div><div class=\"line\">\t// 将 scene 赋给 view</div><div class=\"line\">\tsceneView.scene = scene</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>现在运行该项目，就会看到有3D立方体悬浮在空中，并且全方位无死角。</p>\n<p>此外还可以增加一些调试信息<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">// ARKit统计信息例如fps等</div><div class=\"line\">sceneView.showsStatistics = YES;</div><div class=\"line\"></div><div class=\"line\">sceneView.debugOptions = [ARSCNDebugOptions.showFeaturePoints];</div><div class=\"line\">// 调整摄像头属性 当前摄像头有效直径在10m范围内</div><div class=\"line\">if let camera = sceneView.pointOfView?.camera &#123;</div><div class=\"line\">\tcamera.wantsHDR = true</div><div class=\"line\">      camera.wantsExposureAdaptation = true</div><div class=\"line\">      camera.exposureOffset = -1</div><div class=\"line\">      camera.minimumExposure = -1</div><div class=\"line\">      camera.zFar = 10</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>之前简单体验了ARKit的功能，下面简单介绍ARKit的工作原理：   </p>\n<h4 id=\"ARKit工作原理\"><a href=\"#ARKit工作原理\" class=\"headerlink\" title=\"ARKit工作原理\"></a>ARKit工作原理</h4><p>在ARKit中，创建虚拟3D模型其实可以分为两个步骤：   </p>\n<ol>\n<li>相机捕捉现实世界图像–由ARKit实现   </li>\n<li>在图像中显示虚拟3D模型/2D模型–由SceneKit/SpriteKit实现     </li>\n</ol>\n<p>ARKit中ARSCNView用于显示3D虚拟AR的视图，它的作用是管理一个ARSession，一个ARSCNView实例默认持有一个ARSession。<br>在一个完整的AR体验中，ARKit框架只负责将真实世界画面转变为一个3D场景，这一个转变的过程主要分为两个环节：由ARCamera负责捕捉摄像头画面，由ARSession负责搭建3D场景，而将虚拟物体显示在3D场景中则是由SceneKit框架来完成，每个虚拟物体都是一个节点SCNNode，每个节点构成一个场景SCNScene。<br>ARCamera只负责捕捉图像，不参与数据的处理。它属于3D场景中的一个环节，每一个3D Scene都会有一个Camera，它决定了我们看物体的视野。<br>下图是ARKit与SceneKit的框架关系图:   </p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/ARKit-class.png\" alt=\"ARKit class结构\"></p>\n<p>ARSessionConfiguration的主要目的就是负责追踪相机在3D世界中的位置以及一些特征场景的捕捉（例如平面捕捉），这个类本身比较简单却作用巨大。ARSessionConfiguration是一个父类，为了更好的看到增强现实的效果，苹果官方建议我们使用它的子类ARWorldTrackingSessionConfiguration，该类只支持A9芯片之后的机型，也就是iPhone6s之后的机型。</p>\n<p>当ARWorldTrackingSessionConfiguration计算出相机在3D世界中的位置时，它本身并不持有这个位置数据，而是将其计算出的位置数据交给ARSession去管理，而相机的位置数据对应的类就是ARFrame。ARSession类一个属性叫做currentFrame，维护的就是ARFrame这个对象。  </p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/AR-Session.png\" alt=\"ARFrame\"></p>\n<p>ARKit的完整运行流程可以参考下图：</p>\n<ol>\n<li>ARSCNView加载场景SCNScene  </li>\n<li>SCNScene启动ARCamera开始捕捉图像  </li>\n<li>ARSCNView开始将SCNScene的场景数据交给ARSession  </li>\n<li>ARSession通过管理ARSessionConfiguration实现场景的追踪并且返回一个ARFrame(添加3D物体模型时计算3D模型相对于相机的真实矩阵位置时需要使用)</li>\n<li>给ARSCNView的SCNScene添加一个子节点(SCNNode)</li>\n</ol>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/AR-flow.png\" alt=\"ARKit工作流程\"></p>\n<p>本文将会使用ARKit创建一个简单的app，结束时就可以在AR世界里放置3D物体，并且可以用iOS设备绕着它移动。虽然这是一个非常简单的app，我们会在之后的文章中继续为其编写更多功能，包括平面检测、3D物理效果等其他东西。   </p>\n","site":{"data":{}},"excerpt":"<p>ARKit是2017年6月6日，苹果发布的iOS11系统所新增的框架,它能够帮助我们以最简单快捷的方式实现AR技术功能。而且ARKit框架对基于3D场景(SceneKit)和2D场景(SpriteKit)的增强现实都提供了支持。</p>\n<h4 id=\"开发环境\"><a href=\"#开发环境\" class=\"headerlink\" title=\"开发环境\"></a>开发环境</h4><ol>\n<li>Xcode版本： Xcode9以上<br>Xcode 9 Beta：<a href=\"https://developer.apple.com/download/\" target=\"_blank\" rel=\"external\">https://developer.apple.com/download/</a><br>下载最新的beta版本就可以了，不过Xcode需要Mac 10.12.4及以上的版本。  </li>\n<li>iOS系统： iOS11以上</li>\n<li>iOS设备： A9/A10处理器的iOS设备，即iPhone6s、iPad2017及以上的设备</li>\n</ol>\n<h4 id=\"创建项目\"><a href=\"#创建项目\" class=\"headerlink\" title=\"创建项目\"></a>创建项目</h4><p>首先打开Xcode，选择ARKit模板，如下所示：  </p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/ARKit_1Project.png\" alt=\"AR项目创建\"></p>\n<p>之后，填写完项目信息后，选择Content Technology为SceneKit，当然也可以选择SpriteKit，不过在3D空间中就不是那么立体了。<br>开发语言选择Swift，Swift天然亲和ARKit，很多网上的Demo都是用Swift写的，这样也方便移植和借鉴。<br>","more":"<br>然后连接你的测试设备并运行，app就可以运行了。该模版APP会在实施摄像头镜头中展示一架飞机的3D模型。如下图所示：  </p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/AR-Plane.jpg\" alt=\"3D飞机\"></p>\n<p>实际项目中，你也可以不使用该模版来创建项目，直接引入相关库也可以进行开发。</p>\n<p>在项目中可以看到<code>viewWillAppear</code>方法中已经初始化了ARWorldTrackingConfiguration实例。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div></pre></td><td class=\"code\"><pre><div class=\"line\">override func viewWillAppear(_ animated: Bool) &#123;</div><div class=\"line\">      super.viewWillAppear(animated)  </div><div class=\"line\"></div><div class=\"line\">      // Create a session configuration</div><div class=\"line\">      let configuration = ARWorldTrackingConfiguration()</div><div class=\"line\"></div><div class=\"line\">      // Run the view&apos;s session</div><div class=\"line\">      sceneView.session.run(configuration)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h4 id=\"放置3D物体\"><a href=\"#放置3D物体\" class=\"headerlink\" title=\"放置3D物体\"></a>放置3D物体</h4><p>SceneKit有一些基础类，SCNScene是所有3D内容的容器，可以在其中添加多个3D物体。<br>要向scene中添加内容，要创建SCNGeometry，然后将其包装为SCNNode并添加到SCNScene中。</p>\n<p>首先注释掉<code>let scene = SCNScene(named: &quot;art.scnassets/ship.scn&quot;)! sceneView.scene = scene</code>，然后添加代码如下：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div></pre></td><td class=\"code\"><pre><div class=\"line\">override func viewDidLoad() &#123;</div><div class=\"line\">\tsuper.viewDidLoad()</div><div class=\"line\">\t// 存放所有3D几何体的容器</div><div class=\"line\">\tlet scene = SCNScene()</div><div class=\"line\"></div><div class=\"line\">\t// 想要绘制的 3D 立方体</div><div class=\"line\">\tlet boxGeometry = SCNBox(width: 0.1, height: 0.1, length: 0.1, chamferRadius: 0.0)</div><div class=\"line\"></div><div class=\"line\">\t// 将几何体包装为node以便添加到scene</div><div class=\"line\">\tlet boxNode = SCNNode(geometry: boxGeometry)</div><div class=\"line\"></div><div class=\"line\">\t// 把box放在摄像头正前方</div><div class=\"line\">\tboxNode.position = SCNVector3Make(0, 0, -0.5)</div><div class=\"line\"></div><div class=\"line\">\t// rootNode是一个特殊的node，它是所有node的起始点</div><div class=\"line\">\tscene.rootNode.addChildNode(boxNode)</div><div class=\"line\"></div><div class=\"line\">\t// 将 scene 赋给 view</div><div class=\"line\">\tsceneView.scene = scene</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>现在运行该项目，就会看到有3D立方体悬浮在空中，并且全方位无死角。</p>\n<p>此外还可以增加一些调试信息<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div></pre></td><td class=\"code\"><pre><div class=\"line\">// ARKit统计信息例如fps等</div><div class=\"line\">sceneView.showsStatistics = YES;</div><div class=\"line\"></div><div class=\"line\">sceneView.debugOptions = [ARSCNDebugOptions.showFeaturePoints];</div><div class=\"line\">// 调整摄像头属性 当前摄像头有效直径在10m范围内</div><div class=\"line\">if let camera = sceneView.pointOfView?.camera &#123;</div><div class=\"line\">\tcamera.wantsHDR = true</div><div class=\"line\">      camera.wantsExposureAdaptation = true</div><div class=\"line\">      camera.exposureOffset = -1</div><div class=\"line\">      camera.minimumExposure = -1</div><div class=\"line\">      camera.zFar = 10</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>之前简单体验了ARKit的功能，下面简单介绍ARKit的工作原理：   </p>\n<h4 id=\"ARKit工作原理\"><a href=\"#ARKit工作原理\" class=\"headerlink\" title=\"ARKit工作原理\"></a>ARKit工作原理</h4><p>在ARKit中，创建虚拟3D模型其实可以分为两个步骤：   </p>\n<ol>\n<li>相机捕捉现实世界图像–由ARKit实现   </li>\n<li>在图像中显示虚拟3D模型/2D模型–由SceneKit/SpriteKit实现     </li>\n</ol>\n<p>ARKit中ARSCNView用于显示3D虚拟AR的视图，它的作用是管理一个ARSession，一个ARSCNView实例默认持有一个ARSession。<br>在一个完整的AR体验中，ARKit框架只负责将真实世界画面转变为一个3D场景，这一个转变的过程主要分为两个环节：由ARCamera负责捕捉摄像头画面，由ARSession负责搭建3D场景，而将虚拟物体显示在3D场景中则是由SceneKit框架来完成，每个虚拟物体都是一个节点SCNNode，每个节点构成一个场景SCNScene。<br>ARCamera只负责捕捉图像，不参与数据的处理。它属于3D场景中的一个环节，每一个3D Scene都会有一个Camera，它决定了我们看物体的视野。<br>下图是ARKit与SceneKit的框架关系图:   </p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/ARKit-class.png\" alt=\"ARKit class结构\"></p>\n<p>ARSessionConfiguration的主要目的就是负责追踪相机在3D世界中的位置以及一些特征场景的捕捉（例如平面捕捉），这个类本身比较简单却作用巨大。ARSessionConfiguration是一个父类，为了更好的看到增强现实的效果，苹果官方建议我们使用它的子类ARWorldTrackingSessionConfiguration，该类只支持A9芯片之后的机型，也就是iPhone6s之后的机型。</p>\n<p>当ARWorldTrackingSessionConfiguration计算出相机在3D世界中的位置时，它本身并不持有这个位置数据，而是将其计算出的位置数据交给ARSession去管理，而相机的位置数据对应的类就是ARFrame。ARSession类一个属性叫做currentFrame，维护的就是ARFrame这个对象。  </p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/AR-Session.png\" alt=\"ARFrame\"></p>\n<p>ARKit的完整运行流程可以参考下图：</p>\n<ol>\n<li>ARSCNView加载场景SCNScene  </li>\n<li>SCNScene启动ARCamera开始捕捉图像  </li>\n<li>ARSCNView开始将SCNScene的场景数据交给ARSession  </li>\n<li>ARSession通过管理ARSessionConfiguration实现场景的追踪并且返回一个ARFrame(添加3D物体模型时计算3D模型相对于相机的真实矩阵位置时需要使用)</li>\n<li>给ARSCNView的SCNScene添加一个子节点(SCNNode)</li>\n</ol>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/AR-flow.png\" alt=\"ARKit工作流程\"></p>\n<p>本文将会使用ARKit创建一个简单的app，结束时就可以在AR世界里放置3D物体，并且可以用iOS设备绕着它移动。虽然这是一个非常简单的app，我们会在之后的文章中继续为其编写更多功能，包括平面检测、3D物理效果等其他东西。   </p>"},{"title":"ARKit 上手指南 02 平面检测","date":"2017-09-12T12:53:07.000Z","_content":"\n上一小节中，我们在ARKit虚拟世界中添加了3D物体，接下来我们会使用ARKit检测现实世界的平面。这样我们才能在平面上放置物体以及进行其他操作。\n\n#### 检测平面  \n\n如果要在ARKit空间里检测水平面，需要设置ARSessionConfiguration的planeDetection属性为ARPlaneDetectionHorizontal。设置完后，ARSceneView的delegate方法会收到回调。\n\n```\nfunc renderer(_ renderer: SCNSceneRenderer, didAdd node: SCNNode, for anchor: ARAnchor) {\n    DispatchQueue.main.async {\n        if let planeAnchor = anchor as? ARPlaneAnchor {\n            self.addPlane(node: node, anchor: planeAnchor)\n        }\n    }\n }\n```\n\n每次ARKit认为检测到平面时都会调用该方法，并且返回一个ARAnchor对象，包含当前检测平面锚点，其真正类型是ARPlaneAnchor，拥有extent(范围)、center(中心)等属性信息。\n```\nopen class ARPlaneAnchor : ARAnchor {\n    // The alignment of the plane.\n    open var alignment: ARPlaneAnchor.Alignment { get }\n\n    // The center of the plane in the anchor’s coordinate space.\n    open var center: vector_float3 { get }\n\n\t // The extent of the plane in the anchor’s coordinate space.\n    open var extent: vector_float3 { get }\n}\n```\n\n#### 渲染平面\n\n根据第一步得到的锚点信息，我们可以在ARKit的空间中绘制一个3D平面。创建一个Plance类，继承自SCNNode来管理需要渲染的平面，然后创建SCNGeometry子类SCNPlane的对象，可以用该对象创建平面对应的SCNNode。在构造方法中创建平面并调整其大小：\n\n```\ninit(_ anchor: ARPlaneAnchor) {\n\t...\n\t// 用ARPlaneAnchor的尺寸来创建3D平面几何体\n\tlet plane = SCNPlane(width: CGFloat(anchor.extent.x - 0.05), height: CGFloat(anchor.extent.z - 0.05))\n\tlet material = SCNMaterial()\n\tmaterial.colorBufferWriteMask = []\n\tmaterial.isDoubleSided = true\n\tplane.materials = [material]\n\n\tplaneNode = SCNNode()\n\tplaneNode!.geometry = plane\n\t// SceneKit 里的平面默认是垂直的，所以需要旋转90度来匹配 ARKit 中的平面\n\tplaneNode!.transform = SCNMatrix4MakeRotation(-Float.pi / 2.0, 1, 0, 0)\n\t// 将平面plane移动到ARKit对应的位置\n\tplaneNode!.position = SCNVector3Make(anchor.center.x, -0.01, anchor.center.z)\n}\n```\n\n然后在ARSCNViewDelegate的回调方法中，每次扫描到新的ARAnchor时都可以创建新的平面。\n\n```\n    func renderer(_ renderer: SCNSceneRenderer, didAdd node: SCNNode, for anchor: ARAnchor) {\n        DispatchQueue.main.async {\n            if let planeAnchor = anchor as? ARPlaneAnchor {\n              let plane = Plane(anchor)\n\t\t        node.addChildNode(plane)\n            }\n        }\n    }\n\n```\n\n#### 更新平面\n\n上述创建渲染的平面只会保持创建时的大小，然后现实世界的平面可能比创建初始化的大很多，若需要更新平面的大小，需要更新平面的extent(范围)值。\n\n可以从ARSCNViewDelegate的代理方法中获取到更新的信息：\n\n```\n    func renderer(_ renderer: SCNSceneRenderer, didUpdate node: SCNNode, for anchor: ARAnchor) {\n        DispatchQueue.main.async {\n            if let planeAnchor = anchor as? ARPlaneAnchor {\n\t            plane.update(anchor)\n            }\n        }\n    }\n\n```\n\n然后在Plane类的update方法里，更新plane的宽高：\n```\n\tfunc update(_ anchor: ARPlaneAnchor) {\n\t\tplane.width = CGFloat(anchor.extent.x - 0.05)\n\t\tplane.height = CGFloat(anchor.extent.z - 0.05)\n\t\t// 更新位置\n\t\tplane.position = SCNVector3Make(anchor.center.x, -0.01, anchor.center.z)\n\t}\n\n```\n","source":"_posts/ARKit-Plane-Detector.md","raw":"---\ntitle: ARKit 上手指南 02 平面检测\ndate: 2017-09-12 20:53:07\ntags:\n   ARKit\ncategories: iOS\n---\n\n上一小节中，我们在ARKit虚拟世界中添加了3D物体，接下来我们会使用ARKit检测现实世界的平面。这样我们才能在平面上放置物体以及进行其他操作。\n\n#### 检测平面  \n\n如果要在ARKit空间里检测水平面，需要设置ARSessionConfiguration的planeDetection属性为ARPlaneDetectionHorizontal。设置完后，ARSceneView的delegate方法会收到回调。\n\n```\nfunc renderer(_ renderer: SCNSceneRenderer, didAdd node: SCNNode, for anchor: ARAnchor) {\n    DispatchQueue.main.async {\n        if let planeAnchor = anchor as? ARPlaneAnchor {\n            self.addPlane(node: node, anchor: planeAnchor)\n        }\n    }\n }\n```\n\n每次ARKit认为检测到平面时都会调用该方法，并且返回一个ARAnchor对象，包含当前检测平面锚点，其真正类型是ARPlaneAnchor，拥有extent(范围)、center(中心)等属性信息。\n```\nopen class ARPlaneAnchor : ARAnchor {\n    // The alignment of the plane.\n    open var alignment: ARPlaneAnchor.Alignment { get }\n\n    // The center of the plane in the anchor’s coordinate space.\n    open var center: vector_float3 { get }\n\n\t // The extent of the plane in the anchor’s coordinate space.\n    open var extent: vector_float3 { get }\n}\n```\n\n#### 渲染平面\n\n根据第一步得到的锚点信息，我们可以在ARKit的空间中绘制一个3D平面。创建一个Plance类，继承自SCNNode来管理需要渲染的平面，然后创建SCNGeometry子类SCNPlane的对象，可以用该对象创建平面对应的SCNNode。在构造方法中创建平面并调整其大小：\n\n```\ninit(_ anchor: ARPlaneAnchor) {\n\t...\n\t// 用ARPlaneAnchor的尺寸来创建3D平面几何体\n\tlet plane = SCNPlane(width: CGFloat(anchor.extent.x - 0.05), height: CGFloat(anchor.extent.z - 0.05))\n\tlet material = SCNMaterial()\n\tmaterial.colorBufferWriteMask = []\n\tmaterial.isDoubleSided = true\n\tplane.materials = [material]\n\n\tplaneNode = SCNNode()\n\tplaneNode!.geometry = plane\n\t// SceneKit 里的平面默认是垂直的，所以需要旋转90度来匹配 ARKit 中的平面\n\tplaneNode!.transform = SCNMatrix4MakeRotation(-Float.pi / 2.0, 1, 0, 0)\n\t// 将平面plane移动到ARKit对应的位置\n\tplaneNode!.position = SCNVector3Make(anchor.center.x, -0.01, anchor.center.z)\n}\n```\n\n然后在ARSCNViewDelegate的回调方法中，每次扫描到新的ARAnchor时都可以创建新的平面。\n\n```\n    func renderer(_ renderer: SCNSceneRenderer, didAdd node: SCNNode, for anchor: ARAnchor) {\n        DispatchQueue.main.async {\n            if let planeAnchor = anchor as? ARPlaneAnchor {\n              let plane = Plane(anchor)\n\t\t        node.addChildNode(plane)\n            }\n        }\n    }\n\n```\n\n#### 更新平面\n\n上述创建渲染的平面只会保持创建时的大小，然后现实世界的平面可能比创建初始化的大很多，若需要更新平面的大小，需要更新平面的extent(范围)值。\n\n可以从ARSCNViewDelegate的代理方法中获取到更新的信息：\n\n```\n    func renderer(_ renderer: SCNSceneRenderer, didUpdate node: SCNNode, for anchor: ARAnchor) {\n        DispatchQueue.main.async {\n            if let planeAnchor = anchor as? ARPlaneAnchor {\n\t            plane.update(anchor)\n            }\n        }\n    }\n\n```\n\n然后在Plane类的update方法里，更新plane的宽高：\n```\n\tfunc update(_ anchor: ARPlaneAnchor) {\n\t\tplane.width = CGFloat(anchor.extent.x - 0.05)\n\t\tplane.height = CGFloat(anchor.extent.z - 0.05)\n\t\t// 更新位置\n\t\tplane.position = SCNVector3Make(anchor.center.x, -0.01, anchor.center.z)\n\t}\n\n```\n","slug":"ARKit-Plane-Detector","published":1,"updated":"2017-09-25T12:08:03.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj81l545k0008wluvkcf0ew2d","content":"<p>上一小节中，我们在ARKit虚拟世界中添加了3D物体，接下来我们会使用ARKit检测现实世界的平面。这样我们才能在平面上放置物体以及进行其他操作。</p>\n<h4 id=\"检测平面\"><a href=\"#检测平面\" class=\"headerlink\" title=\"检测平面\"></a>检测平面</h4><p>如果要在ARKit空间里检测水平面，需要设置ARSessionConfiguration的planeDetection属性为ARPlaneDetectionHorizontal。设置完后，ARSceneView的delegate方法会收到回调。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">func renderer(_ renderer: SCNSceneRenderer, didAdd node: SCNNode, for anchor: ARAnchor) &#123;</div><div class=\"line\">    DispatchQueue.main.async &#123;</div><div class=\"line\">        if let planeAnchor = anchor as? ARPlaneAnchor &#123;</div><div class=\"line\">            self.addPlane(node: node, anchor: planeAnchor)</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\"> &#125;</div></pre></td></tr></table></figure>\n<p>每次ARKit认为检测到平面时都会调用该方法，并且返回一个ARAnchor对象，包含当前检测平面锚点，其真正类型是ARPlaneAnchor，拥有extent(范围)、center(中心)等属性信息。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">open class ARPlaneAnchor : ARAnchor &#123;</div><div class=\"line\">    // The alignment of the plane.</div><div class=\"line\">    open var alignment: ARPlaneAnchor.Alignment &#123; get &#125;</div><div class=\"line\"></div><div class=\"line\">    // The center of the plane in the anchor’s coordinate space.</div><div class=\"line\">    open var center: vector_float3 &#123; get &#125;</div><div class=\"line\"></div><div class=\"line\">\t // The extent of the plane in the anchor’s coordinate space.</div><div class=\"line\">    open var extent: vector_float3 &#123; get &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h4 id=\"渲染平面\"><a href=\"#渲染平面\" class=\"headerlink\" title=\"渲染平面\"></a>渲染平面</h4><p>根据第一步得到的锚点信息，我们可以在ARKit的空间中绘制一个3D平面。创建一个Plance类，继承自SCNNode来管理需要渲染的平面，然后创建SCNGeometry子类SCNPlane的对象，可以用该对象创建平面对应的SCNNode。在构造方法中创建平面并调整其大小：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\">init(_ anchor: ARPlaneAnchor) &#123;</div><div class=\"line\">\t...</div><div class=\"line\">\t// 用ARPlaneAnchor的尺寸来创建3D平面几何体</div><div class=\"line\">\tlet plane = SCNPlane(width: CGFloat(anchor.extent.x - 0.05), height: CGFloat(anchor.extent.z - 0.05))</div><div class=\"line\">\tlet material = SCNMaterial()</div><div class=\"line\">\tmaterial.colorBufferWriteMask = []</div><div class=\"line\">\tmaterial.isDoubleSided = true</div><div class=\"line\">\tplane.materials = [material]</div><div class=\"line\"></div><div class=\"line\">\tplaneNode = SCNNode()</div><div class=\"line\">\tplaneNode!.geometry = plane</div><div class=\"line\">\t// SceneKit 里的平面默认是垂直的，所以需要旋转90度来匹配 ARKit 中的平面</div><div class=\"line\">\tplaneNode!.transform = SCNMatrix4MakeRotation(-Float.pi / 2.0, 1, 0, 0)</div><div class=\"line\">\t// 将平面plane移动到ARKit对应的位置</div><div class=\"line\">\tplaneNode!.position = SCNVector3Make(anchor.center.x, -0.01, anchor.center.z)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>然后在ARSCNViewDelegate的回调方法中，每次扫描到新的ARAnchor时都可以创建新的平面。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">func renderer(_ renderer: SCNSceneRenderer, didAdd node: SCNNode, for anchor: ARAnchor) &#123;</div><div class=\"line\">    DispatchQueue.main.async &#123;</div><div class=\"line\">        if let planeAnchor = anchor as? ARPlaneAnchor &#123;</div><div class=\"line\">          let plane = Plane(anchor)</div><div class=\"line\">      node.addChildNode(plane)</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h4 id=\"更新平面\"><a href=\"#更新平面\" class=\"headerlink\" title=\"更新平面\"></a>更新平面</h4><p>上述创建渲染的平面只会保持创建时的大小，然后现实世界的平面可能比创建初始化的大很多，若需要更新平面的大小，需要更新平面的extent(范围)值。</p>\n<p>可以从ARSCNViewDelegate的代理方法中获取到更新的信息：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">func renderer(_ renderer: SCNSceneRenderer, didUpdate node: SCNNode, for anchor: ARAnchor) &#123;</div><div class=\"line\">    DispatchQueue.main.async &#123;</div><div class=\"line\">        if let planeAnchor = anchor as? ARPlaneAnchor &#123;</div><div class=\"line\">         plane.update(anchor)</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>然后在Plane类的update方法里，更新plane的宽高：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">func update(_ anchor: ARPlaneAnchor) &#123;</div><div class=\"line\">\tplane.width = CGFloat(anchor.extent.x - 0.05)</div><div class=\"line\">\tplane.height = CGFloat(anchor.extent.z - 0.05)</div><div class=\"line\">\t// 更新位置</div><div class=\"line\">\tplane.position = SCNVector3Make(anchor.center.x, -0.01, anchor.center.z)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"","more":"<p>上一小节中，我们在ARKit虚拟世界中添加了3D物体，接下来我们会使用ARKit检测现实世界的平面。这样我们才能在平面上放置物体以及进行其他操作。</p>\n<h4 id=\"检测平面\"><a href=\"#检测平面\" class=\"headerlink\" title=\"检测平面\"></a>检测平面</h4><p>如果要在ARKit空间里检测水平面，需要设置ARSessionConfiguration的planeDetection属性为ARPlaneDetectionHorizontal。设置完后，ARSceneView的delegate方法会收到回调。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">func renderer(_ renderer: SCNSceneRenderer, didAdd node: SCNNode, for anchor: ARAnchor) &#123;</div><div class=\"line\">    DispatchQueue.main.async &#123;</div><div class=\"line\">        if let planeAnchor = anchor as? ARPlaneAnchor &#123;</div><div class=\"line\">            self.addPlane(node: node, anchor: planeAnchor)</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\"> &#125;</div></pre></td></tr></table></figure>\n<p>每次ARKit认为检测到平面时都会调用该方法，并且返回一个ARAnchor对象，包含当前检测平面锚点，其真正类型是ARPlaneAnchor，拥有extent(范围)、center(中心)等属性信息。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">open class ARPlaneAnchor : ARAnchor &#123;</div><div class=\"line\">    // The alignment of the plane.</div><div class=\"line\">    open var alignment: ARPlaneAnchor.Alignment &#123; get &#125;</div><div class=\"line\"></div><div class=\"line\">    // The center of the plane in the anchor’s coordinate space.</div><div class=\"line\">    open var center: vector_float3 &#123; get &#125;</div><div class=\"line\"></div><div class=\"line\">\t // The extent of the plane in the anchor’s coordinate space.</div><div class=\"line\">    open var extent: vector_float3 &#123; get &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<h4 id=\"渲染平面\"><a href=\"#渲染平面\" class=\"headerlink\" title=\"渲染平面\"></a>渲染平面</h4><p>根据第一步得到的锚点信息，我们可以在ARKit的空间中绘制一个3D平面。创建一个Plance类，继承自SCNNode来管理需要渲染的平面，然后创建SCNGeometry子类SCNPlane的对象，可以用该对象创建平面对应的SCNNode。在构造方法中创建平面并调整其大小：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div></pre></td><td class=\"code\"><pre><div class=\"line\">init(_ anchor: ARPlaneAnchor) &#123;</div><div class=\"line\">\t...</div><div class=\"line\">\t// 用ARPlaneAnchor的尺寸来创建3D平面几何体</div><div class=\"line\">\tlet plane = SCNPlane(width: CGFloat(anchor.extent.x - 0.05), height: CGFloat(anchor.extent.z - 0.05))</div><div class=\"line\">\tlet material = SCNMaterial()</div><div class=\"line\">\tmaterial.colorBufferWriteMask = []</div><div class=\"line\">\tmaterial.isDoubleSided = true</div><div class=\"line\">\tplane.materials = [material]</div><div class=\"line\"></div><div class=\"line\">\tplaneNode = SCNNode()</div><div class=\"line\">\tplaneNode!.geometry = plane</div><div class=\"line\">\t// SceneKit 里的平面默认是垂直的，所以需要旋转90度来匹配 ARKit 中的平面</div><div class=\"line\">\tplaneNode!.transform = SCNMatrix4MakeRotation(-Float.pi / 2.0, 1, 0, 0)</div><div class=\"line\">\t// 将平面plane移动到ARKit对应的位置</div><div class=\"line\">\tplaneNode!.position = SCNVector3Make(anchor.center.x, -0.01, anchor.center.z)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>然后在ARSCNViewDelegate的回调方法中，每次扫描到新的ARAnchor时都可以创建新的平面。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">func renderer(_ renderer: SCNSceneRenderer, didAdd node: SCNNode, for anchor: ARAnchor) &#123;</div><div class=\"line\">    DispatchQueue.main.async &#123;</div><div class=\"line\">        if let planeAnchor = anchor as? ARPlaneAnchor &#123;</div><div class=\"line\">          let plane = Plane(anchor)</div><div class=\"line\">      node.addChildNode(plane)</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h4 id=\"更新平面\"><a href=\"#更新平面\" class=\"headerlink\" title=\"更新平面\"></a>更新平面</h4><p>上述创建渲染的平面只会保持创建时的大小，然后现实世界的平面可能比创建初始化的大很多，若需要更新平面的大小，需要更新平面的extent(范围)值。</p>\n<p>可以从ARSCNViewDelegate的代理方法中获取到更新的信息：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">func renderer(_ renderer: SCNSceneRenderer, didUpdate node: SCNNode, for anchor: ARAnchor) &#123;</div><div class=\"line\">    DispatchQueue.main.async &#123;</div><div class=\"line\">        if let planeAnchor = anchor as? ARPlaneAnchor &#123;</div><div class=\"line\">         plane.update(anchor)</div><div class=\"line\">        &#125;</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>然后在Plane类的update方法里，更新plane的宽高：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">func update(_ anchor: ARPlaneAnchor) &#123;</div><div class=\"line\">\tplane.width = CGFloat(anchor.extent.x - 0.05)</div><div class=\"line\">\tplane.height = CGFloat(anchor.extent.z - 0.05)</div><div class=\"line\">\t// 更新位置</div><div class=\"line\">\tplane.position = SCNVector3Make(anchor.center.x, -0.01, anchor.center.z)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n"},{"title":"ARKit入坑指南--技术实现分析","date":"2017-06-27T17:16:11.000Z","type":"ARKit","_content":"\n### ARKit简介\n\n  iOS11发布了ARKit之后，iPhone瞬间变成了最大的AR平台。一直以来对这块都比较感兴趣，最近简单做了些研究，下面介绍下ARKit基础的一些概念，算是当作入坑路径吧。\n  ARKit是一种为iOS构建增强现实（AR，augmented reality）App的框架，意在实现将虚拟内容精确且真实地浸入真实世界场景上。ARKit的核心是为一些基本的关键功能提供支持，包括运动跟踪、水平面检测，以及尺度和环境光预测。\n  有些人认为ARKit是一种SLAM实现，也有人认为是VIO。下面分别简单介绍下对ARKit的技术实现方式的不同理解。\n\n#### 1.Slam的概念  \n\n  SLAM，全称叫做Simultaneous Localization and Mapping，中文叫做同时定位与建图。就是通过传感器获取环境的有限信息，比如视觉信息、深度信息、自身的加速度和角速度等来确定自己的相对或者绝对位置，并完成对于地图的构建。简单点可以说是一个传感器在不停的运动，还在实时的扫描着周围的地形。\n  与其说SLAM是一种技术，不如说是一种概念，SLAM可通过多种方法实现。\n\n  要实现SLAM，最基础就是传感器，目前传感器分为激光和VSLAM两大类。激光雷达由于精度高、速度快，能方便地实现SLAM功能而被研究得最多，主要用于机器人及无人车（机）领域，但缺点就是价格昂贵。   \n  而VSLAM则主要用摄像头来实现，摄像头品种繁多，主要分为单目、双目（或多目）、RGBD。实现难度正序：单目视觉>双目视觉>RGBD。  单目视觉因为基于一个摄像头，在深度感知上存在问题，无法得到机器人的运动轨迹及地图的真实大小，但这也使得单目SLAM不受环境大小的影响，既可用于室内，又可用于室外。\n\n  目前，SLAM技术的实现途径主要包括VSLAM、Wifi-SLAM与Lidar SLAM。\n\n  <!--more-->\n##### VSLAM (视觉SLAM)  \n\n  指在室内环境下，用摄像机、Kinect等深度相机来做导航和探索。其工作原理简单来说就是对机器人周边的环境进行光学处理，先用摄像头进行图像信息采集，将采集的信息进行压缩，然后将它反馈到一个由神经网络和统计学方法构成的学习子系统，再由学习子系统将采集到的图像信息和机器人的实际位置联系起来，完成机器人的自主导航定位功能。  \n  但是，室内的VSLAM仍处于研究阶段，远未到实际应用的程度。一方面，计算量太大，对机器人系统的性能要求较高；另一方面，VSLAM生成的地图（多数是点云）还不能用来做机器人的路径规划，需要进一步探索和研究。\n\n##### Wifi-SLAM\n\n  这项技术主要作用是室内定位，指利用智能手机中的多种传感设备进行定位，包括Wifi、GPS、陀螺仪、加速计和磁力计，并通过机器学**和模式识别等算法将获得的数据绘制出准确的室内地图。\n\n  该技术的提供商已于2013年被苹果公司收购，苹果公司是否已经把 Wifi-SLAM 的科技用到iPhone上，使所有 iPhone 用户相当于携带了一个绘图小机器人，这一切暂未可知。毋庸置疑的是，更精准的定位不仅有利于地图，它会让所有依赖地理位置的应用（LBS) 更加精准。\n\n##### Lidar SLAM\n\n  指利用激光雷达作为传感器，获取地图数据，使机器人实现同步定位与地图构建。该技术是目前最稳定、最可靠、高性能的SLAM方式。就技术本身而言，经过多年验证，已相当成熟，但Lidar成本昂贵这一瓶颈问题亟待解决。  \n  Google无人驾驶汽车正是采用该项技术，车顶安装的激光雷达来自美国Velodyne公司，售价高达7万美元以上。  \n  这款激光雷达可以在高速旋转时向周围发射64束激光，激光碰到周围物体并返回，便可计算出车体与周边物体的距离。  \n  计算机系统再根据这些数据描绘出精细的3D地形图，然后与高分辨率地图相结合，生成不同的数据模型供车载计算机系统使用。激光雷达占去了整车成本的一半，这可能也是 Google 无人车迟迟无法量产的原因之一。  \n  对于 AR/VR 使用场景的室内空间定位，我们可以通过蓝牙，路由器等建立标准点，或者通过红外线进行室内扫描来进行判定。但是一旦将室内定位与 VR 联系起来，就无法通过其它设备进行辅助了。目前我们已经能通过 Oculus 和 HTC Vive 的摄像头和「base station」做到进行小范围内的室内定位，但在移动 VR 领域里，空间定位一直是难题，目前还没有任何一个消费者级移动 VR 设备能够做到空间移动。\n\n#### 2. VIO系统  \n\n  另一种理解是，从技术角度说，ARKit是一种具备简单2D平面检测（Plane detection）能力的视觉惯性里程计（Visual Inertial Odometry，VIO）系统。VIO意味着可以通过软件实时追踪用户在空间中的位置（用户的6dof姿态），例如在屏幕每刷新一帧的过程中重新计算用户姿态，这种操作每秒钟大约进行30次或更高频率。这种计算工作会并行进行两次。用户姿态可通过视觉（摄像头）系统进行追踪，为此需要将现实世界中的点与相机传感器拍摄的每一帧画面上的一个像素进行匹配。此外还需要通过惯性系统（加速计和陀螺仪，统称为惯性测量装置[Inertial Measurement Unit]，即IMU）追踪用户姿态。随后这些系统的输出结果会通过Kalman Filter合并，进而确定其中哪个系统能对用户的“实际”位置（也叫做地表实况[Ground Truth]）提供最佳估测，并通过ARKit SDK发布位置更新。与汽车中统计行驶距离的里程表类似，VIO系统会追踪iPhone在6D空间中的移动距离，6D代表3D世界中的xyz移动（转换），外加俯仰（Pitch）/偏航（Yaw）/翻滚（Roll）的3D移动（旋转）。\n\n  ![AR_6dof](http://ojca2gwha.bkt.clouddn.com/AR_6DOF.jpg)\n\n  VIO最大的优势在于，IMU的读数每秒可更新大约1000次，其数值完全基于加速度（用户的移动）。以往主要使用航位推算（Dead Reckoning）技术测量设备在两个IMU读数之间的移动，但这种技术只能进行猜测，就比如我让你迈出一步，随后猜测你的一步有多长距离一样，此时只能用航位推算技术来估测距离。\n  惯性系统的误差会逐渐累积，因此两个IMU帧之间的时间间隔越长，或者惯性系统不通过视觉系统进行“重置”一直使用的时间越长，追踪结果与地表实况之间的误差就越大。视觉/光学测量的频率可与摄像头的帧率保持一致，通常为30fps，并且完全基于距离（两个帧之间的场景变化）。光学系统的误差通常会随着距离而累积（时间的影响反而比较小），因此移动的距离越长，误差就会越大。 好在两种系统固有的优势结合在一起可以相互弥补劣势。\n\n  视觉和惯性追踪系统基于截然不同的测量系统，相互之间不存在依赖性。这意味着就算摄像头被遮挡或只能看到光学特征极为有限的场景（例如白色墙壁），惯性系统依然可以在少数几帧的范围内继续测量。或者设备可能处于静止状态，此时视觉系统可以提供比惯性系统更稳定的姿态检测。Kalman过滤器始终会选择最佳质量的姿态，进而实现最稳定的追踪。\n\n  ARKit的第二个主要功能是平面检测。正是因为有了这个功能，我们才有了用于放置内容的“表面”，否则所有内容只能悬浮在空间里。平面是由光学系统检测到的特征计算而来的（也就是演示里看到的那些小点），算法通过取平均值，即可用任意三个点定义一个平面，如果将这个操作执行多次，即可估算出现实中的平面到底在哪里。另外，这些点通常也被称之为“点云（Point cloud）”，这个概念也经常会被人混淆。所有这些点结合在一起可以形成一个稀疏点云，进而可用于光学追踪。通过稀疏点云进行追踪需要的内存和CPU运算量都比较少，同时辅以惯性系统的支持，光学系统即可在只需要很少量追踪点的情况下有效运作。\n\n  而SLAM是一个很宽泛的术语，类似我们说的“多媒体”。追踪这个词本身也是一个宽泛的称呼，如果使用“量距（Odometry）”就具体多了，但在AR方面这两个词实际上意思比较接近。这一点可能会让人混淆。SLAM的实现方法有很多，追踪仅仅是整个SLAM系统所包含的组件之一。其实ARKit可以看作一种轻量级的简单SLAM系统。\n\n  “如何通过一个镜头获得3D场景？”，以及“如何确定计量尺度（例如量尺的演示）？”。此处的秘诀在于以真正足够好的方式消除IMU误差（例如提高航位推算的猜测精确度）。做到这一点后，就可以:  \n\n  若要获得3D场景，只需从两个不同位置获得同一场景的两个视图，并对位置进行立体计算即可。我们的眼睛也是通过这种方式看到3D场景的，而这也是某些追踪系统需要使用双摄像头的原因。如果有两个摄像头，因为摄像头间距离已知，并且两帧画面是同时捕获的，此时计算工作将非常容易。如果只有一个摄像头，只需捕获一帧，移动少许位置，再捕获第二帧就行了。通过使用IMU航位推算，我们可以计算两帧画面移动的距离，随后照常进行立体计算（实际可以通过更多帧来计算，获得更精确的结果）。如果IMU足够精确，那么两帧之间哪怕为了保持手部固定产生的轻微肌肉活动导致的“移动”也可以顺利检测出来！这简直就是魔法。\n\n  为了确定计量尺度，系统也需要依赖IMU提供精确的航位推算。通过IMU提供的加速度和时间测量值，我们可以后向合并以计算速率，并再次合并回来以获得IMU帧之间的位移。计算过程并不难，难点在于消除IMU的误差以得到近乎完美的加速度测量值。任何微小的错误，如果每秒钟出现1000次，在移动手机的过程中持续数秒钟，最终都会累积造成30%甚至更高的尺度误差。Apple能将这个误差降低到个位数百分率，这真是让人佩服。\n\n#####  Tango、Hololens、Vuforia等产品又如何呢？\n  Tango其实是一个品牌，并不是某个具体的产品。其中包含了硬件参考设计（RGB、鱼眼、深度摄像头，以及某些CPU/GPU规格）和软件栈，可提供VIO（动作追踪）、Sparse Mapping（区域学习），以及Dense 3D重建（深度感知）等功能。\n\n  Hololens具备完全相同的软件栈，但还包含一些ASIC（被称之为Holographic Processing Unit，全息处理单元），借此分摊CPU/GPU的处理任务以降低能耗。  \n  Vuforia几乎也是相同的，但不依赖特定的硬件。\n\n  上述三种技术使用了相同的VIO系统（Tango和ARKit甚至使用了同一套最初由FlyBy开发的代码！）。Hololens和Tango都没有使用深度摄像头进行追踪（但可能觉得为了解决某些边缘案例，他们正在着手这样做）。那么为何ARKit的表现会这么好？\n\n  答案在于，ARKit其实并不比Hololens好到哪里去（甚至可以说Hololens的追踪系统是市面上最棒的），但Hololens硬件的普及率太低了。微软本应将Hololens的追踪系统包含在Windows智能手机中，但可能他们是出于商业方面的考虑并未这样做（例如可能导致成本增高，需要花时间对手机传感器进行校准，设备销量太小，而微软提供类似ARKit的方案并不足以将开发者从iOS/Android平台策反过来）。\n\n  过去一年多的时间里，Google本来也可以很轻松地将Tango的VIO系统包含在出货量巨大的Android手机中，但他们也没有这样做。如果当时真这么做了，反而会让ARKit成为“跟风者”，而非“引领者”。可能是因为每家OEM厂商不想自己分别进行繁琐的传感器校准，进而导致每个OEM版本的Tango实际使用效果各异，而对于设备出货量足够大，值得这么做的少数OEM厂商（三星、华为等），Google也并不希望过于讨好他们。因而他们等于在告诉OEM厂商：“硬件参考设计是这样的，用不用随意”。随着Android智能手机硬件逐渐变得商品化，摄像头和传感器已成为不同厂商差异性最主要的来源之一，OEM厂商们怎么可能为Google做嫁衣！Google还强制要求必须使用深度摄像头，这会导致厂商的手机物料成本（以及耗电量）大幅增加，这也成了OEM厂商拒绝的另一个原因。但随着ARKit的发布，情况截然不同了……\n\n  使得ARKit如此出色的主要原因依然在于，Apple可以承担这样做的成本，将VIO算法与传感器紧密集成，并投入大量时间进行校准以消除姿态计算过程中的误差/不确定性。\n\n  好了，上面简单介绍了对ARKit技术实现方式的理解，不过看起来第二种更可信，之后我会继续分享一些ARKit的实践。\n\n###### 参考文档　\n1. https://medium.com/super-ventures-blog/why-is-arkit-better-than-the-alternatives-af8871889d6a  \n2. https://developer.apple.com/documentation/arkit 官方API\n3. https://developer.apple.com/documentation/arkit/understanding_augmented_reality\n","source":"_posts/ARKit-startup.md","raw":"---\ntitle: ARKit入坑指南--技术实现分析  \ndate: 2017-06-28 01:16:11\ntype: ARKit\ntags:\n  ARKit\ncategories: iOS\n---\n\n### ARKit简介\n\n  iOS11发布了ARKit之后，iPhone瞬间变成了最大的AR平台。一直以来对这块都比较感兴趣，最近简单做了些研究，下面介绍下ARKit基础的一些概念，算是当作入坑路径吧。\n  ARKit是一种为iOS构建增强现实（AR，augmented reality）App的框架，意在实现将虚拟内容精确且真实地浸入真实世界场景上。ARKit的核心是为一些基本的关键功能提供支持，包括运动跟踪、水平面检测，以及尺度和环境光预测。\n  有些人认为ARKit是一种SLAM实现，也有人认为是VIO。下面分别简单介绍下对ARKit的技术实现方式的不同理解。\n\n#### 1.Slam的概念  \n\n  SLAM，全称叫做Simultaneous Localization and Mapping，中文叫做同时定位与建图。就是通过传感器获取环境的有限信息，比如视觉信息、深度信息、自身的加速度和角速度等来确定自己的相对或者绝对位置，并完成对于地图的构建。简单点可以说是一个传感器在不停的运动，还在实时的扫描着周围的地形。\n  与其说SLAM是一种技术，不如说是一种概念，SLAM可通过多种方法实现。\n\n  要实现SLAM，最基础就是传感器，目前传感器分为激光和VSLAM两大类。激光雷达由于精度高、速度快，能方便地实现SLAM功能而被研究得最多，主要用于机器人及无人车（机）领域，但缺点就是价格昂贵。   \n  而VSLAM则主要用摄像头来实现，摄像头品种繁多，主要分为单目、双目（或多目）、RGBD。实现难度正序：单目视觉>双目视觉>RGBD。  单目视觉因为基于一个摄像头，在深度感知上存在问题，无法得到机器人的运动轨迹及地图的真实大小，但这也使得单目SLAM不受环境大小的影响，既可用于室内，又可用于室外。\n\n  目前，SLAM技术的实现途径主要包括VSLAM、Wifi-SLAM与Lidar SLAM。\n\n  <!--more-->\n##### VSLAM (视觉SLAM)  \n\n  指在室内环境下，用摄像机、Kinect等深度相机来做导航和探索。其工作原理简单来说就是对机器人周边的环境进行光学处理，先用摄像头进行图像信息采集，将采集的信息进行压缩，然后将它反馈到一个由神经网络和统计学方法构成的学习子系统，再由学习子系统将采集到的图像信息和机器人的实际位置联系起来，完成机器人的自主导航定位功能。  \n  但是，室内的VSLAM仍处于研究阶段，远未到实际应用的程度。一方面，计算量太大，对机器人系统的性能要求较高；另一方面，VSLAM生成的地图（多数是点云）还不能用来做机器人的路径规划，需要进一步探索和研究。\n\n##### Wifi-SLAM\n\n  这项技术主要作用是室内定位，指利用智能手机中的多种传感设备进行定位，包括Wifi、GPS、陀螺仪、加速计和磁力计，并通过机器学**和模式识别等算法将获得的数据绘制出准确的室内地图。\n\n  该技术的提供商已于2013年被苹果公司收购，苹果公司是否已经把 Wifi-SLAM 的科技用到iPhone上，使所有 iPhone 用户相当于携带了一个绘图小机器人，这一切暂未可知。毋庸置疑的是，更精准的定位不仅有利于地图，它会让所有依赖地理位置的应用（LBS) 更加精准。\n\n##### Lidar SLAM\n\n  指利用激光雷达作为传感器，获取地图数据，使机器人实现同步定位与地图构建。该技术是目前最稳定、最可靠、高性能的SLAM方式。就技术本身而言，经过多年验证，已相当成熟，但Lidar成本昂贵这一瓶颈问题亟待解决。  \n  Google无人驾驶汽车正是采用该项技术，车顶安装的激光雷达来自美国Velodyne公司，售价高达7万美元以上。  \n  这款激光雷达可以在高速旋转时向周围发射64束激光，激光碰到周围物体并返回，便可计算出车体与周边物体的距离。  \n  计算机系统再根据这些数据描绘出精细的3D地形图，然后与高分辨率地图相结合，生成不同的数据模型供车载计算机系统使用。激光雷达占去了整车成本的一半，这可能也是 Google 无人车迟迟无法量产的原因之一。  \n  对于 AR/VR 使用场景的室内空间定位，我们可以通过蓝牙，路由器等建立标准点，或者通过红外线进行室内扫描来进行判定。但是一旦将室内定位与 VR 联系起来，就无法通过其它设备进行辅助了。目前我们已经能通过 Oculus 和 HTC Vive 的摄像头和「base station」做到进行小范围内的室内定位，但在移动 VR 领域里，空间定位一直是难题，目前还没有任何一个消费者级移动 VR 设备能够做到空间移动。\n\n#### 2. VIO系统  \n\n  另一种理解是，从技术角度说，ARKit是一种具备简单2D平面检测（Plane detection）能力的视觉惯性里程计（Visual Inertial Odometry，VIO）系统。VIO意味着可以通过软件实时追踪用户在空间中的位置（用户的6dof姿态），例如在屏幕每刷新一帧的过程中重新计算用户姿态，这种操作每秒钟大约进行30次或更高频率。这种计算工作会并行进行两次。用户姿态可通过视觉（摄像头）系统进行追踪，为此需要将现实世界中的点与相机传感器拍摄的每一帧画面上的一个像素进行匹配。此外还需要通过惯性系统（加速计和陀螺仪，统称为惯性测量装置[Inertial Measurement Unit]，即IMU）追踪用户姿态。随后这些系统的输出结果会通过Kalman Filter合并，进而确定其中哪个系统能对用户的“实际”位置（也叫做地表实况[Ground Truth]）提供最佳估测，并通过ARKit SDK发布位置更新。与汽车中统计行驶距离的里程表类似，VIO系统会追踪iPhone在6D空间中的移动距离，6D代表3D世界中的xyz移动（转换），外加俯仰（Pitch）/偏航（Yaw）/翻滚（Roll）的3D移动（旋转）。\n\n  ![AR_6dof](http://ojca2gwha.bkt.clouddn.com/AR_6DOF.jpg)\n\n  VIO最大的优势在于，IMU的读数每秒可更新大约1000次，其数值完全基于加速度（用户的移动）。以往主要使用航位推算（Dead Reckoning）技术测量设备在两个IMU读数之间的移动，但这种技术只能进行猜测，就比如我让你迈出一步，随后猜测你的一步有多长距离一样，此时只能用航位推算技术来估测距离。\n  惯性系统的误差会逐渐累积，因此两个IMU帧之间的时间间隔越长，或者惯性系统不通过视觉系统进行“重置”一直使用的时间越长，追踪结果与地表实况之间的误差就越大。视觉/光学测量的频率可与摄像头的帧率保持一致，通常为30fps，并且完全基于距离（两个帧之间的场景变化）。光学系统的误差通常会随着距离而累积（时间的影响反而比较小），因此移动的距离越长，误差就会越大。 好在两种系统固有的优势结合在一起可以相互弥补劣势。\n\n  视觉和惯性追踪系统基于截然不同的测量系统，相互之间不存在依赖性。这意味着就算摄像头被遮挡或只能看到光学特征极为有限的场景（例如白色墙壁），惯性系统依然可以在少数几帧的范围内继续测量。或者设备可能处于静止状态，此时视觉系统可以提供比惯性系统更稳定的姿态检测。Kalman过滤器始终会选择最佳质量的姿态，进而实现最稳定的追踪。\n\n  ARKit的第二个主要功能是平面检测。正是因为有了这个功能，我们才有了用于放置内容的“表面”，否则所有内容只能悬浮在空间里。平面是由光学系统检测到的特征计算而来的（也就是演示里看到的那些小点），算法通过取平均值，即可用任意三个点定义一个平面，如果将这个操作执行多次，即可估算出现实中的平面到底在哪里。另外，这些点通常也被称之为“点云（Point cloud）”，这个概念也经常会被人混淆。所有这些点结合在一起可以形成一个稀疏点云，进而可用于光学追踪。通过稀疏点云进行追踪需要的内存和CPU运算量都比较少，同时辅以惯性系统的支持，光学系统即可在只需要很少量追踪点的情况下有效运作。\n\n  而SLAM是一个很宽泛的术语，类似我们说的“多媒体”。追踪这个词本身也是一个宽泛的称呼，如果使用“量距（Odometry）”就具体多了，但在AR方面这两个词实际上意思比较接近。这一点可能会让人混淆。SLAM的实现方法有很多，追踪仅仅是整个SLAM系统所包含的组件之一。其实ARKit可以看作一种轻量级的简单SLAM系统。\n\n  “如何通过一个镜头获得3D场景？”，以及“如何确定计量尺度（例如量尺的演示）？”。此处的秘诀在于以真正足够好的方式消除IMU误差（例如提高航位推算的猜测精确度）。做到这一点后，就可以:  \n\n  若要获得3D场景，只需从两个不同位置获得同一场景的两个视图，并对位置进行立体计算即可。我们的眼睛也是通过这种方式看到3D场景的，而这也是某些追踪系统需要使用双摄像头的原因。如果有两个摄像头，因为摄像头间距离已知，并且两帧画面是同时捕获的，此时计算工作将非常容易。如果只有一个摄像头，只需捕获一帧，移动少许位置，再捕获第二帧就行了。通过使用IMU航位推算，我们可以计算两帧画面移动的距离，随后照常进行立体计算（实际可以通过更多帧来计算，获得更精确的结果）。如果IMU足够精确，那么两帧之间哪怕为了保持手部固定产生的轻微肌肉活动导致的“移动”也可以顺利检测出来！这简直就是魔法。\n\n  为了确定计量尺度，系统也需要依赖IMU提供精确的航位推算。通过IMU提供的加速度和时间测量值，我们可以后向合并以计算速率，并再次合并回来以获得IMU帧之间的位移。计算过程并不难，难点在于消除IMU的误差以得到近乎完美的加速度测量值。任何微小的错误，如果每秒钟出现1000次，在移动手机的过程中持续数秒钟，最终都会累积造成30%甚至更高的尺度误差。Apple能将这个误差降低到个位数百分率，这真是让人佩服。\n\n#####  Tango、Hololens、Vuforia等产品又如何呢？\n  Tango其实是一个品牌，并不是某个具体的产品。其中包含了硬件参考设计（RGB、鱼眼、深度摄像头，以及某些CPU/GPU规格）和软件栈，可提供VIO（动作追踪）、Sparse Mapping（区域学习），以及Dense 3D重建（深度感知）等功能。\n\n  Hololens具备完全相同的软件栈，但还包含一些ASIC（被称之为Holographic Processing Unit，全息处理单元），借此分摊CPU/GPU的处理任务以降低能耗。  \n  Vuforia几乎也是相同的，但不依赖特定的硬件。\n\n  上述三种技术使用了相同的VIO系统（Tango和ARKit甚至使用了同一套最初由FlyBy开发的代码！）。Hololens和Tango都没有使用深度摄像头进行追踪（但可能觉得为了解决某些边缘案例，他们正在着手这样做）。那么为何ARKit的表现会这么好？\n\n  答案在于，ARKit其实并不比Hololens好到哪里去（甚至可以说Hololens的追踪系统是市面上最棒的），但Hololens硬件的普及率太低了。微软本应将Hololens的追踪系统包含在Windows智能手机中，但可能他们是出于商业方面的考虑并未这样做（例如可能导致成本增高，需要花时间对手机传感器进行校准，设备销量太小，而微软提供类似ARKit的方案并不足以将开发者从iOS/Android平台策反过来）。\n\n  过去一年多的时间里，Google本来也可以很轻松地将Tango的VIO系统包含在出货量巨大的Android手机中，但他们也没有这样做。如果当时真这么做了，反而会让ARKit成为“跟风者”，而非“引领者”。可能是因为每家OEM厂商不想自己分别进行繁琐的传感器校准，进而导致每个OEM版本的Tango实际使用效果各异，而对于设备出货量足够大，值得这么做的少数OEM厂商（三星、华为等），Google也并不希望过于讨好他们。因而他们等于在告诉OEM厂商：“硬件参考设计是这样的，用不用随意”。随着Android智能手机硬件逐渐变得商品化，摄像头和传感器已成为不同厂商差异性最主要的来源之一，OEM厂商们怎么可能为Google做嫁衣！Google还强制要求必须使用深度摄像头，这会导致厂商的手机物料成本（以及耗电量）大幅增加，这也成了OEM厂商拒绝的另一个原因。但随着ARKit的发布，情况截然不同了……\n\n  使得ARKit如此出色的主要原因依然在于，Apple可以承担这样做的成本，将VIO算法与传感器紧密集成，并投入大量时间进行校准以消除姿态计算过程中的误差/不确定性。\n\n  好了，上面简单介绍了对ARKit技术实现方式的理解，不过看起来第二种更可信，之后我会继续分享一些ARKit的实践。\n\n###### 参考文档　\n1. https://medium.com/super-ventures-blog/why-is-arkit-better-than-the-alternatives-af8871889d6a  \n2. https://developer.apple.com/documentation/arkit 官方API\n3. https://developer.apple.com/documentation/arkit/understanding_augmented_reality\n","slug":"ARKit-startup","published":1,"updated":"2017-09-25T12:08:05.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj81l545n0009wluvq2avjh7x","content":"<h3 id=\"ARKit简介\"><a href=\"#ARKit简介\" class=\"headerlink\" title=\"ARKit简介\"></a>ARKit简介</h3><p>  iOS11发布了ARKit之后，iPhone瞬间变成了最大的AR平台。一直以来对这块都比较感兴趣，最近简单做了些研究，下面介绍下ARKit基础的一些概念，算是当作入坑路径吧。<br>  ARKit是一种为iOS构建增强现实（AR，augmented reality）App的框架，意在实现将虚拟内容精确且真实地浸入真实世界场景上。ARKit的核心是为一些基本的关键功能提供支持，包括运动跟踪、水平面检测，以及尺度和环境光预测。<br>  有些人认为ARKit是一种SLAM实现，也有人认为是VIO。下面分别简单介绍下对ARKit的技术实现方式的不同理解。</p>\n<h4 id=\"1-Slam的概念\"><a href=\"#1-Slam的概念\" class=\"headerlink\" title=\"1.Slam的概念\"></a>1.Slam的概念</h4><p>  SLAM，全称叫做Simultaneous Localization and Mapping，中文叫做同时定位与建图。就是通过传感器获取环境的有限信息，比如视觉信息、深度信息、自身的加速度和角速度等来确定自己的相对或者绝对位置，并完成对于地图的构建。简单点可以说是一个传感器在不停的运动，还在实时的扫描着周围的地形。<br>  与其说SLAM是一种技术，不如说是一种概念，SLAM可通过多种方法实现。</p>\n<p>  要实现SLAM，最基础就是传感器，目前传感器分为激光和VSLAM两大类。激光雷达由于精度高、速度快，能方便地实现SLAM功能而被研究得最多，主要用于机器人及无人车（机）领域，但缺点就是价格昂贵。<br>  而VSLAM则主要用摄像头来实现，摄像头品种繁多，主要分为单目、双目（或多目）、RGBD。实现难度正序：单目视觉&gt;双目视觉&gt;RGBD。  单目视觉因为基于一个摄像头，在深度感知上存在问题，无法得到机器人的运动轨迹及地图的真实大小，但这也使得单目SLAM不受环境大小的影响，既可用于室内，又可用于室外。</p>\n<p>  目前，SLAM技术的实现途径主要包括VSLAM、Wifi-SLAM与Lidar SLAM。</p>\n  <a id=\"more\"></a>\n<h5 id=\"VSLAM-视觉SLAM\"><a href=\"#VSLAM-视觉SLAM\" class=\"headerlink\" title=\"VSLAM (视觉SLAM)\"></a>VSLAM (视觉SLAM)</h5><p>  指在室内环境下，用摄像机、Kinect等深度相机来做导航和探索。其工作原理简单来说就是对机器人周边的环境进行光学处理，先用摄像头进行图像信息采集，将采集的信息进行压缩，然后将它反馈到一个由神经网络和统计学方法构成的学习子系统，再由学习子系统将采集到的图像信息和机器人的实际位置联系起来，完成机器人的自主导航定位功能。<br>  但是，室内的VSLAM仍处于研究阶段，远未到实际应用的程度。一方面，计算量太大，对机器人系统的性能要求较高；另一方面，VSLAM生成的地图（多数是点云）还不能用来做机器人的路径规划，需要进一步探索和研究。</p>\n<h5 id=\"Wifi-SLAM\"><a href=\"#Wifi-SLAM\" class=\"headerlink\" title=\"Wifi-SLAM\"></a>Wifi-SLAM</h5><p>  这项技术主要作用是室内定位，指利用智能手机中的多种传感设备进行定位，包括Wifi、GPS、陀螺仪、加速计和磁力计，并通过机器学**和模式识别等算法将获得的数据绘制出准确的室内地图。</p>\n<p>  该技术的提供商已于2013年被苹果公司收购，苹果公司是否已经把 Wifi-SLAM 的科技用到iPhone上，使所有 iPhone 用户相当于携带了一个绘图小机器人，这一切暂未可知。毋庸置疑的是，更精准的定位不仅有利于地图，它会让所有依赖地理位置的应用（LBS) 更加精准。</p>\n<h5 id=\"Lidar-SLAM\"><a href=\"#Lidar-SLAM\" class=\"headerlink\" title=\"Lidar SLAM\"></a>Lidar SLAM</h5><p>  指利用激光雷达作为传感器，获取地图数据，使机器人实现同步定位与地图构建。该技术是目前最稳定、最可靠、高性能的SLAM方式。就技术本身而言，经过多年验证，已相当成熟，但Lidar成本昂贵这一瓶颈问题亟待解决。<br>  Google无人驾驶汽车正是采用该项技术，车顶安装的激光雷达来自美国Velodyne公司，售价高达7万美元以上。<br>  这款激光雷达可以在高速旋转时向周围发射64束激光，激光碰到周围物体并返回，便可计算出车体与周边物体的距离。<br>  计算机系统再根据这些数据描绘出精细的3D地形图，然后与高分辨率地图相结合，生成不同的数据模型供车载计算机系统使用。激光雷达占去了整车成本的一半，这可能也是 Google 无人车迟迟无法量产的原因之一。<br>  对于 AR/VR 使用场景的室内空间定位，我们可以通过蓝牙，路由器等建立标准点，或者通过红外线进行室内扫描来进行判定。但是一旦将室内定位与 VR 联系起来，就无法通过其它设备进行辅助了。目前我们已经能通过 Oculus 和 HTC Vive 的摄像头和「base station」做到进行小范围内的室内定位，但在移动 VR 领域里，空间定位一直是难题，目前还没有任何一个消费者级移动 VR 设备能够做到空间移动。</p>\n<h4 id=\"2-VIO系统\"><a href=\"#2-VIO系统\" class=\"headerlink\" title=\"2. VIO系统\"></a>2. VIO系统</h4><p>  另一种理解是，从技术角度说，ARKit是一种具备简单2D平面检测（Plane detection）能力的视觉惯性里程计（Visual Inertial Odometry，VIO）系统。VIO意味着可以通过软件实时追踪用户在空间中的位置（用户的6dof姿态），例如在屏幕每刷新一帧的过程中重新计算用户姿态，这种操作每秒钟大约进行30次或更高频率。这种计算工作会并行进行两次。用户姿态可通过视觉（摄像头）系统进行追踪，为此需要将现实世界中的点与相机传感器拍摄的每一帧画面上的一个像素进行匹配。此外还需要通过惯性系统（加速计和陀螺仪，统称为惯性测量装置[Inertial Measurement Unit]，即IMU）追踪用户姿态。随后这些系统的输出结果会通过Kalman Filter合并，进而确定其中哪个系统能对用户的“实际”位置（也叫做地表实况[Ground Truth]）提供最佳估测，并通过ARKit SDK发布位置更新。与汽车中统计行驶距离的里程表类似，VIO系统会追踪iPhone在6D空间中的移动距离，6D代表3D世界中的xyz移动（转换），外加俯仰（Pitch）/偏航（Yaw）/翻滚（Roll）的3D移动（旋转）。</p>\n<p>  <img src=\"http://ojca2gwha.bkt.clouddn.com/AR_6DOF.jpg\" alt=\"AR_6dof\"></p>\n<p>  VIO最大的优势在于，IMU的读数每秒可更新大约1000次，其数值完全基于加速度（用户的移动）。以往主要使用航位推算（Dead Reckoning）技术测量设备在两个IMU读数之间的移动，但这种技术只能进行猜测，就比如我让你迈出一步，随后猜测你的一步有多长距离一样，此时只能用航位推算技术来估测距离。<br>  惯性系统的误差会逐渐累积，因此两个IMU帧之间的时间间隔越长，或者惯性系统不通过视觉系统进行“重置”一直使用的时间越长，追踪结果与地表实况之间的误差就越大。视觉/光学测量的频率可与摄像头的帧率保持一致，通常为30fps，并且完全基于距离（两个帧之间的场景变化）。光学系统的误差通常会随着距离而累积（时间的影响反而比较小），因此移动的距离越长，误差就会越大。 好在两种系统固有的优势结合在一起可以相互弥补劣势。</p>\n<p>  视觉和惯性追踪系统基于截然不同的测量系统，相互之间不存在依赖性。这意味着就算摄像头被遮挡或只能看到光学特征极为有限的场景（例如白色墙壁），惯性系统依然可以在少数几帧的范围内继续测量。或者设备可能处于静止状态，此时视觉系统可以提供比惯性系统更稳定的姿态检测。Kalman过滤器始终会选择最佳质量的姿态，进而实现最稳定的追踪。</p>\n<p>  ARKit的第二个主要功能是平面检测。正是因为有了这个功能，我们才有了用于放置内容的“表面”，否则所有内容只能悬浮在空间里。平面是由光学系统检测到的特征计算而来的（也就是演示里看到的那些小点），算法通过取平均值，即可用任意三个点定义一个平面，如果将这个操作执行多次，即可估算出现实中的平面到底在哪里。另外，这些点通常也被称之为“点云（Point cloud）”，这个概念也经常会被人混淆。所有这些点结合在一起可以形成一个稀疏点云，进而可用于光学追踪。通过稀疏点云进行追踪需要的内存和CPU运算量都比较少，同时辅以惯性系统的支持，光学系统即可在只需要很少量追踪点的情况下有效运作。</p>\n<p>  而SLAM是一个很宽泛的术语，类似我们说的“多媒体”。追踪这个词本身也是一个宽泛的称呼，如果使用“量距（Odometry）”就具体多了，但在AR方面这两个词实际上意思比较接近。这一点可能会让人混淆。SLAM的实现方法有很多，追踪仅仅是整个SLAM系统所包含的组件之一。其实ARKit可以看作一种轻量级的简单SLAM系统。</p>\n<p>  “如何通过一个镜头获得3D场景？”，以及“如何确定计量尺度（例如量尺的演示）？”。此处的秘诀在于以真正足够好的方式消除IMU误差（例如提高航位推算的猜测精确度）。做到这一点后，就可以:  </p>\n<p>  若要获得3D场景，只需从两个不同位置获得同一场景的两个视图，并对位置进行立体计算即可。我们的眼睛也是通过这种方式看到3D场景的，而这也是某些追踪系统需要使用双摄像头的原因。如果有两个摄像头，因为摄像头间距离已知，并且两帧画面是同时捕获的，此时计算工作将非常容易。如果只有一个摄像头，只需捕获一帧，移动少许位置，再捕获第二帧就行了。通过使用IMU航位推算，我们可以计算两帧画面移动的距离，随后照常进行立体计算（实际可以通过更多帧来计算，获得更精确的结果）。如果IMU足够精确，那么两帧之间哪怕为了保持手部固定产生的轻微肌肉活动导致的“移动”也可以顺利检测出来！这简直就是魔法。</p>\n<p>  为了确定计量尺度，系统也需要依赖IMU提供精确的航位推算。通过IMU提供的加速度和时间测量值，我们可以后向合并以计算速率，并再次合并回来以获得IMU帧之间的位移。计算过程并不难，难点在于消除IMU的误差以得到近乎完美的加速度测量值。任何微小的错误，如果每秒钟出现1000次，在移动手机的过程中持续数秒钟，最终都会累积造成30%甚至更高的尺度误差。Apple能将这个误差降低到个位数百分率，这真是让人佩服。</p>\n<h5 id=\"Tango、Hololens、Vuforia等产品又如何呢？\"><a href=\"#Tango、Hololens、Vuforia等产品又如何呢？\" class=\"headerlink\" title=\"Tango、Hololens、Vuforia等产品又如何呢？\"></a>Tango、Hololens、Vuforia等产品又如何呢？</h5><p>  Tango其实是一个品牌，并不是某个具体的产品。其中包含了硬件参考设计（RGB、鱼眼、深度摄像头，以及某些CPU/GPU规格）和软件栈，可提供VIO（动作追踪）、Sparse Mapping（区域学习），以及Dense 3D重建（深度感知）等功能。</p>\n<p>  Hololens具备完全相同的软件栈，但还包含一些ASIC（被称之为Holographic Processing Unit，全息处理单元），借此分摊CPU/GPU的处理任务以降低能耗。<br>  Vuforia几乎也是相同的，但不依赖特定的硬件。</p>\n<p>  上述三种技术使用了相同的VIO系统（Tango和ARKit甚至使用了同一套最初由FlyBy开发的代码！）。Hololens和Tango都没有使用深度摄像头进行追踪（但可能觉得为了解决某些边缘案例，他们正在着手这样做）。那么为何ARKit的表现会这么好？</p>\n<p>  答案在于，ARKit其实并不比Hololens好到哪里去（甚至可以说Hololens的追踪系统是市面上最棒的），但Hololens硬件的普及率太低了。微软本应将Hololens的追踪系统包含在Windows智能手机中，但可能他们是出于商业方面的考虑并未这样做（例如可能导致成本增高，需要花时间对手机传感器进行校准，设备销量太小，而微软提供类似ARKit的方案并不足以将开发者从iOS/Android平台策反过来）。</p>\n<p>  过去一年多的时间里，Google本来也可以很轻松地将Tango的VIO系统包含在出货量巨大的Android手机中，但他们也没有这样做。如果当时真这么做了，反而会让ARKit成为“跟风者”，而非“引领者”。可能是因为每家OEM厂商不想自己分别进行繁琐的传感器校准，进而导致每个OEM版本的Tango实际使用效果各异，而对于设备出货量足够大，值得这么做的少数OEM厂商（三星、华为等），Google也并不希望过于讨好他们。因而他们等于在告诉OEM厂商：“硬件参考设计是这样的，用不用随意”。随着Android智能手机硬件逐渐变得商品化，摄像头和传感器已成为不同厂商差异性最主要的来源之一，OEM厂商们怎么可能为Google做嫁衣！Google还强制要求必须使用深度摄像头，这会导致厂商的手机物料成本（以及耗电量）大幅增加，这也成了OEM厂商拒绝的另一个原因。但随着ARKit的发布，情况截然不同了……</p>\n<p>  使得ARKit如此出色的主要原因依然在于，Apple可以承担这样做的成本，将VIO算法与传感器紧密集成，并投入大量时间进行校准以消除姿态计算过程中的误差/不确定性。</p>\n<p>  好了，上面简单介绍了对ARKit技术实现方式的理解，不过看起来第二种更可信，之后我会继续分享一些ARKit的实践。</p>\n<h6 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档　\"></a>参考文档　</h6><ol>\n<li><a href=\"https://medium.com/super-ventures-blog/why-is-arkit-better-than-the-alternatives-af8871889d6a\" target=\"_blank\" rel=\"external\">https://medium.com/super-ventures-blog/why-is-arkit-better-than-the-alternatives-af8871889d6a</a>  </li>\n<li><a href=\"https://developer.apple.com/documentation/arkit\" target=\"_blank\" rel=\"external\">https://developer.apple.com/documentation/arkit</a> 官方API</li>\n<li><a href=\"https://developer.apple.com/documentation/arkit/understanding_augmented_reality\" target=\"_blank\" rel=\"external\">https://developer.apple.com/documentation/arkit/understanding_augmented_reality</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<h3 id=\"ARKit简介\"><a href=\"#ARKit简介\" class=\"headerlink\" title=\"ARKit简介\"></a>ARKit简介</h3><p>  iOS11发布了ARKit之后，iPhone瞬间变成了最大的AR平台。一直以来对这块都比较感兴趣，最近简单做了些研究，下面介绍下ARKit基础的一些概念，算是当作入坑路径吧。<br>  ARKit是一种为iOS构建增强现实（AR，augmented reality）App的框架，意在实现将虚拟内容精确且真实地浸入真实世界场景上。ARKit的核心是为一些基本的关键功能提供支持，包括运动跟踪、水平面检测，以及尺度和环境光预测。<br>  有些人认为ARKit是一种SLAM实现，也有人认为是VIO。下面分别简单介绍下对ARKit的技术实现方式的不同理解。</p>\n<h4 id=\"1-Slam的概念\"><a href=\"#1-Slam的概念\" class=\"headerlink\" title=\"1.Slam的概念\"></a>1.Slam的概念</h4><p>  SLAM，全称叫做Simultaneous Localization and Mapping，中文叫做同时定位与建图。就是通过传感器获取环境的有限信息，比如视觉信息、深度信息、自身的加速度和角速度等来确定自己的相对或者绝对位置，并完成对于地图的构建。简单点可以说是一个传感器在不停的运动，还在实时的扫描着周围的地形。<br>  与其说SLAM是一种技术，不如说是一种概念，SLAM可通过多种方法实现。</p>\n<p>  要实现SLAM，最基础就是传感器，目前传感器分为激光和VSLAM两大类。激光雷达由于精度高、速度快，能方便地实现SLAM功能而被研究得最多，主要用于机器人及无人车（机）领域，但缺点就是价格昂贵。<br>  而VSLAM则主要用摄像头来实现，摄像头品种繁多，主要分为单目、双目（或多目）、RGBD。实现难度正序：单目视觉&gt;双目视觉&gt;RGBD。  单目视觉因为基于一个摄像头，在深度感知上存在问题，无法得到机器人的运动轨迹及地图的真实大小，但这也使得单目SLAM不受环境大小的影响，既可用于室内，又可用于室外。</p>\n<p>  目前，SLAM技术的实现途径主要包括VSLAM、Wifi-SLAM与Lidar SLAM。</p>","more":"<h5 id=\"VSLAM-视觉SLAM\"><a href=\"#VSLAM-视觉SLAM\" class=\"headerlink\" title=\"VSLAM (视觉SLAM)\"></a>VSLAM (视觉SLAM)</h5><p>  指在室内环境下，用摄像机、Kinect等深度相机来做导航和探索。其工作原理简单来说就是对机器人周边的环境进行光学处理，先用摄像头进行图像信息采集，将采集的信息进行压缩，然后将它反馈到一个由神经网络和统计学方法构成的学习子系统，再由学习子系统将采集到的图像信息和机器人的实际位置联系起来，完成机器人的自主导航定位功能。<br>  但是，室内的VSLAM仍处于研究阶段，远未到实际应用的程度。一方面，计算量太大，对机器人系统的性能要求较高；另一方面，VSLAM生成的地图（多数是点云）还不能用来做机器人的路径规划，需要进一步探索和研究。</p>\n<h5 id=\"Wifi-SLAM\"><a href=\"#Wifi-SLAM\" class=\"headerlink\" title=\"Wifi-SLAM\"></a>Wifi-SLAM</h5><p>  这项技术主要作用是室内定位，指利用智能手机中的多种传感设备进行定位，包括Wifi、GPS、陀螺仪、加速计和磁力计，并通过机器学**和模式识别等算法将获得的数据绘制出准确的室内地图。</p>\n<p>  该技术的提供商已于2013年被苹果公司收购，苹果公司是否已经把 Wifi-SLAM 的科技用到iPhone上，使所有 iPhone 用户相当于携带了一个绘图小机器人，这一切暂未可知。毋庸置疑的是，更精准的定位不仅有利于地图，它会让所有依赖地理位置的应用（LBS) 更加精准。</p>\n<h5 id=\"Lidar-SLAM\"><a href=\"#Lidar-SLAM\" class=\"headerlink\" title=\"Lidar SLAM\"></a>Lidar SLAM</h5><p>  指利用激光雷达作为传感器，获取地图数据，使机器人实现同步定位与地图构建。该技术是目前最稳定、最可靠、高性能的SLAM方式。就技术本身而言，经过多年验证，已相当成熟，但Lidar成本昂贵这一瓶颈问题亟待解决。<br>  Google无人驾驶汽车正是采用该项技术，车顶安装的激光雷达来自美国Velodyne公司，售价高达7万美元以上。<br>  这款激光雷达可以在高速旋转时向周围发射64束激光，激光碰到周围物体并返回，便可计算出车体与周边物体的距离。<br>  计算机系统再根据这些数据描绘出精细的3D地形图，然后与高分辨率地图相结合，生成不同的数据模型供车载计算机系统使用。激光雷达占去了整车成本的一半，这可能也是 Google 无人车迟迟无法量产的原因之一。<br>  对于 AR/VR 使用场景的室内空间定位，我们可以通过蓝牙，路由器等建立标准点，或者通过红外线进行室内扫描来进行判定。但是一旦将室内定位与 VR 联系起来，就无法通过其它设备进行辅助了。目前我们已经能通过 Oculus 和 HTC Vive 的摄像头和「base station」做到进行小范围内的室内定位，但在移动 VR 领域里，空间定位一直是难题，目前还没有任何一个消费者级移动 VR 设备能够做到空间移动。</p>\n<h4 id=\"2-VIO系统\"><a href=\"#2-VIO系统\" class=\"headerlink\" title=\"2. VIO系统\"></a>2. VIO系统</h4><p>  另一种理解是，从技术角度说，ARKit是一种具备简单2D平面检测（Plane detection）能力的视觉惯性里程计（Visual Inertial Odometry，VIO）系统。VIO意味着可以通过软件实时追踪用户在空间中的位置（用户的6dof姿态），例如在屏幕每刷新一帧的过程中重新计算用户姿态，这种操作每秒钟大约进行30次或更高频率。这种计算工作会并行进行两次。用户姿态可通过视觉（摄像头）系统进行追踪，为此需要将现实世界中的点与相机传感器拍摄的每一帧画面上的一个像素进行匹配。此外还需要通过惯性系统（加速计和陀螺仪，统称为惯性测量装置[Inertial Measurement Unit]，即IMU）追踪用户姿态。随后这些系统的输出结果会通过Kalman Filter合并，进而确定其中哪个系统能对用户的“实际”位置（也叫做地表实况[Ground Truth]）提供最佳估测，并通过ARKit SDK发布位置更新。与汽车中统计行驶距离的里程表类似，VIO系统会追踪iPhone在6D空间中的移动距离，6D代表3D世界中的xyz移动（转换），外加俯仰（Pitch）/偏航（Yaw）/翻滚（Roll）的3D移动（旋转）。</p>\n<p>  <img src=\"http://ojca2gwha.bkt.clouddn.com/AR_6DOF.jpg\" alt=\"AR_6dof\"></p>\n<p>  VIO最大的优势在于，IMU的读数每秒可更新大约1000次，其数值完全基于加速度（用户的移动）。以往主要使用航位推算（Dead Reckoning）技术测量设备在两个IMU读数之间的移动，但这种技术只能进行猜测，就比如我让你迈出一步，随后猜测你的一步有多长距离一样，此时只能用航位推算技术来估测距离。<br>  惯性系统的误差会逐渐累积，因此两个IMU帧之间的时间间隔越长，或者惯性系统不通过视觉系统进行“重置”一直使用的时间越长，追踪结果与地表实况之间的误差就越大。视觉/光学测量的频率可与摄像头的帧率保持一致，通常为30fps，并且完全基于距离（两个帧之间的场景变化）。光学系统的误差通常会随着距离而累积（时间的影响反而比较小），因此移动的距离越长，误差就会越大。 好在两种系统固有的优势结合在一起可以相互弥补劣势。</p>\n<p>  视觉和惯性追踪系统基于截然不同的测量系统，相互之间不存在依赖性。这意味着就算摄像头被遮挡或只能看到光学特征极为有限的场景（例如白色墙壁），惯性系统依然可以在少数几帧的范围内继续测量。或者设备可能处于静止状态，此时视觉系统可以提供比惯性系统更稳定的姿态检测。Kalman过滤器始终会选择最佳质量的姿态，进而实现最稳定的追踪。</p>\n<p>  ARKit的第二个主要功能是平面检测。正是因为有了这个功能，我们才有了用于放置内容的“表面”，否则所有内容只能悬浮在空间里。平面是由光学系统检测到的特征计算而来的（也就是演示里看到的那些小点），算法通过取平均值，即可用任意三个点定义一个平面，如果将这个操作执行多次，即可估算出现实中的平面到底在哪里。另外，这些点通常也被称之为“点云（Point cloud）”，这个概念也经常会被人混淆。所有这些点结合在一起可以形成一个稀疏点云，进而可用于光学追踪。通过稀疏点云进行追踪需要的内存和CPU运算量都比较少，同时辅以惯性系统的支持，光学系统即可在只需要很少量追踪点的情况下有效运作。</p>\n<p>  而SLAM是一个很宽泛的术语，类似我们说的“多媒体”。追踪这个词本身也是一个宽泛的称呼，如果使用“量距（Odometry）”就具体多了，但在AR方面这两个词实际上意思比较接近。这一点可能会让人混淆。SLAM的实现方法有很多，追踪仅仅是整个SLAM系统所包含的组件之一。其实ARKit可以看作一种轻量级的简单SLAM系统。</p>\n<p>  “如何通过一个镜头获得3D场景？”，以及“如何确定计量尺度（例如量尺的演示）？”。此处的秘诀在于以真正足够好的方式消除IMU误差（例如提高航位推算的猜测精确度）。做到这一点后，就可以:  </p>\n<p>  若要获得3D场景，只需从两个不同位置获得同一场景的两个视图，并对位置进行立体计算即可。我们的眼睛也是通过这种方式看到3D场景的，而这也是某些追踪系统需要使用双摄像头的原因。如果有两个摄像头，因为摄像头间距离已知，并且两帧画面是同时捕获的，此时计算工作将非常容易。如果只有一个摄像头，只需捕获一帧，移动少许位置，再捕获第二帧就行了。通过使用IMU航位推算，我们可以计算两帧画面移动的距离，随后照常进行立体计算（实际可以通过更多帧来计算，获得更精确的结果）。如果IMU足够精确，那么两帧之间哪怕为了保持手部固定产生的轻微肌肉活动导致的“移动”也可以顺利检测出来！这简直就是魔法。</p>\n<p>  为了确定计量尺度，系统也需要依赖IMU提供精确的航位推算。通过IMU提供的加速度和时间测量值，我们可以后向合并以计算速率，并再次合并回来以获得IMU帧之间的位移。计算过程并不难，难点在于消除IMU的误差以得到近乎完美的加速度测量值。任何微小的错误，如果每秒钟出现1000次，在移动手机的过程中持续数秒钟，最终都会累积造成30%甚至更高的尺度误差。Apple能将这个误差降低到个位数百分率，这真是让人佩服。</p>\n<h5 id=\"Tango、Hololens、Vuforia等产品又如何呢？\"><a href=\"#Tango、Hololens、Vuforia等产品又如何呢？\" class=\"headerlink\" title=\"Tango、Hololens、Vuforia等产品又如何呢？\"></a>Tango、Hololens、Vuforia等产品又如何呢？</h5><p>  Tango其实是一个品牌，并不是某个具体的产品。其中包含了硬件参考设计（RGB、鱼眼、深度摄像头，以及某些CPU/GPU规格）和软件栈，可提供VIO（动作追踪）、Sparse Mapping（区域学习），以及Dense 3D重建（深度感知）等功能。</p>\n<p>  Hololens具备完全相同的软件栈，但还包含一些ASIC（被称之为Holographic Processing Unit，全息处理单元），借此分摊CPU/GPU的处理任务以降低能耗。<br>  Vuforia几乎也是相同的，但不依赖特定的硬件。</p>\n<p>  上述三种技术使用了相同的VIO系统（Tango和ARKit甚至使用了同一套最初由FlyBy开发的代码！）。Hololens和Tango都没有使用深度摄像头进行追踪（但可能觉得为了解决某些边缘案例，他们正在着手这样做）。那么为何ARKit的表现会这么好？</p>\n<p>  答案在于，ARKit其实并不比Hololens好到哪里去（甚至可以说Hololens的追踪系统是市面上最棒的），但Hololens硬件的普及率太低了。微软本应将Hololens的追踪系统包含在Windows智能手机中，但可能他们是出于商业方面的考虑并未这样做（例如可能导致成本增高，需要花时间对手机传感器进行校准，设备销量太小，而微软提供类似ARKit的方案并不足以将开发者从iOS/Android平台策反过来）。</p>\n<p>  过去一年多的时间里，Google本来也可以很轻松地将Tango的VIO系统包含在出货量巨大的Android手机中，但他们也没有这样做。如果当时真这么做了，反而会让ARKit成为“跟风者”，而非“引领者”。可能是因为每家OEM厂商不想自己分别进行繁琐的传感器校准，进而导致每个OEM版本的Tango实际使用效果各异，而对于设备出货量足够大，值得这么做的少数OEM厂商（三星、华为等），Google也并不希望过于讨好他们。因而他们等于在告诉OEM厂商：“硬件参考设计是这样的，用不用随意”。随着Android智能手机硬件逐渐变得商品化，摄像头和传感器已成为不同厂商差异性最主要的来源之一，OEM厂商们怎么可能为Google做嫁衣！Google还强制要求必须使用深度摄像头，这会导致厂商的手机物料成本（以及耗电量）大幅增加，这也成了OEM厂商拒绝的另一个原因。但随着ARKit的发布，情况截然不同了……</p>\n<p>  使得ARKit如此出色的主要原因依然在于，Apple可以承担这样做的成本，将VIO算法与传感器紧密集成，并投入大量时间进行校准以消除姿态计算过程中的误差/不确定性。</p>\n<p>  好了，上面简单介绍了对ARKit技术实现方式的理解，不过看起来第二种更可信，之后我会继续分享一些ARKit的实践。</p>\n<h6 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档　\"></a>参考文档　</h6><ol>\n<li><a href=\"https://medium.com/super-ventures-blog/why-is-arkit-better-than-the-alternatives-af8871889d6a\" target=\"_blank\" rel=\"external\">https://medium.com/super-ventures-blog/why-is-arkit-better-than-the-alternatives-af8871889d6a</a>  </li>\n<li><a href=\"https://developer.apple.com/documentation/arkit\" target=\"_blank\" rel=\"external\">https://developer.apple.com/documentation/arkit</a> 官方API</li>\n<li><a href=\"https://developer.apple.com/documentation/arkit/understanding_augmented_reality\" target=\"_blank\" rel=\"external\">https://developer.apple.com/documentation/arkit/understanding_augmented_reality</a></li>\n</ol>"},{"title":"iOS Core NFC指南","date":"2017-08-22T11:41:17.000Z","_content":"\n大家可能听过NFC这项功能，或者有可能你每天都在使用这个功能，比如当你在进出地铁时闸机扫描地铁卡就用到了NFC技术。\n简单来说NFC就是可以让智能手机的NFC模块，可以像读卡器一般，读取电子标签的相关信息，实现NFC手机之间的数据交互或是读取其他IC卡内的数据。NFC(机场通讯)，其实由非接触式射频识别（RFID）演变而来，是一种短距高频的无线电技术，在13.56MHz频率运行于20厘米距离内。它的传输速度有106 Kbit/秒、212 Kbit/秒或者424 Kbit/秒三种。目前NFC已通过成为ISO/IEC IS 18092国际标准、ECMA-340标准与ETSI TS 102 190标准。NFC可以采用主动和被动两种读取模式。\n\n![NFC使用场景](http://upload-images.jianshu.io/upload_images/1944396-b31bb992a4bbb9f9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600)  \n\n\n#### Core NFC介绍  \n或者你可能还吐槽过Apple怎么还不支持NFC呢，其实iPhone6已经有NFC硬件了，已支持Apple Pay支付系统，只是接口没开放，终于在今年的WWDC，苹果在iOS11系统上对开发者开放了NFC接口框架Core NFC，虽然目前权限只有只读模式。  \nApple的Core NFC可以用于检测NFC(近场通讯)标签和读取包含NDEF(NFC Data Exchange Format)数据1到5类型的标签信息，只是该功能只支持iPhone 7和iPhone 7P及以上的机型。目前Core NFC其实同时有NFC和RFID的API存在，但是RFID可能没有很高的安全性，所以苹果没有推广使用(或者还在开发中)。\n\n> NFC Data Exchange Format : NFC数据交换格式，NFC组织约定的NFC tag中的数据格式。NDEF是轻量级的紧凑的二进制格式，可带有URL、vCard和NFC定义的各种数据类型。NDEF的由各种数据记录组成，而各个记录由报头(Header)和有效载荷(Payload)组成，其中NDEF记录的数据类型和大小由记录载荷的报头注明，这里的报头包含3部分，分别为Length、Type和Identifier。\n\n![NFC标签图例](http://ojca2gwha.bkt.clouddn.com/CoreNFC-tags.png)\n\n<!--more-->\n\n#### iOS集成开发\n\n##### 项目配置\n\n首先需要让你的AppID添加对NFC的支持，选中NFC Tag Reading后更新Provisioning Profiles即可。\n\n![NFC Profiles](http://ojca2gwha.bkt.clouddn.com/CoreNFC-profiles.png)\n\n其次在项目中打开Targets->Capabilities下的Near Field Communication Tag Reading选项，Xcode会自动帮你创建NFC entitlement文件。然后你需要在entitlements文件下添加如下内容：\n```\n  <key>com.apple.developer.nfc.readersession.formats</key>\n  <array>\n    <string>NDEF</string>\n  </array>\n```\n\n![NFC Capabilities](http://ojca2gwha.bkt.clouddn.com/CoreNFC-Capacities.png)\n\n随后需要在info.plist中添加隐私标签`Privacy - NFC Scan Usage Description`。\n\n```\n  <key>NFCReaderUsageDescription</key>\n  <string>NFC Import</string>\n```\n\n![NFC Info](http://ojca2gwha.bkt.clouddn.com/CoreNFC-plist.png)\n\n##### 集成Core NFC\n\n集成Core NFC需要用到`NFCNDEFReaderSession`类，其为NFCReaderSession的子类，但是基类不能实例化。\n和iOS的其他Session一样通过其协议`NFCReaderSessionProtocol`方法来处理信息回调的结果。这最重要的一个代理回调是`func readerSession(_ session: NFCNDEFReaderSession, didDetectNDEFs messages:[NFCNDEFMessage]) `方法，用以处理检测到的NDEF消息，messages是一个NFCNDEFMessage的数组，其有一个records数组，包含NFCNDEFPayload对象，该对象存放了真正的数据内容。\n\n\n```\nimport CoreNFC\nclass MessagesTableViewController: UITableViewController, NFCNDEFReaderSessionDelegate {\n  // MARK: NFCNDEReaderSessionDelegate\n  func readerSession(_ session: NFCNDEFReaderSession, didInvalidateWithError error: Error) {\n     // Check invalidation reason from the returned error. Session will be invalidated after the function returns. New session instance is required to restart tag scanning.\n  }\n  func readerSession(_ session: NFCNDEFReaderSession, didDetectNDEFs messages:[NFCNDEFMessage]) {\n     // Process read NFCNDEFMessage objects.\n     for message in messages {\n         print(\" - \\(message.records.count) Records:\")\n         for record in message.records {\n             print(\"\\t- TNF (TypeNameFormat): \\(record.typeNameFormat)\")\n             print(\"\\t- Payload: \\(String(data: record.payload, encoding: .utf8)!)\")\n             print(\"\\t- Type: \\(record.type)\")\n             print(\"\\t- Identifier: \\(record.identifier)\\n\")\n         }\n      }\n  }\n\n  // MARK: - Actions\n  @IBAction func beginScanning(_ sender: Any) {\n     let session = NFCNDEFReaderSession(delegate: self, queue: nil, invalidatedAfterFirstRead:true)\n     session.alertMessage = \"You can scan NFC-tags by holding them behind the top of your iPhone.\"\n     session.begin()\n  }\n```\n\n`NFCReaderSession`还有`NFCISO15693ReaderSession`的子类，用于RFID的读取处理，其使用流程和`NFCNDEFReaderSession`基本一致，只是代理方法不同，ISO15693是一种特殊的RFID标签，它拥有自己的协议和数据API(NFCISO15693Tag)。但是该类不起作用。。。可能Apple工程师还在开发中吧\n\n##### Tips\n1. 注意同时只能实例化一个读取session(系统会把其他的session放在队列里序列化执行)   \n2. Core NFC目前只支持前台扫描，切换到后台会失效    \n3. NFCNDEFReaderSession最大每次扫描60s，超时需要重启  \n4. 可以配置单一Tag或者多Tag读取模式  \n5. 使用提示信息即alertMessage会显示在当前APP的弹出浮层中\n\n\n获取成功后，即可以根据获取到的信息进行之后的业务流程了。\n\n![CoreNFC读取信息图示](http://ojca2gwha.bkt.clouddn.com/CoreNFC-view.png)\n\n\n\n##### 参考\n1. https://developer.apple.com/documentation/corenfc\n2. https://zh.wikipedia.org/zh/%E8%BF%91%E5%A0%B4%E9%80%9A%E8%A8%8A\n3. https://developer.apple.com/videos/play/wwdc2017/718/  \n","source":"_posts/iOS-nfc.md","raw":"---\ntitle: iOS Core NFC指南\ndate: 2017-08-22 19:41:17\ntags:\n  - iOS\n  - Core NFC\ncategories: iOS\n---\n\n大家可能听过NFC这项功能，或者有可能你每天都在使用这个功能，比如当你在进出地铁时闸机扫描地铁卡就用到了NFC技术。\n简单来说NFC就是可以让智能手机的NFC模块，可以像读卡器一般，读取电子标签的相关信息，实现NFC手机之间的数据交互或是读取其他IC卡内的数据。NFC(机场通讯)，其实由非接触式射频识别（RFID）演变而来，是一种短距高频的无线电技术，在13.56MHz频率运行于20厘米距离内。它的传输速度有106 Kbit/秒、212 Kbit/秒或者424 Kbit/秒三种。目前NFC已通过成为ISO/IEC IS 18092国际标准、ECMA-340标准与ETSI TS 102 190标准。NFC可以采用主动和被动两种读取模式。\n\n![NFC使用场景](http://upload-images.jianshu.io/upload_images/1944396-b31bb992a4bbb9f9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600)  \n\n\n#### Core NFC介绍  \n或者你可能还吐槽过Apple怎么还不支持NFC呢，其实iPhone6已经有NFC硬件了，已支持Apple Pay支付系统，只是接口没开放，终于在今年的WWDC，苹果在iOS11系统上对开发者开放了NFC接口框架Core NFC，虽然目前权限只有只读模式。  \nApple的Core NFC可以用于检测NFC(近场通讯)标签和读取包含NDEF(NFC Data Exchange Format)数据1到5类型的标签信息，只是该功能只支持iPhone 7和iPhone 7P及以上的机型。目前Core NFC其实同时有NFC和RFID的API存在，但是RFID可能没有很高的安全性，所以苹果没有推广使用(或者还在开发中)。\n\n> NFC Data Exchange Format : NFC数据交换格式，NFC组织约定的NFC tag中的数据格式。NDEF是轻量级的紧凑的二进制格式，可带有URL、vCard和NFC定义的各种数据类型。NDEF的由各种数据记录组成，而各个记录由报头(Header)和有效载荷(Payload)组成，其中NDEF记录的数据类型和大小由记录载荷的报头注明，这里的报头包含3部分，分别为Length、Type和Identifier。\n\n![NFC标签图例](http://ojca2gwha.bkt.clouddn.com/CoreNFC-tags.png)\n\n<!--more-->\n\n#### iOS集成开发\n\n##### 项目配置\n\n首先需要让你的AppID添加对NFC的支持，选中NFC Tag Reading后更新Provisioning Profiles即可。\n\n![NFC Profiles](http://ojca2gwha.bkt.clouddn.com/CoreNFC-profiles.png)\n\n其次在项目中打开Targets->Capabilities下的Near Field Communication Tag Reading选项，Xcode会自动帮你创建NFC entitlement文件。然后你需要在entitlements文件下添加如下内容：\n```\n  <key>com.apple.developer.nfc.readersession.formats</key>\n  <array>\n    <string>NDEF</string>\n  </array>\n```\n\n![NFC Capabilities](http://ojca2gwha.bkt.clouddn.com/CoreNFC-Capacities.png)\n\n随后需要在info.plist中添加隐私标签`Privacy - NFC Scan Usage Description`。\n\n```\n  <key>NFCReaderUsageDescription</key>\n  <string>NFC Import</string>\n```\n\n![NFC Info](http://ojca2gwha.bkt.clouddn.com/CoreNFC-plist.png)\n\n##### 集成Core NFC\n\n集成Core NFC需要用到`NFCNDEFReaderSession`类，其为NFCReaderSession的子类，但是基类不能实例化。\n和iOS的其他Session一样通过其协议`NFCReaderSessionProtocol`方法来处理信息回调的结果。这最重要的一个代理回调是`func readerSession(_ session: NFCNDEFReaderSession, didDetectNDEFs messages:[NFCNDEFMessage]) `方法，用以处理检测到的NDEF消息，messages是一个NFCNDEFMessage的数组，其有一个records数组，包含NFCNDEFPayload对象，该对象存放了真正的数据内容。\n\n\n```\nimport CoreNFC\nclass MessagesTableViewController: UITableViewController, NFCNDEFReaderSessionDelegate {\n  // MARK: NFCNDEReaderSessionDelegate\n  func readerSession(_ session: NFCNDEFReaderSession, didInvalidateWithError error: Error) {\n     // Check invalidation reason from the returned error. Session will be invalidated after the function returns. New session instance is required to restart tag scanning.\n  }\n  func readerSession(_ session: NFCNDEFReaderSession, didDetectNDEFs messages:[NFCNDEFMessage]) {\n     // Process read NFCNDEFMessage objects.\n     for message in messages {\n         print(\" - \\(message.records.count) Records:\")\n         for record in message.records {\n             print(\"\\t- TNF (TypeNameFormat): \\(record.typeNameFormat)\")\n             print(\"\\t- Payload: \\(String(data: record.payload, encoding: .utf8)!)\")\n             print(\"\\t- Type: \\(record.type)\")\n             print(\"\\t- Identifier: \\(record.identifier)\\n\")\n         }\n      }\n  }\n\n  // MARK: - Actions\n  @IBAction func beginScanning(_ sender: Any) {\n     let session = NFCNDEFReaderSession(delegate: self, queue: nil, invalidatedAfterFirstRead:true)\n     session.alertMessage = \"You can scan NFC-tags by holding them behind the top of your iPhone.\"\n     session.begin()\n  }\n```\n\n`NFCReaderSession`还有`NFCISO15693ReaderSession`的子类，用于RFID的读取处理，其使用流程和`NFCNDEFReaderSession`基本一致，只是代理方法不同，ISO15693是一种特殊的RFID标签，它拥有自己的协议和数据API(NFCISO15693Tag)。但是该类不起作用。。。可能Apple工程师还在开发中吧\n\n##### Tips\n1. 注意同时只能实例化一个读取session(系统会把其他的session放在队列里序列化执行)   \n2. Core NFC目前只支持前台扫描，切换到后台会失效    \n3. NFCNDEFReaderSession最大每次扫描60s，超时需要重启  \n4. 可以配置单一Tag或者多Tag读取模式  \n5. 使用提示信息即alertMessage会显示在当前APP的弹出浮层中\n\n\n获取成功后，即可以根据获取到的信息进行之后的业务流程了。\n\n![CoreNFC读取信息图示](http://ojca2gwha.bkt.clouddn.com/CoreNFC-view.png)\n\n\n\n##### 参考\n1. https://developer.apple.com/documentation/corenfc\n2. https://zh.wikipedia.org/zh/%E8%BF%91%E5%A0%B4%E9%80%9A%E8%A8%8A\n3. https://developer.apple.com/videos/play/wwdc2017/718/  \n","slug":"iOS-nfc","published":1,"updated":"2017-09-26T10:44:02.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj81l545p000awluvjaz6jrva","content":"<p>大家可能听过NFC这项功能，或者有可能你每天都在使用这个功能，比如当你在进出地铁时闸机扫描地铁卡就用到了NFC技术。<br>简单来说NFC就是可以让智能手机的NFC模块，可以像读卡器一般，读取电子标签的相关信息，实现NFC手机之间的数据交互或是读取其他IC卡内的数据。NFC(机场通讯)，其实由非接触式射频识别（RFID）演变而来，是一种短距高频的无线电技术，在13.56MHz频率运行于20厘米距离内。它的传输速度有106 Kbit/秒、212 Kbit/秒或者424 Kbit/秒三种。目前NFC已通过成为ISO/IEC IS 18092国际标准、ECMA-340标准与ETSI TS 102 190标准。NFC可以采用主动和被动两种读取模式。</p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1944396-b31bb992a4bbb9f9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600\" alt=\"NFC使用场景\">  </p>\n<h4 id=\"Core-NFC介绍\"><a href=\"#Core-NFC介绍\" class=\"headerlink\" title=\"Core NFC介绍\"></a>Core NFC介绍</h4><p>或者你可能还吐槽过Apple怎么还不支持NFC呢，其实iPhone6已经有NFC硬件了，已支持Apple Pay支付系统，只是接口没开放，终于在今年的WWDC，苹果在iOS11系统上对开发者开放了NFC接口框架Core NFC，虽然目前权限只有只读模式。<br>Apple的Core NFC可以用于检测NFC(近场通讯)标签和读取包含NDEF(NFC Data Exchange Format)数据1到5类型的标签信息，只是该功能只支持iPhone 7和iPhone 7P及以上的机型。目前Core NFC其实同时有NFC和RFID的API存在，但是RFID可能没有很高的安全性，所以苹果没有推广使用(或者还在开发中)。</p>\n<blockquote>\n<p>NFC Data Exchange Format : NFC数据交换格式，NFC组织约定的NFC tag中的数据格式。NDEF是轻量级的紧凑的二进制格式，可带有URL、vCard和NFC定义的各种数据类型。NDEF的由各种数据记录组成，而各个记录由报头(Header)和有效载荷(Payload)组成，其中NDEF记录的数据类型和大小由记录载荷的报头注明，这里的报头包含3部分，分别为Length、Type和Identifier。</p>\n</blockquote>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/CoreNFC-tags.png\" alt=\"NFC标签图例\"></p>\n<a id=\"more\"></a>\n<h4 id=\"iOS集成开发\"><a href=\"#iOS集成开发\" class=\"headerlink\" title=\"iOS集成开发\"></a>iOS集成开发</h4><h5 id=\"项目配置\"><a href=\"#项目配置\" class=\"headerlink\" title=\"项目配置\"></a>项目配置</h5><p>首先需要让你的AppID添加对NFC的支持，选中NFC Tag Reading后更新Provisioning Profiles即可。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/CoreNFC-profiles.png\" alt=\"NFC Profiles\"></p>\n<p>其次在项目中打开Targets-&gt;Capabilities下的Near Field Communication Tag Reading选项，Xcode会自动帮你创建NFC entitlement文件。然后你需要在entitlements文件下添加如下内容：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;key&gt;com.apple.developer.nfc.readersession.formats&lt;/key&gt;</div><div class=\"line\">&lt;array&gt;</div><div class=\"line\">  &lt;string&gt;NDEF&lt;/string&gt;</div><div class=\"line\">&lt;/array&gt;</div></pre></td></tr></table></figure></p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/CoreNFC-Capacities.png\" alt=\"NFC Capabilities\"></p>\n<p>随后需要在info.plist中添加隐私标签<code>Privacy - NFC Scan Usage Description</code>。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;key&gt;NFCReaderUsageDescription&lt;/key&gt;</div><div class=\"line\">&lt;string&gt;NFC Import&lt;/string&gt;</div></pre></td></tr></table></figure>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/CoreNFC-plist.png\" alt=\"NFC Info\"></p>\n<h5 id=\"集成Core-NFC\"><a href=\"#集成Core-NFC\" class=\"headerlink\" title=\"集成Core NFC\"></a>集成Core NFC</h5><p>集成Core NFC需要用到<code>NFCNDEFReaderSession</code>类，其为NFCReaderSession的子类，但是基类不能实例化。<br>和iOS的其他Session一样通过其协议<code>NFCReaderSessionProtocol</code>方法来处理信息回调的结果。这最重要的一个代理回调是<code>func readerSession(_ session: NFCNDEFReaderSession, didDetectNDEFs messages:[NFCNDEFMessage])</code>方法，用以处理检测到的NDEF消息，messages是一个NFCNDEFMessage的数组，其有一个records数组，包含NFCNDEFPayload对象，该对象存放了真正的数据内容。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\">import CoreNFC</div><div class=\"line\">class MessagesTableViewController: UITableViewController, NFCNDEFReaderSessionDelegate &#123;</div><div class=\"line\">  // MARK: NFCNDEReaderSessionDelegate</div><div class=\"line\">  func readerSession(_ session: NFCNDEFReaderSession, didInvalidateWithError error: Error) &#123;</div><div class=\"line\">     // Check invalidation reason from the returned error. Session will be invalidated after the function returns. New session instance is required to restart tag scanning.</div><div class=\"line\">  &#125;</div><div class=\"line\">  func readerSession(_ session: NFCNDEFReaderSession, didDetectNDEFs messages:[NFCNDEFMessage]) &#123;</div><div class=\"line\">     // Process read NFCNDEFMessage objects.</div><div class=\"line\">     for message in messages &#123;</div><div class=\"line\">         print(&quot; - \\(message.records.count) Records:&quot;)</div><div class=\"line\">         for record in message.records &#123;</div><div class=\"line\">             print(&quot;\\t- TNF (TypeNameFormat): \\(record.typeNameFormat)&quot;)</div><div class=\"line\">             print(&quot;\\t- Payload: \\(String(data: record.payload, encoding: .utf8)!)&quot;)</div><div class=\"line\">             print(&quot;\\t- Type: \\(record.type)&quot;)</div><div class=\"line\">             print(&quot;\\t- Identifier: \\(record.identifier)\\n&quot;)</div><div class=\"line\">         &#125;</div><div class=\"line\">      &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  // MARK: - Actions</div><div class=\"line\">  @IBAction func beginScanning(_ sender: Any) &#123;</div><div class=\"line\">     let session = NFCNDEFReaderSession(delegate: self, queue: nil, invalidatedAfterFirstRead:true)</div><div class=\"line\">     session.alertMessage = &quot;You can scan NFC-tags by holding them behind the top of your iPhone.&quot;</div><div class=\"line\">     session.begin()</div><div class=\"line\">  &#125;</div></pre></td></tr></table></figure>\n<p><code>NFCReaderSession</code>还有<code>NFCISO15693ReaderSession</code>的子类，用于RFID的读取处理，其使用流程和<code>NFCNDEFReaderSession</code>基本一致，只是代理方法不同，ISO15693是一种特殊的RFID标签，它拥有自己的协议和数据API(NFCISO15693Tag)。但是该类不起作用。。。可能Apple工程师还在开发中吧</p>\n<h5 id=\"Tips\"><a href=\"#Tips\" class=\"headerlink\" title=\"Tips\"></a>Tips</h5><ol>\n<li>注意同时只能实例化一个读取session(系统会把其他的session放在队列里序列化执行)   </li>\n<li>Core NFC目前只支持前台扫描，切换到后台会失效    </li>\n<li>NFCNDEFReaderSession最大每次扫描60s，超时需要重启  </li>\n<li>可以配置单一Tag或者多Tag读取模式  </li>\n<li>使用提示信息即alertMessage会显示在当前APP的弹出浮层中</li>\n</ol>\n<p>获取成功后，即可以根据获取到的信息进行之后的业务流程了。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/CoreNFC-view.png\" alt=\"CoreNFC读取信息图示\"></p>\n<h5 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h5><ol>\n<li><a href=\"https://developer.apple.com/documentation/corenfc\" target=\"_blank\" rel=\"external\">https://developer.apple.com/documentation/corenfc</a></li>\n<li><a href=\"https://zh.wikipedia.org/zh/%E8%BF%91%E5%A0%B4%E9%80%9A%E8%A8%8A\" target=\"_blank\" rel=\"external\">https://zh.wikipedia.org/zh/%E8%BF%91%E5%A0%B4%E9%80%9A%E8%A8%8A</a></li>\n<li><a href=\"https://developer.apple.com/videos/play/wwdc2017/718/\" target=\"_blank\" rel=\"external\">https://developer.apple.com/videos/play/wwdc2017/718/</a>  </li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>大家可能听过NFC这项功能，或者有可能你每天都在使用这个功能，比如当你在进出地铁时闸机扫描地铁卡就用到了NFC技术。<br>简单来说NFC就是可以让智能手机的NFC模块，可以像读卡器一般，读取电子标签的相关信息，实现NFC手机之间的数据交互或是读取其他IC卡内的数据。NFC(机场通讯)，其实由非接触式射频识别（RFID）演变而来，是一种短距高频的无线电技术，在13.56MHz频率运行于20厘米距离内。它的传输速度有106 Kbit/秒、212 Kbit/秒或者424 Kbit/秒三种。目前NFC已通过成为ISO/IEC IS 18092国际标准、ECMA-340标准与ETSI TS 102 190标准。NFC可以采用主动和被动两种读取模式。</p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1944396-b31bb992a4bbb9f9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/600\" alt=\"NFC使用场景\">  </p>\n<h4 id=\"Core-NFC介绍\"><a href=\"#Core-NFC介绍\" class=\"headerlink\" title=\"Core NFC介绍\"></a>Core NFC介绍</h4><p>或者你可能还吐槽过Apple怎么还不支持NFC呢，其实iPhone6已经有NFC硬件了，已支持Apple Pay支付系统，只是接口没开放，终于在今年的WWDC，苹果在iOS11系统上对开发者开放了NFC接口框架Core NFC，虽然目前权限只有只读模式。<br>Apple的Core NFC可以用于检测NFC(近场通讯)标签和读取包含NDEF(NFC Data Exchange Format)数据1到5类型的标签信息，只是该功能只支持iPhone 7和iPhone 7P及以上的机型。目前Core NFC其实同时有NFC和RFID的API存在，但是RFID可能没有很高的安全性，所以苹果没有推广使用(或者还在开发中)。</p>\n<blockquote>\n<p>NFC Data Exchange Format : NFC数据交换格式，NFC组织约定的NFC tag中的数据格式。NDEF是轻量级的紧凑的二进制格式，可带有URL、vCard和NFC定义的各种数据类型。NDEF的由各种数据记录组成，而各个记录由报头(Header)和有效载荷(Payload)组成，其中NDEF记录的数据类型和大小由记录载荷的报头注明，这里的报头包含3部分，分别为Length、Type和Identifier。</p>\n</blockquote>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/CoreNFC-tags.png\" alt=\"NFC标签图例\"></p>","more":"<h4 id=\"iOS集成开发\"><a href=\"#iOS集成开发\" class=\"headerlink\" title=\"iOS集成开发\"></a>iOS集成开发</h4><h5 id=\"项目配置\"><a href=\"#项目配置\" class=\"headerlink\" title=\"项目配置\"></a>项目配置</h5><p>首先需要让你的AppID添加对NFC的支持，选中NFC Tag Reading后更新Provisioning Profiles即可。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/CoreNFC-profiles.png\" alt=\"NFC Profiles\"></p>\n<p>其次在项目中打开Targets-&gt;Capabilities下的Near Field Communication Tag Reading选项，Xcode会自动帮你创建NFC entitlement文件。然后你需要在entitlements文件下添加如下内容：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;key&gt;com.apple.developer.nfc.readersession.formats&lt;/key&gt;</div><div class=\"line\">&lt;array&gt;</div><div class=\"line\">  &lt;string&gt;NDEF&lt;/string&gt;</div><div class=\"line\">&lt;/array&gt;</div></pre></td></tr></table></figure></p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/CoreNFC-Capacities.png\" alt=\"NFC Capabilities\"></p>\n<p>随后需要在info.plist中添加隐私标签<code>Privacy - NFC Scan Usage Description</code>。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;key&gt;NFCReaderUsageDescription&lt;/key&gt;</div><div class=\"line\">&lt;string&gt;NFC Import&lt;/string&gt;</div></pre></td></tr></table></figure>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/CoreNFC-plist.png\" alt=\"NFC Info\"></p>\n<h5 id=\"集成Core-NFC\"><a href=\"#集成Core-NFC\" class=\"headerlink\" title=\"集成Core NFC\"></a>集成Core NFC</h5><p>集成Core NFC需要用到<code>NFCNDEFReaderSession</code>类，其为NFCReaderSession的子类，但是基类不能实例化。<br>和iOS的其他Session一样通过其协议<code>NFCReaderSessionProtocol</code>方法来处理信息回调的结果。这最重要的一个代理回调是<code>func readerSession(_ session: NFCNDEFReaderSession, didDetectNDEFs messages:[NFCNDEFMessage])</code>方法，用以处理检测到的NDEF消息，messages是一个NFCNDEFMessage的数组，其有一个records数组，包含NFCNDEFPayload对象，该对象存放了真正的数据内容。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div></pre></td><td class=\"code\"><pre><div class=\"line\">import CoreNFC</div><div class=\"line\">class MessagesTableViewController: UITableViewController, NFCNDEFReaderSessionDelegate &#123;</div><div class=\"line\">  // MARK: NFCNDEReaderSessionDelegate</div><div class=\"line\">  func readerSession(_ session: NFCNDEFReaderSession, didInvalidateWithError error: Error) &#123;</div><div class=\"line\">     // Check invalidation reason from the returned error. Session will be invalidated after the function returns. New session instance is required to restart tag scanning.</div><div class=\"line\">  &#125;</div><div class=\"line\">  func readerSession(_ session: NFCNDEFReaderSession, didDetectNDEFs messages:[NFCNDEFMessage]) &#123;</div><div class=\"line\">     // Process read NFCNDEFMessage objects.</div><div class=\"line\">     for message in messages &#123;</div><div class=\"line\">         print(&quot; - \\(message.records.count) Records:&quot;)</div><div class=\"line\">         for record in message.records &#123;</div><div class=\"line\">             print(&quot;\\t- TNF (TypeNameFormat): \\(record.typeNameFormat)&quot;)</div><div class=\"line\">             print(&quot;\\t- Payload: \\(String(data: record.payload, encoding: .utf8)!)&quot;)</div><div class=\"line\">             print(&quot;\\t- Type: \\(record.type)&quot;)</div><div class=\"line\">             print(&quot;\\t- Identifier: \\(record.identifier)\\n&quot;)</div><div class=\"line\">         &#125;</div><div class=\"line\">      &#125;</div><div class=\"line\">  &#125;</div><div class=\"line\"></div><div class=\"line\">  // MARK: - Actions</div><div class=\"line\">  @IBAction func beginScanning(_ sender: Any) &#123;</div><div class=\"line\">     let session = NFCNDEFReaderSession(delegate: self, queue: nil, invalidatedAfterFirstRead:true)</div><div class=\"line\">     session.alertMessage = &quot;You can scan NFC-tags by holding them behind the top of your iPhone.&quot;</div><div class=\"line\">     session.begin()</div><div class=\"line\">  &#125;</div></pre></td></tr></table></figure>\n<p><code>NFCReaderSession</code>还有<code>NFCISO15693ReaderSession</code>的子类，用于RFID的读取处理，其使用流程和<code>NFCNDEFReaderSession</code>基本一致，只是代理方法不同，ISO15693是一种特殊的RFID标签，它拥有自己的协议和数据API(NFCISO15693Tag)。但是该类不起作用。。。可能Apple工程师还在开发中吧</p>\n<h5 id=\"Tips\"><a href=\"#Tips\" class=\"headerlink\" title=\"Tips\"></a>Tips</h5><ol>\n<li>注意同时只能实例化一个读取session(系统会把其他的session放在队列里序列化执行)   </li>\n<li>Core NFC目前只支持前台扫描，切换到后台会失效    </li>\n<li>NFCNDEFReaderSession最大每次扫描60s，超时需要重启  </li>\n<li>可以配置单一Tag或者多Tag读取模式  </li>\n<li>使用提示信息即alertMessage会显示在当前APP的弹出浮层中</li>\n</ol>\n<p>获取成功后，即可以根据获取到的信息进行之后的业务流程了。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/CoreNFC-view.png\" alt=\"CoreNFC读取信息图示\"></p>\n<h5 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h5><ol>\n<li><a href=\"https://developer.apple.com/documentation/corenfc\" target=\"_blank\" rel=\"external\">https://developer.apple.com/documentation/corenfc</a></li>\n<li><a href=\"https://zh.wikipedia.org/zh/%E8%BF%91%E5%A0%B4%E9%80%9A%E8%A8%8A\" target=\"_blank\" rel=\"external\">https://zh.wikipedia.org/zh/%E8%BF%91%E5%A0%B4%E9%80%9A%E8%A8%8A</a></li>\n<li><a href=\"https://developer.apple.com/videos/play/wwdc2017/718/\" target=\"_blank\" rel=\"external\">https://developer.apple.com/videos/play/wwdc2017/718/</a>  </li>\n</ol>"},{"title":"如何搭建我的博客 - Hexo之Hello World","date":"2017-03-27T17:16:11.000Z","_content":"\n其实很久以前就搭建完博客的基础部分，只是懒癌发作，迟迟没有补上文章来总结，但是记录自己的心得还是必要的。下面描述下搭建博客的整个流程和一些问题的解决方案。搭建博客其实有很多种框架，比如可能大家熟悉的[WordPress](https://cn.wordpress.org/)、[Hexo](https://hexo.io/zh-cn/)等，这里我们将使用很火很流程的Hexo来作为博客基础框架。\n\nHexo是一个快速、简洁且高效的博客框架。Hexo使用Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。\n搭建博客的大体流程主要分为：`GitHub配置`、`Hexo管理`、`域名绑定`三个步骤，非常简单。\n\n### GitHub配置  \n首先需要在[GitHub](https://github.com/)上注册一个账号(当然估计你们都有了)。然后创建一个仓库，命名为`xxx.github.io`，xxx会是你注册时的用户名，所以注册账号时认真想个不错的名字吧，因为这个地址会是你的域名(假如你不单独申请域名的话)。\n\n![新建GitHub仓库](http://ojca2gwha.bkt.clouddn.com/Hexo-blog-github.png)  \n\n### Hexo管理\n\n#### 环境安装\n在进行下一步前，你需要在你的Mac上安装好git(没安装过的，直接去官网找吧，顺便面壁思过下)和Node.js。\n\nNode安装的最佳方式是使用nvm，这是Node.js的版本管理器，安装方式很简单。\n\n```\n// 1. Homebrew 安装方式，此安装方式无需重启\n$ brew install nvm  \n$ mkdir ~/.nvm\n$ export NVM_DIR=~/.nvm\n$ . $(brew --prefix nvm)/nvm.sh\n// 2. curl安装\n$ curl https://raw.github.com/creationix/nvm/master/install.sh | sh\n```\n\n安装完nvm后，执行以下命令即可安装Node。\n```\n$ nvm install stable\n```\n\nHexo安装：  \n```\n$ sudo npm install -g hexo-cli\n```\n所有的工具已经安装完成，下面可以创建博客内容，并上传到我们的github仓库了。\n\n<!--more-->\n\n#### 创建博客  \n\n接下来需要用Hexo初始化博客，并更改设置，来发布内容到之前创建的GitHub仓库。\n\n##### 初始化博客  \n\n安装 Hexo 完成后执行下列命令，Hexo将会在指定文件夹中新建博客所需要的文件。\n```\n$ hexo init xxx.github.io\n$ cd xxx.github.io\n$ npm install\n```\n初始化后，你的文件夹里会有这些内容：\n```\n  .\n  ├── _config.yml        #配置文件\n  ├── package.json       #数据\n  ├── scaffolds          #草稿\n  ├── source             #网站内容\n  |   ├── _drafts        #草稿\n  |   └── _posts         #文章\n  └── themes             #主题\n```\n\n##### 更新配置\n\n当然我们自己的博客，要选择好看的主题。Hexo比较好的一点是现在有很多免费的主题可以使用，只需要把主题文件文件拷贝到你的/themes目录下，做简单配置就可以使用该主题了。\n知乎上有一篇文章罗列了一些[不错的主题](https://www.zhihu.com/question/24422335)，大家可以参考下。这里我们使用了极简的[NexT](http://theme-next.iissnan.com/getting-started.html)这款非常火爆常见的主题。  \n\n```\n$ cd xxx.github.io\n$ git clone https://github.com/iissnan/hexo-theme-next themes/next\n```\n\n之后你需要在`xxx.github.io/_config.yml`中配置博客名、语言、作者等基础配置如下(键值之间需要有空白)，可配置的选项可以参考[Hexo配置](https://hexo.io/zh-cn/docs/configuration.html)。\n\n```\n  title: DragonFly的博客\n  subtitle: 我曾七次鄙视自己的灵魂\n  description: iOS开发、ReactNative开发、AR\n  author: DragonFly\n  language: zh-Hans\n  ......\n  theme: next         // 之前下载的主题名称\n```\n\n这儿需要重点注意的是要配置博客提交的github地址。\n```\n  deploy:\n   type: git    //使用Git 发布\n   repo: https://github.com/xxx/xxx.github.io.git    // 刚创建的Github仓库\n```\n另外主题的配置文件也需要做一些修改，相应的文件目录为`xxx.github.io/themes/next/_config.yml`，可配置的选项可以参考[NexT主题配置](http://theme-next.iissnan.com/theme-settings.html)。\n\n##### 新建一篇文章\n\n所有基础框架已经创建完成，接下来你可以开始写第一篇博客了，hexo的命令也很简单，使用两次就记住了。\n\n```\n$ hexo new \"My-New-Post\"  // 这儿是你的文章标题，创建后可以在文档中修改\n```\n更多细节可以参考： [Writing](https://hexo.io/docs/writing.html)\n\n##### 启用本地服务\n\n写完文章后，可以在本地启用服务，来看你的成果。在浏览器中输入`https://localhost:4000`即可访问你的博客主目录。\n```\n$ hexo server //hexo s\n```\n\n##### 发布内容  \n\n测试没问题后，我们就可以生成静态网页文件并发布到GitHub Pages上了。\n\n生成静态文件的命令：\n```\n$ hexo generate  //hexo g\n```\n发布的命令：\n```\n$ hexo deploy //hexo d\n```\n\n以上命令可以简写为`hexo g -d`，这样你的博客已经上传到GitHub了。此时你可以在浏览器里输入fighting300.github.io来访问你的博客。\n另外第一次使用时，你需要在终端配置Github的邮箱和密码。\n\n### 域名绑定  \n\n或许你对你的github域名不满意，想要使用自己独立的域名。那么你可以在阿里云旗下的[万网](https://wanwang.aliyun.com/)购买域名(如`http://fighting300.com`)，购买之后进行实名认证。\n\n![域名购买](http://ojca2gwha.bkt.clouddn.com/Hexo-blog-domain.png)\n\n#### 创建CNAME文件\n为了绑定域名，首先需要在source文件夹下创建一个CNAME文件，文件内容为你要设置的域名(如fighting300.com)，这样将你的域名指向了Github服务器。用Hexo命令deploy后，几分钟后生效，你会看到你的仓库下GitHub Pages的信息已经发生变化。\n\n![GitHub domain](http://ojca2gwha.bkt.clouddn.com/Hexo-blog-domain-page.png)  \n\n#### 添加DNS解析\n阿里云其实有自带的DNS解析服务，但是有小伙伴反馈他的DNS解析服务会有问题(目前使用过程中暂未发现)，可以切换为[DNSPod](https://www.dnspod.cn/)的解析服务。两种DNS的解析配置都很简单，只需要添加对应的IP地址到你的域名配置中即可。该IP地址使用`ping fighting300.github.io`来获取到。\n\n![阿里云DNS配置](http://ojca2gwha.bkt.clouddn.com/Hexo-blog-aliyun.png)\n\n![DNSPod配置](http://ojca2gwha.bkt.clouddn.com/Hexo-blog-dnspod.png)\n\n完成上述步骤后，需要等一段时间上述配置才会生效，最后你的博客已经搭建完成，你可以开启你的博客之旅了。\n\n![My blog](http://ojca2gwha.bkt.clouddn.com/Hexo-blog-review.png)   \n\n本文将持续记录一些hexo使用方法和常见错误的解决方式，如果喜欢，请持续关注本博客。\n\n\n\n#### 常见问题\n##### 1.首页文章显示部分  \n最简单的方案是在文章中添加以下标签内容：  \n`<!--more-->`\n\n##### 2.评论系统支持\n试了几种评论服务，感觉还是[Disqus](https://disqus.com/)的服务比较好，比较麻烦的一点是需要翻墙才能评论。不过为了良好的体验，目前还是使用Disqus吧，最主要它是免费的。接入很简单，现在[网站注册](https://disqus.com/admin/create/),然后在主题配置文件下填写以下内容即可：\n\n```\n# Disqus\ndisqus:\n  enable: true\n  shortname: ***** //这儿填写相应的服务名  \n  count: true\n```\n\n注意使用过程中，要配置Guest Commenting,这样就可以允许所有人在页面评论了。   \n注意，在标签需要关闭评论,添加以下标签即可。  \n```\n  ---\n  comments: false\n  ---\n```\n\n##### 3.统计支持  \n目前发现GoogleAnalysis的统计数据非常丰富，翻墙去体验下吧。\n\n##### 4.添加标签\n\n新建一个页面，命名为tags。命令如下：  \n\n```\n$ hexo new page \"tags\"\n```\n\n编辑刚新建的页面，将页面的类型设置为 tags ，主题将自动为这个页面显示标签云。页面内容如下：  \n\n```\ntitle: tags\ndate: 2016-12-22 12:39:04\ntype: \"tags\"\n```\n\n注意： 如果有启用Disqus评论，默认页面也会带有评论。如果需要关闭，请添加comments字段并将值设置为false，如：\n\n```\ncomments: false\n```\n\n然后在菜单中添加链接，编辑主题配置文件，添加tags到menu中，如下：  \n\n```\nmenu:\n  home: /\n  archives: /archives\n  tags: /tags\n```\n\n\n\n##### 参考文档\n1. [Hexo](https://hexo.io/)!\n2. [NexT](http://theme-next.iissnan.com/getting-started.html)\n3. [troubleshooting](https://hexo.io/docs/troubleshooting.html)\n4. [GitHub](https://github.com/hexojs/hexo/issues).\n","source":"_posts/hello-world.md","raw":"---\ntitle: 如何搭建我的博客 - Hexo之Hello World\ndate: 2017-03-28 01:16:11\ntags: blog\ncategories: tools\n---\n\n其实很久以前就搭建完博客的基础部分，只是懒癌发作，迟迟没有补上文章来总结，但是记录自己的心得还是必要的。下面描述下搭建博客的整个流程和一些问题的解决方案。搭建博客其实有很多种框架，比如可能大家熟悉的[WordPress](https://cn.wordpress.org/)、[Hexo](https://hexo.io/zh-cn/)等，这里我们将使用很火很流程的Hexo来作为博客基础框架。\n\nHexo是一个快速、简洁且高效的博客框架。Hexo使用Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。\n搭建博客的大体流程主要分为：`GitHub配置`、`Hexo管理`、`域名绑定`三个步骤，非常简单。\n\n### GitHub配置  \n首先需要在[GitHub](https://github.com/)上注册一个账号(当然估计你们都有了)。然后创建一个仓库，命名为`xxx.github.io`，xxx会是你注册时的用户名，所以注册账号时认真想个不错的名字吧，因为这个地址会是你的域名(假如你不单独申请域名的话)。\n\n![新建GitHub仓库](http://ojca2gwha.bkt.clouddn.com/Hexo-blog-github.png)  \n\n### Hexo管理\n\n#### 环境安装\n在进行下一步前，你需要在你的Mac上安装好git(没安装过的，直接去官网找吧，顺便面壁思过下)和Node.js。\n\nNode安装的最佳方式是使用nvm，这是Node.js的版本管理器，安装方式很简单。\n\n```\n// 1. Homebrew 安装方式，此安装方式无需重启\n$ brew install nvm  \n$ mkdir ~/.nvm\n$ export NVM_DIR=~/.nvm\n$ . $(brew --prefix nvm)/nvm.sh\n// 2. curl安装\n$ curl https://raw.github.com/creationix/nvm/master/install.sh | sh\n```\n\n安装完nvm后，执行以下命令即可安装Node。\n```\n$ nvm install stable\n```\n\nHexo安装：  \n```\n$ sudo npm install -g hexo-cli\n```\n所有的工具已经安装完成，下面可以创建博客内容，并上传到我们的github仓库了。\n\n<!--more-->\n\n#### 创建博客  \n\n接下来需要用Hexo初始化博客，并更改设置，来发布内容到之前创建的GitHub仓库。\n\n##### 初始化博客  \n\n安装 Hexo 完成后执行下列命令，Hexo将会在指定文件夹中新建博客所需要的文件。\n```\n$ hexo init xxx.github.io\n$ cd xxx.github.io\n$ npm install\n```\n初始化后，你的文件夹里会有这些内容：\n```\n  .\n  ├── _config.yml        #配置文件\n  ├── package.json       #数据\n  ├── scaffolds          #草稿\n  ├── source             #网站内容\n  |   ├── _drafts        #草稿\n  |   └── _posts         #文章\n  └── themes             #主题\n```\n\n##### 更新配置\n\n当然我们自己的博客，要选择好看的主题。Hexo比较好的一点是现在有很多免费的主题可以使用，只需要把主题文件文件拷贝到你的/themes目录下，做简单配置就可以使用该主题了。\n知乎上有一篇文章罗列了一些[不错的主题](https://www.zhihu.com/question/24422335)，大家可以参考下。这里我们使用了极简的[NexT](http://theme-next.iissnan.com/getting-started.html)这款非常火爆常见的主题。  \n\n```\n$ cd xxx.github.io\n$ git clone https://github.com/iissnan/hexo-theme-next themes/next\n```\n\n之后你需要在`xxx.github.io/_config.yml`中配置博客名、语言、作者等基础配置如下(键值之间需要有空白)，可配置的选项可以参考[Hexo配置](https://hexo.io/zh-cn/docs/configuration.html)。\n\n```\n  title: DragonFly的博客\n  subtitle: 我曾七次鄙视自己的灵魂\n  description: iOS开发、ReactNative开发、AR\n  author: DragonFly\n  language: zh-Hans\n  ......\n  theme: next         // 之前下载的主题名称\n```\n\n这儿需要重点注意的是要配置博客提交的github地址。\n```\n  deploy:\n   type: git    //使用Git 发布\n   repo: https://github.com/xxx/xxx.github.io.git    // 刚创建的Github仓库\n```\n另外主题的配置文件也需要做一些修改，相应的文件目录为`xxx.github.io/themes/next/_config.yml`，可配置的选项可以参考[NexT主题配置](http://theme-next.iissnan.com/theme-settings.html)。\n\n##### 新建一篇文章\n\n所有基础框架已经创建完成，接下来你可以开始写第一篇博客了，hexo的命令也很简单，使用两次就记住了。\n\n```\n$ hexo new \"My-New-Post\"  // 这儿是你的文章标题，创建后可以在文档中修改\n```\n更多细节可以参考： [Writing](https://hexo.io/docs/writing.html)\n\n##### 启用本地服务\n\n写完文章后，可以在本地启用服务，来看你的成果。在浏览器中输入`https://localhost:4000`即可访问你的博客主目录。\n```\n$ hexo server //hexo s\n```\n\n##### 发布内容  \n\n测试没问题后，我们就可以生成静态网页文件并发布到GitHub Pages上了。\n\n生成静态文件的命令：\n```\n$ hexo generate  //hexo g\n```\n发布的命令：\n```\n$ hexo deploy //hexo d\n```\n\n以上命令可以简写为`hexo g -d`，这样你的博客已经上传到GitHub了。此时你可以在浏览器里输入fighting300.github.io来访问你的博客。\n另外第一次使用时，你需要在终端配置Github的邮箱和密码。\n\n### 域名绑定  \n\n或许你对你的github域名不满意，想要使用自己独立的域名。那么你可以在阿里云旗下的[万网](https://wanwang.aliyun.com/)购买域名(如`http://fighting300.com`)，购买之后进行实名认证。\n\n![域名购买](http://ojca2gwha.bkt.clouddn.com/Hexo-blog-domain.png)\n\n#### 创建CNAME文件\n为了绑定域名，首先需要在source文件夹下创建一个CNAME文件，文件内容为你要设置的域名(如fighting300.com)，这样将你的域名指向了Github服务器。用Hexo命令deploy后，几分钟后生效，你会看到你的仓库下GitHub Pages的信息已经发生变化。\n\n![GitHub domain](http://ojca2gwha.bkt.clouddn.com/Hexo-blog-domain-page.png)  \n\n#### 添加DNS解析\n阿里云其实有自带的DNS解析服务，但是有小伙伴反馈他的DNS解析服务会有问题(目前使用过程中暂未发现)，可以切换为[DNSPod](https://www.dnspod.cn/)的解析服务。两种DNS的解析配置都很简单，只需要添加对应的IP地址到你的域名配置中即可。该IP地址使用`ping fighting300.github.io`来获取到。\n\n![阿里云DNS配置](http://ojca2gwha.bkt.clouddn.com/Hexo-blog-aliyun.png)\n\n![DNSPod配置](http://ojca2gwha.bkt.clouddn.com/Hexo-blog-dnspod.png)\n\n完成上述步骤后，需要等一段时间上述配置才会生效，最后你的博客已经搭建完成，你可以开启你的博客之旅了。\n\n![My blog](http://ojca2gwha.bkt.clouddn.com/Hexo-blog-review.png)   \n\n本文将持续记录一些hexo使用方法和常见错误的解决方式，如果喜欢，请持续关注本博客。\n\n\n\n#### 常见问题\n##### 1.首页文章显示部分  \n最简单的方案是在文章中添加以下标签内容：  \n`<!--more-->`\n\n##### 2.评论系统支持\n试了几种评论服务，感觉还是[Disqus](https://disqus.com/)的服务比较好，比较麻烦的一点是需要翻墙才能评论。不过为了良好的体验，目前还是使用Disqus吧，最主要它是免费的。接入很简单，现在[网站注册](https://disqus.com/admin/create/),然后在主题配置文件下填写以下内容即可：\n\n```\n# Disqus\ndisqus:\n  enable: true\n  shortname: ***** //这儿填写相应的服务名  \n  count: true\n```\n\n注意使用过程中，要配置Guest Commenting,这样就可以允许所有人在页面评论了。   \n注意，在标签需要关闭评论,添加以下标签即可。  \n```\n  ---\n  comments: false\n  ---\n```\n\n##### 3.统计支持  \n目前发现GoogleAnalysis的统计数据非常丰富，翻墙去体验下吧。\n\n##### 4.添加标签\n\n新建一个页面，命名为tags。命令如下：  \n\n```\n$ hexo new page \"tags\"\n```\n\n编辑刚新建的页面，将页面的类型设置为 tags ，主题将自动为这个页面显示标签云。页面内容如下：  \n\n```\ntitle: tags\ndate: 2016-12-22 12:39:04\ntype: \"tags\"\n```\n\n注意： 如果有启用Disqus评论，默认页面也会带有评论。如果需要关闭，请添加comments字段并将值设置为false，如：\n\n```\ncomments: false\n```\n\n然后在菜单中添加链接，编辑主题配置文件，添加tags到menu中，如下：  \n\n```\nmenu:\n  home: /\n  archives: /archives\n  tags: /tags\n```\n\n\n\n##### 参考文档\n1. [Hexo](https://hexo.io/)!\n2. [NexT](http://theme-next.iissnan.com/getting-started.html)\n3. [troubleshooting](https://hexo.io/docs/troubleshooting.html)\n4. [GitHub](https://github.com/hexojs/hexo/issues).\n","slug":"hello-world","published":1,"updated":"2017-09-25T12:15:29.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj81l545r000ewluvaqchwrc8","content":"<p>其实很久以前就搭建完博客的基础部分，只是懒癌发作，迟迟没有补上文章来总结，但是记录自己的心得还是必要的。下面描述下搭建博客的整个流程和一些问题的解决方案。搭建博客其实有很多种框架，比如可能大家熟悉的<a href=\"https://cn.wordpress.org/\" target=\"_blank\" rel=\"external\">WordPress</a>、<a href=\"https://hexo.io/zh-cn/\" target=\"_blank\" rel=\"external\">Hexo</a>等，这里我们将使用很火很流程的Hexo来作为博客基础框架。</p>\n<p>Hexo是一个快速、简洁且高效的博客框架。Hexo使用Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。<br>搭建博客的大体流程主要分为：<code>GitHub配置</code>、<code>Hexo管理</code>、<code>域名绑定</code>三个步骤，非常简单。</p>\n<h3 id=\"GitHub配置\"><a href=\"#GitHub配置\" class=\"headerlink\" title=\"GitHub配置\"></a>GitHub配置</h3><p>首先需要在<a href=\"https://github.com/\" target=\"_blank\" rel=\"external\">GitHub</a>上注册一个账号(当然估计你们都有了)。然后创建一个仓库，命名为<code>xxx.github.io</code>，xxx会是你注册时的用户名，所以注册账号时认真想个不错的名字吧，因为这个地址会是你的域名(假如你不单独申请域名的话)。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/Hexo-blog-github.png\" alt=\"新建GitHub仓库\">  </p>\n<h3 id=\"Hexo管理\"><a href=\"#Hexo管理\" class=\"headerlink\" title=\"Hexo管理\"></a>Hexo管理</h3><h4 id=\"环境安装\"><a href=\"#环境安装\" class=\"headerlink\" title=\"环境安装\"></a>环境安装</h4><p>在进行下一步前，你需要在你的Mac上安装好git(没安装过的，直接去官网找吧，顺便面壁思过下)和Node.js。</p>\n<p>Node安装的最佳方式是使用nvm，这是Node.js的版本管理器，安装方式很简单。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">// 1. Homebrew 安装方式，此安装方式无需重启</div><div class=\"line\">$ brew install nvm  </div><div class=\"line\">$ mkdir ~/.nvm</div><div class=\"line\">$ export NVM_DIR=~/.nvm</div><div class=\"line\">$ . $(brew --prefix nvm)/nvm.sh</div><div class=\"line\">// 2. curl安装</div><div class=\"line\">$ curl https://raw.github.com/creationix/nvm/master/install.sh | sh</div></pre></td></tr></table></figure>\n<p>安装完nvm后，执行以下命令即可安装Node。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ nvm install stable</div></pre></td></tr></table></figure></p>\n<p>Hexo安装：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ sudo npm install -g hexo-cli</div></pre></td></tr></table></figure></p>\n<p>所有的工具已经安装完成，下面可以创建博客内容，并上传到我们的github仓库了。</p>\n<a id=\"more\"></a>\n<h4 id=\"创建博客\"><a href=\"#创建博客\" class=\"headerlink\" title=\"创建博客\"></a>创建博客</h4><p>接下来需要用Hexo初始化博客，并更改设置，来发布内容到之前创建的GitHub仓库。</p>\n<h5 id=\"初始化博客\"><a href=\"#初始化博客\" class=\"headerlink\" title=\"初始化博客\"></a>初始化博客</h5><p>安装 Hexo 完成后执行下列命令，Hexo将会在指定文件夹中新建博客所需要的文件。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo init xxx.github.io</div><div class=\"line\">$ cd xxx.github.io</div><div class=\"line\">$ npm install</div></pre></td></tr></table></figure></p>\n<p>初始化后，你的文件夹里会有这些内容：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">.</div><div class=\"line\">├── _config.yml        #配置文件</div><div class=\"line\">├── package.json       #数据</div><div class=\"line\">├── scaffolds          #草稿</div><div class=\"line\">├── source             #网站内容</div><div class=\"line\">|   ├── _drafts        #草稿</div><div class=\"line\">|   └── _posts         #文章</div><div class=\"line\">└── themes             #主题</div></pre></td></tr></table></figure></p>\n<h5 id=\"更新配置\"><a href=\"#更新配置\" class=\"headerlink\" title=\"更新配置\"></a>更新配置</h5><p>当然我们自己的博客，要选择好看的主题。Hexo比较好的一点是现在有很多免费的主题可以使用，只需要把主题文件文件拷贝到你的/themes目录下，做简单配置就可以使用该主题了。<br>知乎上有一篇文章罗列了一些<a href=\"https://www.zhihu.com/question/24422335\" target=\"_blank\" rel=\"external\">不错的主题</a>，大家可以参考下。这里我们使用了极简的<a href=\"http://theme-next.iissnan.com/getting-started.html\" target=\"_blank\" rel=\"external\">NexT</a>这款非常火爆常见的主题。  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ cd xxx.github.io</div><div class=\"line\">$ git clone https://github.com/iissnan/hexo-theme-next themes/next</div></pre></td></tr></table></figure>\n<p>之后你需要在<code>xxx.github.io/_config.yml</code>中配置博客名、语言、作者等基础配置如下(键值之间需要有空白)，可配置的选项可以参考<a href=\"https://hexo.io/zh-cn/docs/configuration.html\" target=\"_blank\" rel=\"external\">Hexo配置</a>。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">title: DragonFly的博客</div><div class=\"line\">subtitle: 我曾七次鄙视自己的灵魂</div><div class=\"line\">description: iOS开发、ReactNative开发、AR</div><div class=\"line\">author: DragonFly</div><div class=\"line\">language: zh-Hans</div><div class=\"line\">......</div><div class=\"line\">theme: next         // 之前下载的主题名称</div></pre></td></tr></table></figure>\n<p>这儿需要重点注意的是要配置博客提交的github地址。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">deploy:</div><div class=\"line\"> type: git    //使用Git 发布</div><div class=\"line\"> repo: https://github.com/xxx/xxx.github.io.git    // 刚创建的Github仓库</div></pre></td></tr></table></figure></p>\n<p>另外主题的配置文件也需要做一些修改，相应的文件目录为<code>xxx.github.io/themes/next/_config.yml</code>，可配置的选项可以参考<a href=\"http://theme-next.iissnan.com/theme-settings.html\" target=\"_blank\" rel=\"external\">NexT主题配置</a>。</p>\n<h5 id=\"新建一篇文章\"><a href=\"#新建一篇文章\" class=\"headerlink\" title=\"新建一篇文章\"></a>新建一篇文章</h5><p>所有基础框架已经创建完成，接下来你可以开始写第一篇博客了，hexo的命令也很简单，使用两次就记住了。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo new &quot;My-New-Post&quot;  // 这儿是你的文章标题，创建后可以在文档中修改</div></pre></td></tr></table></figure>\n<p>更多细节可以参考： <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"external\">Writing</a></p>\n<h5 id=\"启用本地服务\"><a href=\"#启用本地服务\" class=\"headerlink\" title=\"启用本地服务\"></a>启用本地服务</h5><p>写完文章后，可以在本地启用服务，来看你的成果。在浏览器中输入<code>https://localhost:4000</code>即可访问你的博客主目录。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo server //hexo s</div></pre></td></tr></table></figure></p>\n<h5 id=\"发布内容\"><a href=\"#发布内容\" class=\"headerlink\" title=\"发布内容\"></a>发布内容</h5><p>测试没问题后，我们就可以生成静态网页文件并发布到GitHub Pages上了。</p>\n<p>生成静态文件的命令：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo generate  //hexo g</div></pre></td></tr></table></figure></p>\n<p>发布的命令：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo deploy //hexo d</div></pre></td></tr></table></figure></p>\n<p>以上命令可以简写为<code>hexo g -d</code>，这样你的博客已经上传到GitHub了。此时你可以在浏览器里输入fighting300.github.io来访问你的博客。<br>另外第一次使用时，你需要在终端配置Github的邮箱和密码。</p>\n<h3 id=\"域名绑定\"><a href=\"#域名绑定\" class=\"headerlink\" title=\"域名绑定\"></a>域名绑定</h3><p>或许你对你的github域名不满意，想要使用自己独立的域名。那么你可以在阿里云旗下的<a href=\"https://wanwang.aliyun.com/\" target=\"_blank\" rel=\"external\">万网</a>购买域名(如<code>http://fighting300.com</code>)，购买之后进行实名认证。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/Hexo-blog-domain.png\" alt=\"域名购买\"></p>\n<h4 id=\"创建CNAME文件\"><a href=\"#创建CNAME文件\" class=\"headerlink\" title=\"创建CNAME文件\"></a>创建CNAME文件</h4><p>为了绑定域名，首先需要在source文件夹下创建一个CNAME文件，文件内容为你要设置的域名(如fighting300.com)，这样将你的域名指向了Github服务器。用Hexo命令deploy后，几分钟后生效，你会看到你的仓库下GitHub Pages的信息已经发生变化。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/Hexo-blog-domain-page.png\" alt=\"GitHub domain\">  </p>\n<h4 id=\"添加DNS解析\"><a href=\"#添加DNS解析\" class=\"headerlink\" title=\"添加DNS解析\"></a>添加DNS解析</h4><p>阿里云其实有自带的DNS解析服务，但是有小伙伴反馈他的DNS解析服务会有问题(目前使用过程中暂未发现)，可以切换为<a href=\"https://www.dnspod.cn/\" target=\"_blank\" rel=\"external\">DNSPod</a>的解析服务。两种DNS的解析配置都很简单，只需要添加对应的IP地址到你的域名配置中即可。该IP地址使用<code>ping fighting300.github.io</code>来获取到。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/Hexo-blog-aliyun.png\" alt=\"阿里云DNS配置\"></p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/Hexo-blog-dnspod.png\" alt=\"DNSPod配置\"></p>\n<p>完成上述步骤后，需要等一段时间上述配置才会生效，最后你的博客已经搭建完成，你可以开启你的博客之旅了。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/Hexo-blog-review.png\" alt=\"My blog\">   </p>\n<p>本文将持续记录一些hexo使用方法和常见错误的解决方式，如果喜欢，请持续关注本博客。</p>\n<h4 id=\"常见问题\"><a href=\"#常见问题\" class=\"headerlink\" title=\"常见问题\"></a>常见问题</h4><h5 id=\"1-首页文章显示部分\"><a href=\"#1-首页文章显示部分\" class=\"headerlink\" title=\"1.首页文章显示部分\"></a>1.首页文章显示部分</h5><p>最简单的方案是在文章中添加以下标签内容：<br><code>&lt;!--more--&gt;</code></p>\n<h5 id=\"2-评论系统支持\"><a href=\"#2-评论系统支持\" class=\"headerlink\" title=\"2.评论系统支持\"></a>2.评论系统支持</h5><p>试了几种评论服务，感觉还是<a href=\"https://disqus.com/\" target=\"_blank\" rel=\"external\">Disqus</a>的服务比较好，比较麻烦的一点是需要翻墙才能评论。不过为了良好的体验，目前还是使用Disqus吧，最主要它是免费的。接入很简单，现在<a href=\"https://disqus.com/admin/create/\" target=\"_blank\" rel=\"external\">网站注册</a>,然后在主题配置文件下填写以下内容即可：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"># Disqus</div><div class=\"line\">disqus:</div><div class=\"line\">  enable: true</div><div class=\"line\">  shortname: ***** //这儿填写相应的服务名  </div><div class=\"line\">  count: true</div></pre></td></tr></table></figure>\n<p>注意使用过程中，要配置Guest Commenting,这样就可以允许所有人在页面评论了。<br>注意，在标签需要关闭评论,添加以下标签即可。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">---</div><div class=\"line\">comments: false</div><div class=\"line\">---</div></pre></td></tr></table></figure></p>\n<h5 id=\"3-统计支持\"><a href=\"#3-统计支持\" class=\"headerlink\" title=\"3.统计支持\"></a>3.统计支持</h5><p>目前发现GoogleAnalysis的统计数据非常丰富，翻墙去体验下吧。</p>\n<h5 id=\"4-添加标签\"><a href=\"#4-添加标签\" class=\"headerlink\" title=\"4.添加标签\"></a>4.添加标签</h5><p>新建一个页面，命名为tags。命令如下：  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo new page &quot;tags&quot;</div></pre></td></tr></table></figure>\n<p>编辑刚新建的页面，将页面的类型设置为 tags ，主题将自动为这个页面显示标签云。页面内容如下：  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">title: tags</div><div class=\"line\">date: 2016-12-22 12:39:04</div><div class=\"line\">type: &quot;tags&quot;</div></pre></td></tr></table></figure>\n<p>注意： 如果有启用Disqus评论，默认页面也会带有评论。如果需要关闭，请添加comments字段并将值设置为false，如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">comments: false</div></pre></td></tr></table></figure>\n<p>然后在菜单中添加链接，编辑主题配置文件，添加tags到menu中，如下：  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">menu:</div><div class=\"line\">  home: /</div><div class=\"line\">  archives: /archives</div><div class=\"line\">  tags: /tags</div></pre></td></tr></table></figure>\n<h5 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h5><ol>\n<li><a href=\"https://hexo.io/\" target=\"_blank\" rel=\"external\">Hexo</a>!</li>\n<li><a href=\"http://theme-next.iissnan.com/getting-started.html\" target=\"_blank\" rel=\"external\">NexT</a></li>\n<li><a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"external\">troubleshooting</a></li>\n<li><a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"external\">GitHub</a>.</li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>其实很久以前就搭建完博客的基础部分，只是懒癌发作，迟迟没有补上文章来总结，但是记录自己的心得还是必要的。下面描述下搭建博客的整个流程和一些问题的解决方案。搭建博客其实有很多种框架，比如可能大家熟悉的<a href=\"https://cn.wordpress.org/\" target=\"_blank\" rel=\"external\">WordPress</a>、<a href=\"https://hexo.io/zh-cn/\" target=\"_blank\" rel=\"external\">Hexo</a>等，这里我们将使用很火很流程的Hexo来作为博客基础框架。</p>\n<p>Hexo是一个快速、简洁且高效的博客框架。Hexo使用Markdown（或其他渲染引擎）解析文章，在几秒内，即可利用靓丽的主题生成静态网页。<br>搭建博客的大体流程主要分为：<code>GitHub配置</code>、<code>Hexo管理</code>、<code>域名绑定</code>三个步骤，非常简单。</p>\n<h3 id=\"GitHub配置\"><a href=\"#GitHub配置\" class=\"headerlink\" title=\"GitHub配置\"></a>GitHub配置</h3><p>首先需要在<a href=\"https://github.com/\" target=\"_blank\" rel=\"external\">GitHub</a>上注册一个账号(当然估计你们都有了)。然后创建一个仓库，命名为<code>xxx.github.io</code>，xxx会是你注册时的用户名，所以注册账号时认真想个不错的名字吧，因为这个地址会是你的域名(假如你不单独申请域名的话)。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/Hexo-blog-github.png\" alt=\"新建GitHub仓库\">  </p>\n<h3 id=\"Hexo管理\"><a href=\"#Hexo管理\" class=\"headerlink\" title=\"Hexo管理\"></a>Hexo管理</h3><h4 id=\"环境安装\"><a href=\"#环境安装\" class=\"headerlink\" title=\"环境安装\"></a>环境安装</h4><p>在进行下一步前，你需要在你的Mac上安装好git(没安装过的，直接去官网找吧，顺便面壁思过下)和Node.js。</p>\n<p>Node安装的最佳方式是使用nvm，这是Node.js的版本管理器，安装方式很简单。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">// 1. Homebrew 安装方式，此安装方式无需重启</div><div class=\"line\">$ brew install nvm  </div><div class=\"line\">$ mkdir ~/.nvm</div><div class=\"line\">$ export NVM_DIR=~/.nvm</div><div class=\"line\">$ . $(brew --prefix nvm)/nvm.sh</div><div class=\"line\">// 2. curl安装</div><div class=\"line\">$ curl https://raw.github.com/creationix/nvm/master/install.sh | sh</div></pre></td></tr></table></figure>\n<p>安装完nvm后，执行以下命令即可安装Node。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ nvm install stable</div></pre></td></tr></table></figure></p>\n<p>Hexo安装：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ sudo npm install -g hexo-cli</div></pre></td></tr></table></figure></p>\n<p>所有的工具已经安装完成，下面可以创建博客内容，并上传到我们的github仓库了。</p>","more":"<h4 id=\"创建博客\"><a href=\"#创建博客\" class=\"headerlink\" title=\"创建博客\"></a>创建博客</h4><p>接下来需要用Hexo初始化博客，并更改设置，来发布内容到之前创建的GitHub仓库。</p>\n<h5 id=\"初始化博客\"><a href=\"#初始化博客\" class=\"headerlink\" title=\"初始化博客\"></a>初始化博客</h5><p>安装 Hexo 完成后执行下列命令，Hexo将会在指定文件夹中新建博客所需要的文件。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo init xxx.github.io</div><div class=\"line\">$ cd xxx.github.io</div><div class=\"line\">$ npm install</div></pre></td></tr></table></figure></p>\n<p>初始化后，你的文件夹里会有这些内容：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">.</div><div class=\"line\">├── _config.yml        #配置文件</div><div class=\"line\">├── package.json       #数据</div><div class=\"line\">├── scaffolds          #草稿</div><div class=\"line\">├── source             #网站内容</div><div class=\"line\">|   ├── _drafts        #草稿</div><div class=\"line\">|   └── _posts         #文章</div><div class=\"line\">└── themes             #主题</div></pre></td></tr></table></figure></p>\n<h5 id=\"更新配置\"><a href=\"#更新配置\" class=\"headerlink\" title=\"更新配置\"></a>更新配置</h5><p>当然我们自己的博客，要选择好看的主题。Hexo比较好的一点是现在有很多免费的主题可以使用，只需要把主题文件文件拷贝到你的/themes目录下，做简单配置就可以使用该主题了。<br>知乎上有一篇文章罗列了一些<a href=\"https://www.zhihu.com/question/24422335\" target=\"_blank\" rel=\"external\">不错的主题</a>，大家可以参考下。这里我们使用了极简的<a href=\"http://theme-next.iissnan.com/getting-started.html\" target=\"_blank\" rel=\"external\">NexT</a>这款非常火爆常见的主题。  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ cd xxx.github.io</div><div class=\"line\">$ git clone https://github.com/iissnan/hexo-theme-next themes/next</div></pre></td></tr></table></figure>\n<p>之后你需要在<code>xxx.github.io/_config.yml</code>中配置博客名、语言、作者等基础配置如下(键值之间需要有空白)，可配置的选项可以参考<a href=\"https://hexo.io/zh-cn/docs/configuration.html\" target=\"_blank\" rel=\"external\">Hexo配置</a>。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">title: DragonFly的博客</div><div class=\"line\">subtitle: 我曾七次鄙视自己的灵魂</div><div class=\"line\">description: iOS开发、ReactNative开发、AR</div><div class=\"line\">author: DragonFly</div><div class=\"line\">language: zh-Hans</div><div class=\"line\">......</div><div class=\"line\">theme: next         // 之前下载的主题名称</div></pre></td></tr></table></figure>\n<p>这儿需要重点注意的是要配置博客提交的github地址。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">deploy:</div><div class=\"line\"> type: git    //使用Git 发布</div><div class=\"line\"> repo: https://github.com/xxx/xxx.github.io.git    // 刚创建的Github仓库</div></pre></td></tr></table></figure></p>\n<p>另外主题的配置文件也需要做一些修改，相应的文件目录为<code>xxx.github.io/themes/next/_config.yml</code>，可配置的选项可以参考<a href=\"http://theme-next.iissnan.com/theme-settings.html\" target=\"_blank\" rel=\"external\">NexT主题配置</a>。</p>\n<h5 id=\"新建一篇文章\"><a href=\"#新建一篇文章\" class=\"headerlink\" title=\"新建一篇文章\"></a>新建一篇文章</h5><p>所有基础框架已经创建完成，接下来你可以开始写第一篇博客了，hexo的命令也很简单，使用两次就记住了。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo new &quot;My-New-Post&quot;  // 这儿是你的文章标题，创建后可以在文档中修改</div></pre></td></tr></table></figure>\n<p>更多细节可以参考： <a href=\"https://hexo.io/docs/writing.html\" target=\"_blank\" rel=\"external\">Writing</a></p>\n<h5 id=\"启用本地服务\"><a href=\"#启用本地服务\" class=\"headerlink\" title=\"启用本地服务\"></a>启用本地服务</h5><p>写完文章后，可以在本地启用服务，来看你的成果。在浏览器中输入<code>https://localhost:4000</code>即可访问你的博客主目录。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo server //hexo s</div></pre></td></tr></table></figure></p>\n<h5 id=\"发布内容\"><a href=\"#发布内容\" class=\"headerlink\" title=\"发布内容\"></a>发布内容</h5><p>测试没问题后，我们就可以生成静态网页文件并发布到GitHub Pages上了。</p>\n<p>生成静态文件的命令：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo generate  //hexo g</div></pre></td></tr></table></figure></p>\n<p>发布的命令：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo deploy //hexo d</div></pre></td></tr></table></figure></p>\n<p>以上命令可以简写为<code>hexo g -d</code>，这样你的博客已经上传到GitHub了。此时你可以在浏览器里输入fighting300.github.io来访问你的博客。<br>另外第一次使用时，你需要在终端配置Github的邮箱和密码。</p>\n<h3 id=\"域名绑定\"><a href=\"#域名绑定\" class=\"headerlink\" title=\"域名绑定\"></a>域名绑定</h3><p>或许你对你的github域名不满意，想要使用自己独立的域名。那么你可以在阿里云旗下的<a href=\"https://wanwang.aliyun.com/\" target=\"_blank\" rel=\"external\">万网</a>购买域名(如<code>http://fighting300.com</code>)，购买之后进行实名认证。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/Hexo-blog-domain.png\" alt=\"域名购买\"></p>\n<h4 id=\"创建CNAME文件\"><a href=\"#创建CNAME文件\" class=\"headerlink\" title=\"创建CNAME文件\"></a>创建CNAME文件</h4><p>为了绑定域名，首先需要在source文件夹下创建一个CNAME文件，文件内容为你要设置的域名(如fighting300.com)，这样将你的域名指向了Github服务器。用Hexo命令deploy后，几分钟后生效，你会看到你的仓库下GitHub Pages的信息已经发生变化。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/Hexo-blog-domain-page.png\" alt=\"GitHub domain\">  </p>\n<h4 id=\"添加DNS解析\"><a href=\"#添加DNS解析\" class=\"headerlink\" title=\"添加DNS解析\"></a>添加DNS解析</h4><p>阿里云其实有自带的DNS解析服务，但是有小伙伴反馈他的DNS解析服务会有问题(目前使用过程中暂未发现)，可以切换为<a href=\"https://www.dnspod.cn/\" target=\"_blank\" rel=\"external\">DNSPod</a>的解析服务。两种DNS的解析配置都很简单，只需要添加对应的IP地址到你的域名配置中即可。该IP地址使用<code>ping fighting300.github.io</code>来获取到。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/Hexo-blog-aliyun.png\" alt=\"阿里云DNS配置\"></p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/Hexo-blog-dnspod.png\" alt=\"DNSPod配置\"></p>\n<p>完成上述步骤后，需要等一段时间上述配置才会生效，最后你的博客已经搭建完成，你可以开启你的博客之旅了。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/Hexo-blog-review.png\" alt=\"My blog\">   </p>\n<p>本文将持续记录一些hexo使用方法和常见错误的解决方式，如果喜欢，请持续关注本博客。</p>\n<h4 id=\"常见问题\"><a href=\"#常见问题\" class=\"headerlink\" title=\"常见问题\"></a>常见问题</h4><h5 id=\"1-首页文章显示部分\"><a href=\"#1-首页文章显示部分\" class=\"headerlink\" title=\"1.首页文章显示部分\"></a>1.首页文章显示部分</h5><p>最简单的方案是在文章中添加以下标签内容：<br><code>&lt;!--more--&gt;</code></p>\n<h5 id=\"2-评论系统支持\"><a href=\"#2-评论系统支持\" class=\"headerlink\" title=\"2.评论系统支持\"></a>2.评论系统支持</h5><p>试了几种评论服务，感觉还是<a href=\"https://disqus.com/\" target=\"_blank\" rel=\"external\">Disqus</a>的服务比较好，比较麻烦的一点是需要翻墙才能评论。不过为了良好的体验，目前还是使用Disqus吧，最主要它是免费的。接入很简单，现在<a href=\"https://disqus.com/admin/create/\" target=\"_blank\" rel=\"external\">网站注册</a>,然后在主题配置文件下填写以下内容即可：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\"># Disqus</div><div class=\"line\">disqus:</div><div class=\"line\">  enable: true</div><div class=\"line\">  shortname: ***** //这儿填写相应的服务名  </div><div class=\"line\">  count: true</div></pre></td></tr></table></figure>\n<p>注意使用过程中，要配置Guest Commenting,这样就可以允许所有人在页面评论了。<br>注意，在标签需要关闭评论,添加以下标签即可。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">---</div><div class=\"line\">comments: false</div><div class=\"line\">---</div></pre></td></tr></table></figure></p>\n<h5 id=\"3-统计支持\"><a href=\"#3-统计支持\" class=\"headerlink\" title=\"3.统计支持\"></a>3.统计支持</h5><p>目前发现GoogleAnalysis的统计数据非常丰富，翻墙去体验下吧。</p>\n<h5 id=\"4-添加标签\"><a href=\"#4-添加标签\" class=\"headerlink\" title=\"4.添加标签\"></a>4.添加标签</h5><p>新建一个页面，命名为tags。命令如下：  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ hexo new page &quot;tags&quot;</div></pre></td></tr></table></figure>\n<p>编辑刚新建的页面，将页面的类型设置为 tags ，主题将自动为这个页面显示标签云。页面内容如下：  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">title: tags</div><div class=\"line\">date: 2016-12-22 12:39:04</div><div class=\"line\">type: &quot;tags&quot;</div></pre></td></tr></table></figure>\n<p>注意： 如果有启用Disqus评论，默认页面也会带有评论。如果需要关闭，请添加comments字段并将值设置为false，如：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">comments: false</div></pre></td></tr></table></figure>\n<p>然后在菜单中添加链接，编辑主题配置文件，添加tags到menu中，如下：  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">menu:</div><div class=\"line\">  home: /</div><div class=\"line\">  archives: /archives</div><div class=\"line\">  tags: /tags</div></pre></td></tr></table></figure>\n<h5 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h5><ol>\n<li><a href=\"https://hexo.io/\" target=\"_blank\" rel=\"external\">Hexo</a>!</li>\n<li><a href=\"http://theme-next.iissnan.com/getting-started.html\" target=\"_blank\" rel=\"external\">NexT</a></li>\n<li><a href=\"https://hexo.io/docs/troubleshooting.html\" target=\"_blank\" rel=\"external\">troubleshooting</a></li>\n<li><a href=\"https://github.com/hexojs/hexo/issues\" target=\"_blank\" rel=\"external\">GitHub</a>.</li>\n</ol>"},{"title":"iOS Bonjour的使用-本地通信/智能交互","date":"2017-07-21T10:34:41.000Z","_content":"\n之前一直考虑在local现场怎么与别的用户通信，后来陆续了解了苹果的[Bonjour](https://developer.apple.com/library/content/documentation/Cocoa/Conceptual/NetServices/Introduction.html)。现在简单写一篇Bonjour的入门介绍。\n\n#### Bonjour介绍  \n\nbonjour其实来自法语，是你好的意思。而Bonjour服务是苹果公司发布的一个基于ZEROCONF工作组(IETF下属小组)的工作,用于实现零配置网络联网的解决方案。Bonjour是基于IP层协议的,简单来说,就是一套解决方案,能够不需要复杂的配置,即可互相发现彼此的解决方案。可以用它来轻松探测并连接到相同网络中的其他设备，并与别的智能硬件进行交互或者其他操作。典型的Bonjour应用有Remote、AirPrint等。\n\n![Bonjour-overview](http://ojca2gwha.bkt.clouddn.com/iOS-bonjour-Overview.png)\n\n为了实现简单配置网络，Bonjour做了以下三点：   \n1. 寻址(分配IP地址给主机）\n一个在网络中的设备需要有一个自己的IP。有了IP地址,我们才能基于IP协议进行通信。对于IPV6标准,IP协议已经包括了自动寻找IP地址的功能。但是目前仍然普遍使用的IPV4不包含本地链路寻址功能。而Bonjour会在本地网络选择一个随机的IP地址进行测试,如果已经被占用,则继续挑选另外一个地址，直到选到可用的IP地址。\n\n2. 命名(使用名字而不是IP地址来代表主机）\nBonjour还实现了命名和解析功能，保证了我们服务的名字在本地网络是唯一的,并且把别人对我们名字的查询指向正确的IP地址和端口，而不是以IP地址这样不易读的方式来作为服务的标志。\n而且Bonjour在系统级别上添加了一个mDNSResponder服务来处理请求和发送回复,从系统级层面上处理,我们就无需在应用内自己监听和返回IP地址,只需到系统内注册服务即可。减少了我们应用的工作量和提高了稳定性。\n\n3. 服务搜索（自动在网络搜索服务）\nBonjour可以只需指定所需服务的类型，即可收到本地网络上可用的设备列表。设备在本地网络发出请求,说我需要\"XXX\"类型的服务,例如：我要打印机服务。所有打印机服务的设备回应自己的名字。\n\n<!--more-->\n#### Bonjour API\n\nCocoa中网络框架有三层，最底层的是基于 BSD socket库，然后是 Cocoa 中基于 C 的 CFNetwork，最上面一层是 Cocoa 中 Bonjour。通常我们无需与 socket 打交道，我们会使用经 Cocoa 封装的 CFNetwork 和 Bonjour 来完成大多数工作。  \n> cocoa 很多组件都有两种实现，一种是基于 C 的以 CF 开头的类（CF=Core Foundation），这是比较底层的；另一种是基于 Obj-C 的以 NS 开头的类(NS=Next Step)，这种类抽象层次更高，易于使用。对于网络框架也一样。Bonjour 中 NSNetService 也有对应的 CFNetService，NSInputStream 有对应的 CFInputStream。  \n\n通过 Bonjour，一个应用程序publish一个网络服务 service，然后网络中的其他程序就能自动发现这个 service，从而可以向这个 service 查询其 ip 和 port，然后通过获得的 ip 和 port 建立 socket 链接进行通信。通常我们是通过 NSNetService 和 NSNetServiceBrowser 来使用 Bonjour 的，前者用于建立与发布 service，后者用于监听查询网络上的 service。\n\n![Bonjour-API](http://ojca2gwha.bkt.clouddn.com/iOS-bonjour-API.png)\n\n#### 建立连接\n\n简单来说，建立Bonjour连接一般需要三个步骤，即服务端发布服务、客户端浏览服务、客户端/服务端交互。\n\n![Bonjour-API](http://ojca2gwha.bkt.clouddn.com/iOS-bonjour-API1.png)\n##### 客户端发布服务\n\n首先通过`NetService`对象初始化服务，指定服务的域、类型、名称和端口，在同一网络中，服务类型名必须唯一，这样才能精准定位服务。\nBonjour操作也需要异步进行，以免长时间阻碍主线程，所以我们将发布任务交给当前run loop去调度。   \n\n```\n    func setupService(){\n        let service = NetService.init(domain: \"local.\", type: \"_dragon._tcp\", name: \"dragon\", port: 2333)\n        service.schedule(in: RunLoop.current, forMode: .commonModes)\n        service.delegate = self\n        let dictData = \"http://fighting300.github.io\".data(using: String.Encoding.utf8)\n        let data = NetService.data(fromTXTRecord: [\"node\":dictData!])\n        service.setTXTRecord(data)\n        service.publish()\n        self.service = service\n    }\n```\n\n另外需要实现NetService协议`NetServiceDelegate`的代理方法跟踪服务发布信息。  \n\n```\n  func netServiceWillPublish(_ sender: NetService) {\n      print(\"----netServiceWillPublish\")\n  }\n  func netService(_ sender: NetService, didNotPublish errorDict: [String : NSNumber]) {\n      print(\"----netService didNotPublish\")\n  }\n\n```\n\n##### 客户端浏览服务\n\n服务发布成功后，会在代理方法中接受到发布的消息，这时候要在客户端通过`NetServiceBrowser`对象来浏览本地的服务，并展示本地网络中可用的服务。\n可以通过`searchForServices`方法指定需要查找的服务类型和查找的域，然后运行在mainRunLoop中。\n\n```\n    func netServiceDidPublish(_ sender: NetService) {\n        print(\"----netService didPublish\")\n        let browser = NetServiceBrowser()\n        browser.delegate = self\n        browser.searchForServices(ofType: \"_WE._tcp\", inDomain: \"local.\")\n        browser.schedule(in: RunLoop.current, forMode: .commonModes)\n        RunLoop.current.run(until: Date.init(timeIntervalSinceNow: 300))\n    }\n\n```\n\n同时实现NetServiceBrowser的代理`NetServiceBrowserDelegate`方法`netServiceBrowser(_ browser: NetServiceBrowser, didFind service: NetService, moreComing: Bool)`来处理相应服务的解析。当前代码实例中没有选择服务的服务，直接对扫描到的服务来做解析。\n\n```\n    func netServiceBrowser(_ browser: NetServiceBrowser, didFind service: NetService, moreComing: Bool) {\n        print(\"----netServiceBrowser didFind\", service.domain, service.type, service.name, service.port,service)\n        // 在界面选择对应的service\n        self.service = service\n        service.delegate = self\n        service.resolve(withTimeout: 5)\n    }\n\n    func netServiceBrowser(_ browser: NetServiceBrowser, didRemove service: NetService, moreComing: Bool) {\n        print(\"----netServiceBrowser didRemove\")\n    }\n```\n##### 客户端/服务端交互\n\n最后，可以在NetService代理的解析方法里`func netServiceDidResolveAddress(_ sender: NetService)`，拿到名称、类型、域、主机名和ip地址等信息。\n\n```\n    func netServiceWillResolve(_ sender: NetService) {\n        print(\"----netService willResolve\")\n    }\n\n    func netServiceDidResolveAddress(_ sender: NetService) {\n        print(\"----netService didResolveAddress\", sender.name, sender.addresses, sender.hostName, sender.addresses?.first)\n        let data = sender.txtRecordData()\n        let dict = NetService.dictionary(fromTXTRecord: data!)\n        let info = String.init(data: dict[\"node\"]!, encoding: String.Encoding.utf8)\n        print(\"mac info = \",info);\n\n    }\n\n    func netService(_ sender: NetService, didNotResolve errorDict: [String : NSNumber]) {\n        print(\"----netService didNotResolve \", errorDict)\n    }\n\n    func netServiceDidStop(_ sender: NetService) {\n        print(\"----netServiceDidStop\")\n    }\n\n    func netService(_ sender: NetService, didUpdateTXTRecord data: Data) {\n        print(\"----netService didUpdateTXTRecord\")\n    }\n\n    func netService(_ sender: NetService, didAcceptConnectionWith inputStream: InputStream, outputStream: OutputStream) {\n        print(\"----netService didAcceptConnectionWith\")\n    }\n\n    // MARK: util 获取ip地址\n    func IPFrom(data: Data) -> String {\n      let dataIn: NSData = data as NSData\n      var storage = sockaddr_storage()\n      dataIn.getBytes(&storage, length: MemoryLayout<sockaddr_storage>.size)\n      if Int32(storage.ss_family) == AF_INET {\n          let addr4 = withUnsafePointer(to: &storage) {\n              $0.withMemoryRebound(to: sockaddr_in.self, capacity: 1) {\n                  $0.pointee\n              }\n          }\n          let ipString =  String(cString: inet_ntoa(addr4.sin_addr), encoding: .ascii)\n          print(\"ip\", ipString)\n          return ipString\n      }\n      return \"\"\n    }\n```\n\n之后依靠以上获取的信息，需要通过Socket/Streams建立连接来进行通信，本篇文章不对这部分做更多的介绍，后续有时间再补充完整。\n\n##### 参考    \n1. http://mobileorchard.com/tutorial-networking-and-bonjour-on-iphone/\n2. https://developer.apple.com/library/content/documentation/Networking/Conceptual/NSNetServiceProgGuide/Introduction.html#//apple_ref/doc/uid/TP40002520-SW2\n3. http://www.cocoachina.com/ios/20150918/13434.html\n","source":"_posts/iOS-bonjour.md","raw":"---\ntitle: iOS Bonjour的使用-本地通信/智能交互\ndate: 2017-07-21 18:34:41\ntags: [iOS, Bonjour]\ncategories: iOS\n---\n\n之前一直考虑在local现场怎么与别的用户通信，后来陆续了解了苹果的[Bonjour](https://developer.apple.com/library/content/documentation/Cocoa/Conceptual/NetServices/Introduction.html)。现在简单写一篇Bonjour的入门介绍。\n\n#### Bonjour介绍  \n\nbonjour其实来自法语，是你好的意思。而Bonjour服务是苹果公司发布的一个基于ZEROCONF工作组(IETF下属小组)的工作,用于实现零配置网络联网的解决方案。Bonjour是基于IP层协议的,简单来说,就是一套解决方案,能够不需要复杂的配置,即可互相发现彼此的解决方案。可以用它来轻松探测并连接到相同网络中的其他设备，并与别的智能硬件进行交互或者其他操作。典型的Bonjour应用有Remote、AirPrint等。\n\n![Bonjour-overview](http://ojca2gwha.bkt.clouddn.com/iOS-bonjour-Overview.png)\n\n为了实现简单配置网络，Bonjour做了以下三点：   \n1. 寻址(分配IP地址给主机）\n一个在网络中的设备需要有一个自己的IP。有了IP地址,我们才能基于IP协议进行通信。对于IPV6标准,IP协议已经包括了自动寻找IP地址的功能。但是目前仍然普遍使用的IPV4不包含本地链路寻址功能。而Bonjour会在本地网络选择一个随机的IP地址进行测试,如果已经被占用,则继续挑选另外一个地址，直到选到可用的IP地址。\n\n2. 命名(使用名字而不是IP地址来代表主机）\nBonjour还实现了命名和解析功能，保证了我们服务的名字在本地网络是唯一的,并且把别人对我们名字的查询指向正确的IP地址和端口，而不是以IP地址这样不易读的方式来作为服务的标志。\n而且Bonjour在系统级别上添加了一个mDNSResponder服务来处理请求和发送回复,从系统级层面上处理,我们就无需在应用内自己监听和返回IP地址,只需到系统内注册服务即可。减少了我们应用的工作量和提高了稳定性。\n\n3. 服务搜索（自动在网络搜索服务）\nBonjour可以只需指定所需服务的类型，即可收到本地网络上可用的设备列表。设备在本地网络发出请求,说我需要\"XXX\"类型的服务,例如：我要打印机服务。所有打印机服务的设备回应自己的名字。\n\n<!--more-->\n#### Bonjour API\n\nCocoa中网络框架有三层，最底层的是基于 BSD socket库，然后是 Cocoa 中基于 C 的 CFNetwork，最上面一层是 Cocoa 中 Bonjour。通常我们无需与 socket 打交道，我们会使用经 Cocoa 封装的 CFNetwork 和 Bonjour 来完成大多数工作。  \n> cocoa 很多组件都有两种实现，一种是基于 C 的以 CF 开头的类（CF=Core Foundation），这是比较底层的；另一种是基于 Obj-C 的以 NS 开头的类(NS=Next Step)，这种类抽象层次更高，易于使用。对于网络框架也一样。Bonjour 中 NSNetService 也有对应的 CFNetService，NSInputStream 有对应的 CFInputStream。  \n\n通过 Bonjour，一个应用程序publish一个网络服务 service，然后网络中的其他程序就能自动发现这个 service，从而可以向这个 service 查询其 ip 和 port，然后通过获得的 ip 和 port 建立 socket 链接进行通信。通常我们是通过 NSNetService 和 NSNetServiceBrowser 来使用 Bonjour 的，前者用于建立与发布 service，后者用于监听查询网络上的 service。\n\n![Bonjour-API](http://ojca2gwha.bkt.clouddn.com/iOS-bonjour-API.png)\n\n#### 建立连接\n\n简单来说，建立Bonjour连接一般需要三个步骤，即服务端发布服务、客户端浏览服务、客户端/服务端交互。\n\n![Bonjour-API](http://ojca2gwha.bkt.clouddn.com/iOS-bonjour-API1.png)\n##### 客户端发布服务\n\n首先通过`NetService`对象初始化服务，指定服务的域、类型、名称和端口，在同一网络中，服务类型名必须唯一，这样才能精准定位服务。\nBonjour操作也需要异步进行，以免长时间阻碍主线程，所以我们将发布任务交给当前run loop去调度。   \n\n```\n    func setupService(){\n        let service = NetService.init(domain: \"local.\", type: \"_dragon._tcp\", name: \"dragon\", port: 2333)\n        service.schedule(in: RunLoop.current, forMode: .commonModes)\n        service.delegate = self\n        let dictData = \"http://fighting300.github.io\".data(using: String.Encoding.utf8)\n        let data = NetService.data(fromTXTRecord: [\"node\":dictData!])\n        service.setTXTRecord(data)\n        service.publish()\n        self.service = service\n    }\n```\n\n另外需要实现NetService协议`NetServiceDelegate`的代理方法跟踪服务发布信息。  \n\n```\n  func netServiceWillPublish(_ sender: NetService) {\n      print(\"----netServiceWillPublish\")\n  }\n  func netService(_ sender: NetService, didNotPublish errorDict: [String : NSNumber]) {\n      print(\"----netService didNotPublish\")\n  }\n\n```\n\n##### 客户端浏览服务\n\n服务发布成功后，会在代理方法中接受到发布的消息，这时候要在客户端通过`NetServiceBrowser`对象来浏览本地的服务，并展示本地网络中可用的服务。\n可以通过`searchForServices`方法指定需要查找的服务类型和查找的域，然后运行在mainRunLoop中。\n\n```\n    func netServiceDidPublish(_ sender: NetService) {\n        print(\"----netService didPublish\")\n        let browser = NetServiceBrowser()\n        browser.delegate = self\n        browser.searchForServices(ofType: \"_WE._tcp\", inDomain: \"local.\")\n        browser.schedule(in: RunLoop.current, forMode: .commonModes)\n        RunLoop.current.run(until: Date.init(timeIntervalSinceNow: 300))\n    }\n\n```\n\n同时实现NetServiceBrowser的代理`NetServiceBrowserDelegate`方法`netServiceBrowser(_ browser: NetServiceBrowser, didFind service: NetService, moreComing: Bool)`来处理相应服务的解析。当前代码实例中没有选择服务的服务，直接对扫描到的服务来做解析。\n\n```\n    func netServiceBrowser(_ browser: NetServiceBrowser, didFind service: NetService, moreComing: Bool) {\n        print(\"----netServiceBrowser didFind\", service.domain, service.type, service.name, service.port,service)\n        // 在界面选择对应的service\n        self.service = service\n        service.delegate = self\n        service.resolve(withTimeout: 5)\n    }\n\n    func netServiceBrowser(_ browser: NetServiceBrowser, didRemove service: NetService, moreComing: Bool) {\n        print(\"----netServiceBrowser didRemove\")\n    }\n```\n##### 客户端/服务端交互\n\n最后，可以在NetService代理的解析方法里`func netServiceDidResolveAddress(_ sender: NetService)`，拿到名称、类型、域、主机名和ip地址等信息。\n\n```\n    func netServiceWillResolve(_ sender: NetService) {\n        print(\"----netService willResolve\")\n    }\n\n    func netServiceDidResolveAddress(_ sender: NetService) {\n        print(\"----netService didResolveAddress\", sender.name, sender.addresses, sender.hostName, sender.addresses?.first)\n        let data = sender.txtRecordData()\n        let dict = NetService.dictionary(fromTXTRecord: data!)\n        let info = String.init(data: dict[\"node\"]!, encoding: String.Encoding.utf8)\n        print(\"mac info = \",info);\n\n    }\n\n    func netService(_ sender: NetService, didNotResolve errorDict: [String : NSNumber]) {\n        print(\"----netService didNotResolve \", errorDict)\n    }\n\n    func netServiceDidStop(_ sender: NetService) {\n        print(\"----netServiceDidStop\")\n    }\n\n    func netService(_ sender: NetService, didUpdateTXTRecord data: Data) {\n        print(\"----netService didUpdateTXTRecord\")\n    }\n\n    func netService(_ sender: NetService, didAcceptConnectionWith inputStream: InputStream, outputStream: OutputStream) {\n        print(\"----netService didAcceptConnectionWith\")\n    }\n\n    // MARK: util 获取ip地址\n    func IPFrom(data: Data) -> String {\n      let dataIn: NSData = data as NSData\n      var storage = sockaddr_storage()\n      dataIn.getBytes(&storage, length: MemoryLayout<sockaddr_storage>.size)\n      if Int32(storage.ss_family) == AF_INET {\n          let addr4 = withUnsafePointer(to: &storage) {\n              $0.withMemoryRebound(to: sockaddr_in.self, capacity: 1) {\n                  $0.pointee\n              }\n          }\n          let ipString =  String(cString: inet_ntoa(addr4.sin_addr), encoding: .ascii)\n          print(\"ip\", ipString)\n          return ipString\n      }\n      return \"\"\n    }\n```\n\n之后依靠以上获取的信息，需要通过Socket/Streams建立连接来进行通信，本篇文章不对这部分做更多的介绍，后续有时间再补充完整。\n\n##### 参考    \n1. http://mobileorchard.com/tutorial-networking-and-bonjour-on-iphone/\n2. https://developer.apple.com/library/content/documentation/Networking/Conceptual/NSNetServiceProgGuide/Introduction.html#//apple_ref/doc/uid/TP40002520-SW2\n3. http://www.cocoachina.com/ios/20150918/13434.html\n","slug":"iOS-bonjour","published":1,"updated":"2017-09-26T09:56:44.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj81l545t000gwluvkqv3g5lu","content":"<p>之前一直考虑在local现场怎么与别的用户通信，后来陆续了解了苹果的<a href=\"https://developer.apple.com/library/content/documentation/Cocoa/Conceptual/NetServices/Introduction.html\" target=\"_blank\" rel=\"external\">Bonjour</a>。现在简单写一篇Bonjour的入门介绍。</p>\n<h4 id=\"Bonjour介绍\"><a href=\"#Bonjour介绍\" class=\"headerlink\" title=\"Bonjour介绍\"></a>Bonjour介绍</h4><p>bonjour其实来自法语，是你好的意思。而Bonjour服务是苹果公司发布的一个基于ZEROCONF工作组(IETF下属小组)的工作,用于实现零配置网络联网的解决方案。Bonjour是基于IP层协议的,简单来说,就是一套解决方案,能够不需要复杂的配置,即可互相发现彼此的解决方案。可以用它来轻松探测并连接到相同网络中的其他设备，并与别的智能硬件进行交互或者其他操作。典型的Bonjour应用有Remote、AirPrint等。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/iOS-bonjour-Overview.png\" alt=\"Bonjour-overview\"></p>\n<p>为了实现简单配置网络，Bonjour做了以下三点：   </p>\n<ol>\n<li><p>寻址(分配IP地址给主机）<br>一个在网络中的设备需要有一个自己的IP。有了IP地址,我们才能基于IP协议进行通信。对于IPV6标准,IP协议已经包括了自动寻找IP地址的功能。但是目前仍然普遍使用的IPV4不包含本地链路寻址功能。而Bonjour会在本地网络选择一个随机的IP地址进行测试,如果已经被占用,则继续挑选另外一个地址，直到选到可用的IP地址。</p>\n</li>\n<li><p>命名(使用名字而不是IP地址来代表主机）<br>Bonjour还实现了命名和解析功能，保证了我们服务的名字在本地网络是唯一的,并且把别人对我们名字的查询指向正确的IP地址和端口，而不是以IP地址这样不易读的方式来作为服务的标志。<br>而且Bonjour在系统级别上添加了一个mDNSResponder服务来处理请求和发送回复,从系统级层面上处理,我们就无需在应用内自己监听和返回IP地址,只需到系统内注册服务即可。减少了我们应用的工作量和提高了稳定性。</p>\n</li>\n<li><p>服务搜索（自动在网络搜索服务）<br>Bonjour可以只需指定所需服务的类型，即可收到本地网络上可用的设备列表。设备在本地网络发出请求,说我需要”XXX”类型的服务,例如：我要打印机服务。所有打印机服务的设备回应自己的名字。</p>\n</li>\n</ol>\n<a id=\"more\"></a>\n<h4 id=\"Bonjour-API\"><a href=\"#Bonjour-API\" class=\"headerlink\" title=\"Bonjour API\"></a>Bonjour API</h4><p>Cocoa中网络框架有三层，最底层的是基于 BSD socket库，然后是 Cocoa 中基于 C 的 CFNetwork，最上面一层是 Cocoa 中 Bonjour。通常我们无需与 socket 打交道，我们会使用经 Cocoa 封装的 CFNetwork 和 Bonjour 来完成大多数工作。  </p>\n<blockquote>\n<p>cocoa 很多组件都有两种实现，一种是基于 C 的以 CF 开头的类（CF=Core Foundation），这是比较底层的；另一种是基于 Obj-C 的以 NS 开头的类(NS=Next Step)，这种类抽象层次更高，易于使用。对于网络框架也一样。Bonjour 中 NSNetService 也有对应的 CFNetService，NSInputStream 有对应的 CFInputStream。  </p>\n</blockquote>\n<p>通过 Bonjour，一个应用程序publish一个网络服务 service，然后网络中的其他程序就能自动发现这个 service，从而可以向这个 service 查询其 ip 和 port，然后通过获得的 ip 和 port 建立 socket 链接进行通信。通常我们是通过 NSNetService 和 NSNetServiceBrowser 来使用 Bonjour 的，前者用于建立与发布 service，后者用于监听查询网络上的 service。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/iOS-bonjour-API.png\" alt=\"Bonjour-API\"></p>\n<h4 id=\"建立连接\"><a href=\"#建立连接\" class=\"headerlink\" title=\"建立连接\"></a>建立连接</h4><p>简单来说，建立Bonjour连接一般需要三个步骤，即服务端发布服务、客户端浏览服务、客户端/服务端交互。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/iOS-bonjour-API1.png\" alt=\"Bonjour-API\"></p>\n<h5 id=\"客户端发布服务\"><a href=\"#客户端发布服务\" class=\"headerlink\" title=\"客户端发布服务\"></a>客户端发布服务</h5><p>首先通过<code>NetService</code>对象初始化服务，指定服务的域、类型、名称和端口，在同一网络中，服务类型名必须唯一，这样才能精准定位服务。<br>Bonjour操作也需要异步进行，以免长时间阻碍主线程，所以我们将发布任务交给当前run loop去调度。   </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">func setupService()&#123;</div><div class=\"line\">    let service = NetService.init(domain: &quot;local.&quot;, type: &quot;_dragon._tcp&quot;, name: &quot;dragon&quot;, port: 2333)</div><div class=\"line\">    service.schedule(in: RunLoop.current, forMode: .commonModes)</div><div class=\"line\">    service.delegate = self</div><div class=\"line\">    let dictData = &quot;http://fighting300.github.io&quot;.data(using: String.Encoding.utf8)</div><div class=\"line\">    let data = NetService.data(fromTXTRecord: [&quot;node&quot;:dictData!])</div><div class=\"line\">    service.setTXTRecord(data)</div><div class=\"line\">    service.publish()</div><div class=\"line\">    self.service = service</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>另外需要实现NetService协议<code>NetServiceDelegate</code>的代理方法跟踪服务发布信息。  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">func netServiceWillPublish(_ sender: NetService) &#123;</div><div class=\"line\">    print(&quot;----netServiceWillPublish&quot;)</div><div class=\"line\">&#125;</div><div class=\"line\">func netService(_ sender: NetService, didNotPublish errorDict: [String : NSNumber]) &#123;</div><div class=\"line\">    print(&quot;----netService didNotPublish&quot;)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h5 id=\"客户端浏览服务\"><a href=\"#客户端浏览服务\" class=\"headerlink\" title=\"客户端浏览服务\"></a>客户端浏览服务</h5><p>服务发布成功后，会在代理方法中接受到发布的消息，这时候要在客户端通过<code>NetServiceBrowser</code>对象来浏览本地的服务，并展示本地网络中可用的服务。<br>可以通过<code>searchForServices</code>方法指定需要查找的服务类型和查找的域，然后运行在mainRunLoop中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">func netServiceDidPublish(_ sender: NetService) &#123;</div><div class=\"line\">    print(&quot;----netService didPublish&quot;)</div><div class=\"line\">    let browser = NetServiceBrowser()</div><div class=\"line\">    browser.delegate = self</div><div class=\"line\">    browser.searchForServices(ofType: &quot;_WE._tcp&quot;, inDomain: &quot;local.&quot;)</div><div class=\"line\">    browser.schedule(in: RunLoop.current, forMode: .commonModes)</div><div class=\"line\">    RunLoop.current.run(until: Date.init(timeIntervalSinceNow: 300))</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>同时实现NetServiceBrowser的代理<code>NetServiceBrowserDelegate</code>方法<code>netServiceBrowser(_ browser: NetServiceBrowser, didFind service: NetService, moreComing: Bool)</code>来处理相应服务的解析。当前代码实例中没有选择服务的服务，直接对扫描到的服务来做解析。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">func netServiceBrowser(_ browser: NetServiceBrowser, didFind service: NetService, moreComing: Bool) &#123;</div><div class=\"line\">    print(&quot;----netServiceBrowser didFind&quot;, service.domain, service.type, service.name, service.port,service)</div><div class=\"line\">    // 在界面选择对应的service</div><div class=\"line\">    self.service = service</div><div class=\"line\">    service.delegate = self</div><div class=\"line\">    service.resolve(withTimeout: 5)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func netServiceBrowser(_ browser: NetServiceBrowser, didRemove service: NetService, moreComing: Bool) &#123;</div><div class=\"line\">    print(&quot;----netServiceBrowser didRemove&quot;)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h5 id=\"客户端-服务端交互\"><a href=\"#客户端-服务端交互\" class=\"headerlink\" title=\"客户端/服务端交互\"></a>客户端/服务端交互</h5><p>最后，可以在NetService代理的解析方法里<code>func netServiceDidResolveAddress(_ sender: NetService)</code>，拿到名称、类型、域、主机名和ip地址等信息。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div></pre></td><td class=\"code\"><pre><div class=\"line\">func netServiceWillResolve(_ sender: NetService) &#123;</div><div class=\"line\">    print(&quot;----netService willResolve&quot;)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func netServiceDidResolveAddress(_ sender: NetService) &#123;</div><div class=\"line\">    print(&quot;----netService didResolveAddress&quot;, sender.name, sender.addresses, sender.hostName, sender.addresses?.first)</div><div class=\"line\">    let data = sender.txtRecordData()</div><div class=\"line\">    let dict = NetService.dictionary(fromTXTRecord: data!)</div><div class=\"line\">    let info = String.init(data: dict[&quot;node&quot;]!, encoding: String.Encoding.utf8)</div><div class=\"line\">    print(&quot;mac info = &quot;,info);</div><div class=\"line\"></div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func netService(_ sender: NetService, didNotResolve errorDict: [String : NSNumber]) &#123;</div><div class=\"line\">    print(&quot;----netService didNotResolve &quot;, errorDict)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func netServiceDidStop(_ sender: NetService) &#123;</div><div class=\"line\">    print(&quot;----netServiceDidStop&quot;)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func netService(_ sender: NetService, didUpdateTXTRecord data: Data) &#123;</div><div class=\"line\">    print(&quot;----netService didUpdateTXTRecord&quot;)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func netService(_ sender: NetService, didAcceptConnectionWith inputStream: InputStream, outputStream: OutputStream) &#123;</div><div class=\"line\">    print(&quot;----netService didAcceptConnectionWith&quot;)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">// MARK: util 获取ip地址</div><div class=\"line\">func IPFrom(data: Data) -&gt; String &#123;</div><div class=\"line\">  let dataIn: NSData = data as NSData</div><div class=\"line\">  var storage = sockaddr_storage()</div><div class=\"line\">  dataIn.getBytes(&amp;storage, length: MemoryLayout&lt;sockaddr_storage&gt;.size)</div><div class=\"line\">  if Int32(storage.ss_family) == AF_INET &#123;</div><div class=\"line\">      let addr4 = withUnsafePointer(to: &amp;storage) &#123;</div><div class=\"line\">          $0.withMemoryRebound(to: sockaddr_in.self, capacity: 1) &#123;</div><div class=\"line\">              $0.pointee</div><div class=\"line\">          &#125;</div><div class=\"line\">      &#125;</div><div class=\"line\">      let ipString =  String(cString: inet_ntoa(addr4.sin_addr), encoding: .ascii)</div><div class=\"line\">      print(&quot;ip&quot;, ipString)</div><div class=\"line\">      return ipString</div><div class=\"line\">  &#125;</div><div class=\"line\">  return &quot;&quot;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>之后依靠以上获取的信息，需要通过Socket/Streams建立连接来进行通信，本篇文章不对这部分做更多的介绍，后续有时间再补充完整。</p>\n<h5 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h5><ol>\n<li><a href=\"http://mobileorchard.com/tutorial-networking-and-bonjour-on-iphone/\" target=\"_blank\" rel=\"external\">http://mobileorchard.com/tutorial-networking-and-bonjour-on-iphone/</a></li>\n<li><a href=\"https://developer.apple.com/library/content/documentation/Networking/Conceptual/NSNetServiceProgGuide/Introduction.html#//apple_ref/doc/uid/TP40002520-SW2\" target=\"_blank\" rel=\"external\">https://developer.apple.com/library/content/documentation/Networking/Conceptual/NSNetServiceProgGuide/Introduction.html#//apple_ref/doc/uid/TP40002520-SW2</a></li>\n<li><a href=\"http://www.cocoachina.com/ios/20150918/13434.html\" target=\"_blank\" rel=\"external\">http://www.cocoachina.com/ios/20150918/13434.html</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>之前一直考虑在local现场怎么与别的用户通信，后来陆续了解了苹果的<a href=\"https://developer.apple.com/library/content/documentation/Cocoa/Conceptual/NetServices/Introduction.html\" target=\"_blank\" rel=\"external\">Bonjour</a>。现在简单写一篇Bonjour的入门介绍。</p>\n<h4 id=\"Bonjour介绍\"><a href=\"#Bonjour介绍\" class=\"headerlink\" title=\"Bonjour介绍\"></a>Bonjour介绍</h4><p>bonjour其实来自法语，是你好的意思。而Bonjour服务是苹果公司发布的一个基于ZEROCONF工作组(IETF下属小组)的工作,用于实现零配置网络联网的解决方案。Bonjour是基于IP层协议的,简单来说,就是一套解决方案,能够不需要复杂的配置,即可互相发现彼此的解决方案。可以用它来轻松探测并连接到相同网络中的其他设备，并与别的智能硬件进行交互或者其他操作。典型的Bonjour应用有Remote、AirPrint等。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/iOS-bonjour-Overview.png\" alt=\"Bonjour-overview\"></p>\n<p>为了实现简单配置网络，Bonjour做了以下三点：   </p>\n<ol>\n<li><p>寻址(分配IP地址给主机）<br>一个在网络中的设备需要有一个自己的IP。有了IP地址,我们才能基于IP协议进行通信。对于IPV6标准,IP协议已经包括了自动寻找IP地址的功能。但是目前仍然普遍使用的IPV4不包含本地链路寻址功能。而Bonjour会在本地网络选择一个随机的IP地址进行测试,如果已经被占用,则继续挑选另外一个地址，直到选到可用的IP地址。</p>\n</li>\n<li><p>命名(使用名字而不是IP地址来代表主机）<br>Bonjour还实现了命名和解析功能，保证了我们服务的名字在本地网络是唯一的,并且把别人对我们名字的查询指向正确的IP地址和端口，而不是以IP地址这样不易读的方式来作为服务的标志。<br>而且Bonjour在系统级别上添加了一个mDNSResponder服务来处理请求和发送回复,从系统级层面上处理,我们就无需在应用内自己监听和返回IP地址,只需到系统内注册服务即可。减少了我们应用的工作量和提高了稳定性。</p>\n</li>\n<li><p>服务搜索（自动在网络搜索服务）<br>Bonjour可以只需指定所需服务的类型，即可收到本地网络上可用的设备列表。设备在本地网络发出请求,说我需要”XXX”类型的服务,例如：我要打印机服务。所有打印机服务的设备回应自己的名字。</p>\n</li>\n</ol>","more":"<h4 id=\"Bonjour-API\"><a href=\"#Bonjour-API\" class=\"headerlink\" title=\"Bonjour API\"></a>Bonjour API</h4><p>Cocoa中网络框架有三层，最底层的是基于 BSD socket库，然后是 Cocoa 中基于 C 的 CFNetwork，最上面一层是 Cocoa 中 Bonjour。通常我们无需与 socket 打交道，我们会使用经 Cocoa 封装的 CFNetwork 和 Bonjour 来完成大多数工作。  </p>\n<blockquote>\n<p>cocoa 很多组件都有两种实现，一种是基于 C 的以 CF 开头的类（CF=Core Foundation），这是比较底层的；另一种是基于 Obj-C 的以 NS 开头的类(NS=Next Step)，这种类抽象层次更高，易于使用。对于网络框架也一样。Bonjour 中 NSNetService 也有对应的 CFNetService，NSInputStream 有对应的 CFInputStream。  </p>\n</blockquote>\n<p>通过 Bonjour，一个应用程序publish一个网络服务 service，然后网络中的其他程序就能自动发现这个 service，从而可以向这个 service 查询其 ip 和 port，然后通过获得的 ip 和 port 建立 socket 链接进行通信。通常我们是通过 NSNetService 和 NSNetServiceBrowser 来使用 Bonjour 的，前者用于建立与发布 service，后者用于监听查询网络上的 service。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/iOS-bonjour-API.png\" alt=\"Bonjour-API\"></p>\n<h4 id=\"建立连接\"><a href=\"#建立连接\" class=\"headerlink\" title=\"建立连接\"></a>建立连接</h4><p>简单来说，建立Bonjour连接一般需要三个步骤，即服务端发布服务、客户端浏览服务、客户端/服务端交互。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/iOS-bonjour-API1.png\" alt=\"Bonjour-API\"></p>\n<h5 id=\"客户端发布服务\"><a href=\"#客户端发布服务\" class=\"headerlink\" title=\"客户端发布服务\"></a>客户端发布服务</h5><p>首先通过<code>NetService</code>对象初始化服务，指定服务的域、类型、名称和端口，在同一网络中，服务类型名必须唯一，这样才能精准定位服务。<br>Bonjour操作也需要异步进行，以免长时间阻碍主线程，所以我们将发布任务交给当前run loop去调度。   </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">func setupService()&#123;</div><div class=\"line\">    let service = NetService.init(domain: &quot;local.&quot;, type: &quot;_dragon._tcp&quot;, name: &quot;dragon&quot;, port: 2333)</div><div class=\"line\">    service.schedule(in: RunLoop.current, forMode: .commonModes)</div><div class=\"line\">    service.delegate = self</div><div class=\"line\">    let dictData = &quot;http://fighting300.github.io&quot;.data(using: String.Encoding.utf8)</div><div class=\"line\">    let data = NetService.data(fromTXTRecord: [&quot;node&quot;:dictData!])</div><div class=\"line\">    service.setTXTRecord(data)</div><div class=\"line\">    service.publish()</div><div class=\"line\">    self.service = service</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>另外需要实现NetService协议<code>NetServiceDelegate</code>的代理方法跟踪服务发布信息。  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">func netServiceWillPublish(_ sender: NetService) &#123;</div><div class=\"line\">    print(&quot;----netServiceWillPublish&quot;)</div><div class=\"line\">&#125;</div><div class=\"line\">func netService(_ sender: NetService, didNotPublish errorDict: [String : NSNumber]) &#123;</div><div class=\"line\">    print(&quot;----netService didNotPublish&quot;)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h5 id=\"客户端浏览服务\"><a href=\"#客户端浏览服务\" class=\"headerlink\" title=\"客户端浏览服务\"></a>客户端浏览服务</h5><p>服务发布成功后，会在代理方法中接受到发布的消息，这时候要在客户端通过<code>NetServiceBrowser</code>对象来浏览本地的服务，并展示本地网络中可用的服务。<br>可以通过<code>searchForServices</code>方法指定需要查找的服务类型和查找的域，然后运行在mainRunLoop中。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div></pre></td><td class=\"code\"><pre><div class=\"line\">func netServiceDidPublish(_ sender: NetService) &#123;</div><div class=\"line\">    print(&quot;----netService didPublish&quot;)</div><div class=\"line\">    let browser = NetServiceBrowser()</div><div class=\"line\">    browser.delegate = self</div><div class=\"line\">    browser.searchForServices(ofType: &quot;_WE._tcp&quot;, inDomain: &quot;local.&quot;)</div><div class=\"line\">    browser.schedule(in: RunLoop.current, forMode: .commonModes)</div><div class=\"line\">    RunLoop.current.run(until: Date.init(timeIntervalSinceNow: 300))</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>同时实现NetServiceBrowser的代理<code>NetServiceBrowserDelegate</code>方法<code>netServiceBrowser(_ browser: NetServiceBrowser, didFind service: NetService, moreComing: Bool)</code>来处理相应服务的解析。当前代码实例中没有选择服务的服务，直接对扫描到的服务来做解析。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\">func netServiceBrowser(_ browser: NetServiceBrowser, didFind service: NetService, moreComing: Bool) &#123;</div><div class=\"line\">    print(&quot;----netServiceBrowser didFind&quot;, service.domain, service.type, service.name, service.port,service)</div><div class=\"line\">    // 在界面选择对应的service</div><div class=\"line\">    self.service = service</div><div class=\"line\">    service.delegate = self</div><div class=\"line\">    service.resolve(withTimeout: 5)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func netServiceBrowser(_ browser: NetServiceBrowser, didRemove service: NetService, moreComing: Bool) &#123;</div><div class=\"line\">    print(&quot;----netServiceBrowser didRemove&quot;)</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h5 id=\"客户端-服务端交互\"><a href=\"#客户端-服务端交互\" class=\"headerlink\" title=\"客户端/服务端交互\"></a>客户端/服务端交互</h5><p>最后，可以在NetService代理的解析方法里<code>func netServiceDidResolveAddress(_ sender: NetService)</code>，拿到名称、类型、域、主机名和ip地址等信息。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div></pre></td><td class=\"code\"><pre><div class=\"line\">func netServiceWillResolve(_ sender: NetService) &#123;</div><div class=\"line\">    print(&quot;----netService willResolve&quot;)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func netServiceDidResolveAddress(_ sender: NetService) &#123;</div><div class=\"line\">    print(&quot;----netService didResolveAddress&quot;, sender.name, sender.addresses, sender.hostName, sender.addresses?.first)</div><div class=\"line\">    let data = sender.txtRecordData()</div><div class=\"line\">    let dict = NetService.dictionary(fromTXTRecord: data!)</div><div class=\"line\">    let info = String.init(data: dict[&quot;node&quot;]!, encoding: String.Encoding.utf8)</div><div class=\"line\">    print(&quot;mac info = &quot;,info);</div><div class=\"line\"></div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func netService(_ sender: NetService, didNotResolve errorDict: [String : NSNumber]) &#123;</div><div class=\"line\">    print(&quot;----netService didNotResolve &quot;, errorDict)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func netServiceDidStop(_ sender: NetService) &#123;</div><div class=\"line\">    print(&quot;----netServiceDidStop&quot;)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func netService(_ sender: NetService, didUpdateTXTRecord data: Data) &#123;</div><div class=\"line\">    print(&quot;----netService didUpdateTXTRecord&quot;)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">func netService(_ sender: NetService, didAcceptConnectionWith inputStream: InputStream, outputStream: OutputStream) &#123;</div><div class=\"line\">    print(&quot;----netService didAcceptConnectionWith&quot;)</div><div class=\"line\">&#125;</div><div class=\"line\"></div><div class=\"line\">// MARK: util 获取ip地址</div><div class=\"line\">func IPFrom(data: Data) -&gt; String &#123;</div><div class=\"line\">  let dataIn: NSData = data as NSData</div><div class=\"line\">  var storage = sockaddr_storage()</div><div class=\"line\">  dataIn.getBytes(&amp;storage, length: MemoryLayout&lt;sockaddr_storage&gt;.size)</div><div class=\"line\">  if Int32(storage.ss_family) == AF_INET &#123;</div><div class=\"line\">      let addr4 = withUnsafePointer(to: &amp;storage) &#123;</div><div class=\"line\">          $0.withMemoryRebound(to: sockaddr_in.self, capacity: 1) &#123;</div><div class=\"line\">              $0.pointee</div><div class=\"line\">          &#125;</div><div class=\"line\">      &#125;</div><div class=\"line\">      let ipString =  String(cString: inet_ntoa(addr4.sin_addr), encoding: .ascii)</div><div class=\"line\">      print(&quot;ip&quot;, ipString)</div><div class=\"line\">      return ipString</div><div class=\"line\">  &#125;</div><div class=\"line\">  return &quot;&quot;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>之后依靠以上获取的信息，需要通过Socket/Streams建立连接来进行通信，本篇文章不对这部分做更多的介绍，后续有时间再补充完整。</p>\n<h5 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h5><ol>\n<li><a href=\"http://mobileorchard.com/tutorial-networking-and-bonjour-on-iphone/\" target=\"_blank\" rel=\"external\">http://mobileorchard.com/tutorial-networking-and-bonjour-on-iphone/</a></li>\n<li><a href=\"https://developer.apple.com/library/content/documentation/Networking/Conceptual/NSNetServiceProgGuide/Introduction.html#//apple_ref/doc/uid/TP40002520-SW2\" target=\"_blank\" rel=\"external\">https://developer.apple.com/library/content/documentation/Networking/Conceptual/NSNetServiceProgGuide/Introduction.html#//apple_ref/doc/uid/TP40002520-SW2</a></li>\n<li><a href=\"http://www.cocoachina.com/ios/20150918/13434.html\" target=\"_blank\" rel=\"external\">http://www.cocoachina.com/ios/20150918/13434.html</a></li>\n</ol>"},{"title":"iOS代码加固","date":"2017-03-31T17:11:18.000Z","_content":"\n众所周知的是大部分iOS代码一般不会做加密加固，因为iOS APP一般是通过AppStore发布的，而且苹果的系统难以攻破，所以在iOS里做代码加固一般是一件出力不讨好的事情。万事皆有例外，不管iOS、adr还是js，加密的目的是为了代码的安全性，虽然现在开源畅行，但是不管个人开发者还是大厂皆有保护代码安全的需求，所以iOS代码加固有了生存的土壤。下面简单介绍下iOS代码加密的几种方式。\n\n### iOS代码加密的几种方式\n\n#### 1.字符串加密\n\n  字符串会暴露APP的很多关键信息，攻击者可以根据从界面获取的字符串，快速找到相关逻辑的处理函数，从而进行分析破解。加密字符串可以增加攻击者阅读代码的难度以及根据字符串静态搜索的难度。   \n  一般的处理方式是对需要加密的字符串加密，并保存加密后的数据，再在使用字符串的地方插入解密算法。简单的加密算法可以把NSString转为byte或者NSData的方式，还可以把字符串放到后端来返回，尽量少的暴露页面信息。下面举个简单例子，把NSString转为16进制的字符串：   \n\n  ```\n  + (NSString *)globalString {    \n    return   @\"5f48494748203d20323b202020202020202020202020202020202020202020202020202020202020676c6f62616c2e44495350415443485f51554555455f5052494f524954595f44454641554c54203d20303b2020202020202020202020202020202020202020202020202\";  \n  }\n  ```\n<!--more-->\n#### 2.符号混淆  \n  符号混淆的中心思想是将类名、方法名、变量名替换为无意义符号，提高应用安全性；防止敏感符号被class-dump工具提取，防止IDA Pro等工具反编译后分析业务代码。目前市面上的IOS应用基本上是没有使用类名方法名混淆的。  \n\n##### a. 别名  \n  在编写代码的时候直接用别名可能是最简单的一种方式，也是比较管用的一种方式。因为你的app被破解后，假如很容易就能从你的类名中寻找到蛛丝马迹，那离hook只是一步之遥，之前微信抢红包的插件应该就是用hook的方式执行的。\n\n##### b.C重写\n  编写别名的方式不是很易读，而且也不利于后续维护，这时你可能需要升级一下你的保护方式，用C来重写你的代码吧。这样把函数名隐藏在结构体中，用函数指针成员的形式存储，编译后，只留下了地址，去掉了名字和参数表，让他们无从下手(copy from 念茜)。如下例子：\n\n  ```\n  typedef struct _util {  \n    BOOL (*doTrade)(void);  \n    BOOL (*makeDeal)(void);  \n\t void (*transferMoney)(NSString *password);  \n   }FTradeUtil_t ;  \n\n  #define FTradeUtil ([_FTradeUtil sharedUtil])  \n\n  @interface _FTradeUtil : NSObject  \n\n  + (FTradeUtil_t *)sharedUtil;  \n\n  @end  \n\n  ```\n\n##### c.脚本处理\n  稍微高级一点的是脚本扫描处理替换代码，因为要用到linux命令来编写脚本，可能会有一点门槛，不过学了之后你就可以出去吹嘘你全栈工程师的名头啦。。。\n  linux脚本比较常用的几个命令如下：\n  `grep  sed  awk`\n  脚本混淆替换是用上述几个命令扫描出来需要替换的字符串，比如方法名，类名，变量名，并做替换，如果你能熟练应用上述几个命令，恭喜你，已经了解了脚本的一点皮毛了。  \n  如以下脚本搜索遍历了代码目录下的需要混淆的关键字：  \n\n  ```\n  grep -h -r -I  \"^[-+]\" $ROOTFOLDER $EXCLUDE_DIR --include '*.[mh]' |sed \"s/[+-]//g\"|sed \"s/[();,: *\\^\\/\\{]/ /g\"|sed \"s/[ ]*</</\"| sed \"s/<.*>//g\" |awk '{split($0,b,\" \");print b[2];}'| sort|uniq |sed \"/^$/d\"|sed \"/^init/d\" >filter_fun.txt\n  ```\n  替换的方式可以直接扫描文件并对文件中的所有内容替换，也可以采用define的方式定义别名。例如：\n\n  ```\n  #ifndef setIsBackgroundFetchInterval    \n  #define setIsBackgroundFetchInterval setIsN0XsgPe2OVJoyuT5QWAKwaH    \n  #endif // setIsBackgroundFetchInterval  \n  ```\n\n##### d.开源项目[ios-class-guard](https://github.com/Polidea/ios-class-guard)  \n  该项目是基于class-dump的扩展，和脚本处理类似，是用class-dump扫描出编译后的类名、方法名、属性名等并做替换，只是不支持隐式C方法的替换，有兴趣的同学可以使用下。  \n\n#### 2.代码逻辑混淆\n  代码逻辑混淆有以下几个方面的含义：  \n  对方法体进行混淆，保证源码被逆向后该部分的代码有很大的迷惑性，因为有一些垃圾代码的存在；   \n  对应用程序逻辑结构进行打乱混排，保证源码可读性降到最低，这很容易把破解者带到沟里去；  \n  它拥有和原始的代码一样的功能，这是最最关键的。  \n  一般使用[obfuscator-llvm](https://github.com/obfuscator-llvm/obfuscator)来做代码逻辑混淆，或许会对该开源工具做个简单介绍。\n\n\n#### 3.加固SDK\n  adr中一般比较常见的加固等操作，iOS也有一些第三方提供这样的服务，但是没有真正使用过，不知道效果如何。   \n\n  当然还有一些第三方服务的加固产品，基本上都是采用了以上一种或几种混淆方式做的封装，如果想要直接可以拿来使用的服务，可以采用下，常用的一些服务如下：   \n\n  [爱加密iOS加密](http://www.ijiami.cn/ios)    \n  [Safengine](http://www.safengine.com/mobile/)   \n  [几维安全](http://kiwisec.com/)   \n\n  iOS加密可能市场很小，但是存在必有道理，在越狱/开源/极客的眼中，你的APP并没有你想像的那么安全，如果希望你的代码更加安全，在闲暇的精力之外，可以小做研究，说不准你在哪天就会用到它。\n","source":"_posts/iOS-code-obfuscate.md","raw":"---\ntitle: iOS代码加固\ndate: 2017-04-01 01:11:18\ntags: 安全\ncategories: iOS\n---\n\n众所周知的是大部分iOS代码一般不会做加密加固，因为iOS APP一般是通过AppStore发布的，而且苹果的系统难以攻破，所以在iOS里做代码加固一般是一件出力不讨好的事情。万事皆有例外，不管iOS、adr还是js，加密的目的是为了代码的安全性，虽然现在开源畅行，但是不管个人开发者还是大厂皆有保护代码安全的需求，所以iOS代码加固有了生存的土壤。下面简单介绍下iOS代码加密的几种方式。\n\n### iOS代码加密的几种方式\n\n#### 1.字符串加密\n\n  字符串会暴露APP的很多关键信息，攻击者可以根据从界面获取的字符串，快速找到相关逻辑的处理函数，从而进行分析破解。加密字符串可以增加攻击者阅读代码的难度以及根据字符串静态搜索的难度。   \n  一般的处理方式是对需要加密的字符串加密，并保存加密后的数据，再在使用字符串的地方插入解密算法。简单的加密算法可以把NSString转为byte或者NSData的方式，还可以把字符串放到后端来返回，尽量少的暴露页面信息。下面举个简单例子，把NSString转为16进制的字符串：   \n\n  ```\n  + (NSString *)globalString {    \n    return   @\"5f48494748203d20323b202020202020202020202020202020202020202020202020202020202020676c6f62616c2e44495350415443485f51554555455f5052494f524954595f44454641554c54203d20303b2020202020202020202020202020202020202020202020202\";  \n  }\n  ```\n<!--more-->\n#### 2.符号混淆  \n  符号混淆的中心思想是将类名、方法名、变量名替换为无意义符号，提高应用安全性；防止敏感符号被class-dump工具提取，防止IDA Pro等工具反编译后分析业务代码。目前市面上的IOS应用基本上是没有使用类名方法名混淆的。  \n\n##### a. 别名  \n  在编写代码的时候直接用别名可能是最简单的一种方式，也是比较管用的一种方式。因为你的app被破解后，假如很容易就能从你的类名中寻找到蛛丝马迹，那离hook只是一步之遥，之前微信抢红包的插件应该就是用hook的方式执行的。\n\n##### b.C重写\n  编写别名的方式不是很易读，而且也不利于后续维护，这时你可能需要升级一下你的保护方式，用C来重写你的代码吧。这样把函数名隐藏在结构体中，用函数指针成员的形式存储，编译后，只留下了地址，去掉了名字和参数表，让他们无从下手(copy from 念茜)。如下例子：\n\n  ```\n  typedef struct _util {  \n    BOOL (*doTrade)(void);  \n    BOOL (*makeDeal)(void);  \n\t void (*transferMoney)(NSString *password);  \n   }FTradeUtil_t ;  \n\n  #define FTradeUtil ([_FTradeUtil sharedUtil])  \n\n  @interface _FTradeUtil : NSObject  \n\n  + (FTradeUtil_t *)sharedUtil;  \n\n  @end  \n\n  ```\n\n##### c.脚本处理\n  稍微高级一点的是脚本扫描处理替换代码，因为要用到linux命令来编写脚本，可能会有一点门槛，不过学了之后你就可以出去吹嘘你全栈工程师的名头啦。。。\n  linux脚本比较常用的几个命令如下：\n  `grep  sed  awk`\n  脚本混淆替换是用上述几个命令扫描出来需要替换的字符串，比如方法名，类名，变量名，并做替换，如果你能熟练应用上述几个命令，恭喜你，已经了解了脚本的一点皮毛了。  \n  如以下脚本搜索遍历了代码目录下的需要混淆的关键字：  \n\n  ```\n  grep -h -r -I  \"^[-+]\" $ROOTFOLDER $EXCLUDE_DIR --include '*.[mh]' |sed \"s/[+-]//g\"|sed \"s/[();,: *\\^\\/\\{]/ /g\"|sed \"s/[ ]*</</\"| sed \"s/<.*>//g\" |awk '{split($0,b,\" \");print b[2];}'| sort|uniq |sed \"/^$/d\"|sed \"/^init/d\" >filter_fun.txt\n  ```\n  替换的方式可以直接扫描文件并对文件中的所有内容替换，也可以采用define的方式定义别名。例如：\n\n  ```\n  #ifndef setIsBackgroundFetchInterval    \n  #define setIsBackgroundFetchInterval setIsN0XsgPe2OVJoyuT5QWAKwaH    \n  #endif // setIsBackgroundFetchInterval  \n  ```\n\n##### d.开源项目[ios-class-guard](https://github.com/Polidea/ios-class-guard)  \n  该项目是基于class-dump的扩展，和脚本处理类似，是用class-dump扫描出编译后的类名、方法名、属性名等并做替换，只是不支持隐式C方法的替换，有兴趣的同学可以使用下。  \n\n#### 2.代码逻辑混淆\n  代码逻辑混淆有以下几个方面的含义：  \n  对方法体进行混淆，保证源码被逆向后该部分的代码有很大的迷惑性，因为有一些垃圾代码的存在；   \n  对应用程序逻辑结构进行打乱混排，保证源码可读性降到最低，这很容易把破解者带到沟里去；  \n  它拥有和原始的代码一样的功能，这是最最关键的。  \n  一般使用[obfuscator-llvm](https://github.com/obfuscator-llvm/obfuscator)来做代码逻辑混淆，或许会对该开源工具做个简单介绍。\n\n\n#### 3.加固SDK\n  adr中一般比较常见的加固等操作，iOS也有一些第三方提供这样的服务，但是没有真正使用过，不知道效果如何。   \n\n  当然还有一些第三方服务的加固产品，基本上都是采用了以上一种或几种混淆方式做的封装，如果想要直接可以拿来使用的服务，可以采用下，常用的一些服务如下：   \n\n  [爱加密iOS加密](http://www.ijiami.cn/ios)    \n  [Safengine](http://www.safengine.com/mobile/)   \n  [几维安全](http://kiwisec.com/)   \n\n  iOS加密可能市场很小，但是存在必有道理，在越狱/开源/极客的眼中，你的APP并没有你想像的那么安全，如果希望你的代码更加安全，在闲暇的精力之外，可以小做研究，说不准你在哪天就会用到它。\n","slug":"iOS-code-obfuscate","published":1,"updated":"2017-09-26T09:56:10.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj81l545w000lwluv8j2q0kws","content":"<p>众所周知的是大部分iOS代码一般不会做加密加固，因为iOS APP一般是通过AppStore发布的，而且苹果的系统难以攻破，所以在iOS里做代码加固一般是一件出力不讨好的事情。万事皆有例外，不管iOS、adr还是js，加密的目的是为了代码的安全性，虽然现在开源畅行，但是不管个人开发者还是大厂皆有保护代码安全的需求，所以iOS代码加固有了生存的土壤。下面简单介绍下iOS代码加密的几种方式。</p>\n<h3 id=\"iOS代码加密的几种方式\"><a href=\"#iOS代码加密的几种方式\" class=\"headerlink\" title=\"iOS代码加密的几种方式\"></a>iOS代码加密的几种方式</h3><h4 id=\"1-字符串加密\"><a href=\"#1-字符串加密\" class=\"headerlink\" title=\"1.字符串加密\"></a>1.字符串加密</h4><p>  字符串会暴露APP的很多关键信息，攻击者可以根据从界面获取的字符串，快速找到相关逻辑的处理函数，从而进行分析破解。加密字符串可以增加攻击者阅读代码的难度以及根据字符串静态搜索的难度。<br>  一般的处理方式是对需要加密的字符串加密，并保存加密后的数据，再在使用字符串的地方插入解密算法。简单的加密算法可以把NSString转为byte或者NSData的方式，还可以把字符串放到后端来返回，尽量少的暴露页面信息。下面举个简单例子，把NSString转为16进制的字符串：   </p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">+ (NSString *)globalString &#123;    </div><div class=\"line\">  return   @&quot;5f48494748203d20323b202020202020202020202020202020202020202020202020202020202020676c6f62616c2e44495350415443485f51554555455f5052494f524954595f44454641554c54203d20303b2020202020202020202020202020202020202020202020202&quot;;  </div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<a id=\"more\"></a>\n<h4 id=\"2-符号混淆\"><a href=\"#2-符号混淆\" class=\"headerlink\" title=\"2.符号混淆\"></a>2.符号混淆</h4><p>  符号混淆的中心思想是将类名、方法名、变量名替换为无意义符号，提高应用安全性；防止敏感符号被class-dump工具提取，防止IDA Pro等工具反编译后分析业务代码。目前市面上的IOS应用基本上是没有使用类名方法名混淆的。  </p>\n<h5 id=\"a-别名\"><a href=\"#a-别名\" class=\"headerlink\" title=\"a. 别名\"></a>a. 别名</h5><p>  在编写代码的时候直接用别名可能是最简单的一种方式，也是比较管用的一种方式。因为你的app被破解后，假如很容易就能从你的类名中寻找到蛛丝马迹，那离hook只是一步之遥，之前微信抢红包的插件应该就是用hook的方式执行的。</p>\n<h5 id=\"b-C重写\"><a href=\"#b-C重写\" class=\"headerlink\" title=\"b.C重写\"></a>b.C重写</h5><p>  编写别名的方式不是很易读，而且也不利于后续维护，这时你可能需要升级一下你的保护方式，用C来重写你的代码吧。这样把函数名隐藏在结构体中，用函数指针成员的形式存储，编译后，只留下了地址，去掉了名字和参数表，让他们无从下手(copy from 念茜)。如下例子：</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">typedef struct _util &#123;  </div><div class=\"line\">  BOOL (*doTrade)(void);  </div><div class=\"line\">  BOOL (*makeDeal)(void);  </div><div class=\"line\">void (*transferMoney)(NSString *password);  </div><div class=\"line\"> &#125;FTradeUtil_t ;  </div><div class=\"line\"></div><div class=\"line\">#define FTradeUtil ([_FTradeUtil sharedUtil])  </div><div class=\"line\"></div><div class=\"line\">@interface _FTradeUtil : NSObject  </div><div class=\"line\"></div><div class=\"line\">+ (FTradeUtil_t *)sharedUtil;  </div><div class=\"line\"></div><div class=\"line\">@end</div></pre></td></tr></table></figure>\n<h5 id=\"c-脚本处理\"><a href=\"#c-脚本处理\" class=\"headerlink\" title=\"c.脚本处理\"></a>c.脚本处理</h5><p>  稍微高级一点的是脚本扫描处理替换代码，因为要用到linux命令来编写脚本，可能会有一点门槛，不过学了之后你就可以出去吹嘘你全栈工程师的名头啦。。。<br>  linux脚本比较常用的几个命令如下：<br>  <code>grep  sed  awk</code><br>  脚本混淆替换是用上述几个命令扫描出来需要替换的字符串，比如方法名，类名，变量名，并做替换，如果你能熟练应用上述几个命令，恭喜你，已经了解了脚本的一点皮毛了。<br>  如以下脚本搜索遍历了代码目录下的需要混淆的关键字：  </p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">grep -h -r -I  &quot;^[-+]&quot; $ROOTFOLDER $EXCLUDE_DIR --include &apos;*.[mh]&apos; |sed &quot;s/[+-]//g&quot;|sed &quot;s/[();,: *\\^\\/\\&#123;]/ /g&quot;|sed &quot;s/[ ]*&lt;/&lt;/&quot;| sed &quot;s/&lt;.*&gt;//g&quot; |awk &apos;&#123;split($0,b,&quot; &quot;);print b[2];&#125;&apos;| sort|uniq |sed &quot;/^$/d&quot;|sed &quot;/^init/d&quot; &gt;filter_fun.txt</div></pre></td></tr></table></figure>\n<p>  替换的方式可以直接扫描文件并对文件中的所有内容替换，也可以采用define的方式定义别名。例如：</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">#ifndef setIsBackgroundFetchInterval    </div><div class=\"line\">#define setIsBackgroundFetchInterval setIsN0XsgPe2OVJoyuT5QWAKwaH    </div><div class=\"line\">#endif // setIsBackgroundFetchInterval</div></pre></td></tr></table></figure>\n<h5 id=\"d-开源项目ios-class-guard\"><a href=\"#d-开源项目ios-class-guard\" class=\"headerlink\" title=\"d.开源项目ios-class-guard\"></a>d.开源项目<a href=\"https://github.com/Polidea/ios-class-guard\" target=\"_blank\" rel=\"external\">ios-class-guard</a></h5><p>  该项目是基于class-dump的扩展，和脚本处理类似，是用class-dump扫描出编译后的类名、方法名、属性名等并做替换，只是不支持隐式C方法的替换，有兴趣的同学可以使用下。  </p>\n<h4 id=\"2-代码逻辑混淆\"><a href=\"#2-代码逻辑混淆\" class=\"headerlink\" title=\"2.代码逻辑混淆\"></a>2.代码逻辑混淆</h4><p>  代码逻辑混淆有以下几个方面的含义：<br>  对方法体进行混淆，保证源码被逆向后该部分的代码有很大的迷惑性，因为有一些垃圾代码的存在；<br>  对应用程序逻辑结构进行打乱混排，保证源码可读性降到最低，这很容易把破解者带到沟里去；<br>  它拥有和原始的代码一样的功能，这是最最关键的。<br>  一般使用<a href=\"https://github.com/obfuscator-llvm/obfuscator\" target=\"_blank\" rel=\"external\">obfuscator-llvm</a>来做代码逻辑混淆，或许会对该开源工具做个简单介绍。</p>\n<h4 id=\"3-加固SDK\"><a href=\"#3-加固SDK\" class=\"headerlink\" title=\"3.加固SDK\"></a>3.加固SDK</h4><p>  adr中一般比较常见的加固等操作，iOS也有一些第三方提供这样的服务，但是没有真正使用过，不知道效果如何。   </p>\n<p>  当然还有一些第三方服务的加固产品，基本上都是采用了以上一种或几种混淆方式做的封装，如果想要直接可以拿来使用的服务，可以采用下，常用的一些服务如下：   </p>\n<p>  <a href=\"http://www.ijiami.cn/ios\" target=\"_blank\" rel=\"external\">爱加密iOS加密</a><br>  <a href=\"http://www.safengine.com/mobile/\" target=\"_blank\" rel=\"external\">Safengine</a><br>  <a href=\"http://kiwisec.com/\" target=\"_blank\" rel=\"external\">几维安全</a>   </p>\n<p>  iOS加密可能市场很小，但是存在必有道理，在越狱/开源/极客的眼中，你的APP并没有你想像的那么安全，如果希望你的代码更加安全，在闲暇的精力之外，可以小做研究，说不准你在哪天就会用到它。</p>\n","site":{"data":{}},"excerpt":"<p>众所周知的是大部分iOS代码一般不会做加密加固，因为iOS APP一般是通过AppStore发布的，而且苹果的系统难以攻破，所以在iOS里做代码加固一般是一件出力不讨好的事情。万事皆有例外，不管iOS、adr还是js，加密的目的是为了代码的安全性，虽然现在开源畅行，但是不管个人开发者还是大厂皆有保护代码安全的需求，所以iOS代码加固有了生存的土壤。下面简单介绍下iOS代码加密的几种方式。</p>\n<h3 id=\"iOS代码加密的几种方式\"><a href=\"#iOS代码加密的几种方式\" class=\"headerlink\" title=\"iOS代码加密的几种方式\"></a>iOS代码加密的几种方式</h3><h4 id=\"1-字符串加密\"><a href=\"#1-字符串加密\" class=\"headerlink\" title=\"1.字符串加密\"></a>1.字符串加密</h4><p>  字符串会暴露APP的很多关键信息，攻击者可以根据从界面获取的字符串，快速找到相关逻辑的处理函数，从而进行分析破解。加密字符串可以增加攻击者阅读代码的难度以及根据字符串静态搜索的难度。<br>  一般的处理方式是对需要加密的字符串加密，并保存加密后的数据，再在使用字符串的地方插入解密算法。简单的加密算法可以把NSString转为byte或者NSData的方式，还可以把字符串放到后端来返回，尽量少的暴露页面信息。下面举个简单例子，把NSString转为16进制的字符串：   </p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">+ (NSString *)globalString &#123;    </div><div class=\"line\">  return   @&quot;5f48494748203d20323b202020202020202020202020202020202020202020202020202020202020676c6f62616c2e44495350415443485f51554555455f5052494f524954595f44454641554c54203d20303b2020202020202020202020202020202020202020202020202&quot;;  </div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>","more":"<h4 id=\"2-符号混淆\"><a href=\"#2-符号混淆\" class=\"headerlink\" title=\"2.符号混淆\"></a>2.符号混淆</h4><p>  符号混淆的中心思想是将类名、方法名、变量名替换为无意义符号，提高应用安全性；防止敏感符号被class-dump工具提取，防止IDA Pro等工具反编译后分析业务代码。目前市面上的IOS应用基本上是没有使用类名方法名混淆的。  </p>\n<h5 id=\"a-别名\"><a href=\"#a-别名\" class=\"headerlink\" title=\"a. 别名\"></a>a. 别名</h5><p>  在编写代码的时候直接用别名可能是最简单的一种方式，也是比较管用的一种方式。因为你的app被破解后，假如很容易就能从你的类名中寻找到蛛丝马迹，那离hook只是一步之遥，之前微信抢红包的插件应该就是用hook的方式执行的。</p>\n<h5 id=\"b-C重写\"><a href=\"#b-C重写\" class=\"headerlink\" title=\"b.C重写\"></a>b.C重写</h5><p>  编写别名的方式不是很易读，而且也不利于后续维护，这时你可能需要升级一下你的保护方式，用C来重写你的代码吧。这样把函数名隐藏在结构体中，用函数指针成员的形式存储，编译后，只留下了地址，去掉了名字和参数表，让他们无从下手(copy from 念茜)。如下例子：</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\">typedef struct _util &#123;  </div><div class=\"line\">  BOOL (*doTrade)(void);  </div><div class=\"line\">  BOOL (*makeDeal)(void);  </div><div class=\"line\">void (*transferMoney)(NSString *password);  </div><div class=\"line\"> &#125;FTradeUtil_t ;  </div><div class=\"line\"></div><div class=\"line\">#define FTradeUtil ([_FTradeUtil sharedUtil])  </div><div class=\"line\"></div><div class=\"line\">@interface _FTradeUtil : NSObject  </div><div class=\"line\"></div><div class=\"line\">+ (FTradeUtil_t *)sharedUtil;  </div><div class=\"line\"></div><div class=\"line\">@end</div></pre></td></tr></table></figure>\n<h5 id=\"c-脚本处理\"><a href=\"#c-脚本处理\" class=\"headerlink\" title=\"c.脚本处理\"></a>c.脚本处理</h5><p>  稍微高级一点的是脚本扫描处理替换代码，因为要用到linux命令来编写脚本，可能会有一点门槛，不过学了之后你就可以出去吹嘘你全栈工程师的名头啦。。。<br>  linux脚本比较常用的几个命令如下：<br>  <code>grep  sed  awk</code><br>  脚本混淆替换是用上述几个命令扫描出来需要替换的字符串，比如方法名，类名，变量名，并做替换，如果你能熟练应用上述几个命令，恭喜你，已经了解了脚本的一点皮毛了。<br>  如以下脚本搜索遍历了代码目录下的需要混淆的关键字：  </p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">grep -h -r -I  &quot;^[-+]&quot; $ROOTFOLDER $EXCLUDE_DIR --include &apos;*.[mh]&apos; |sed &quot;s/[+-]//g&quot;|sed &quot;s/[();,: *\\^\\/\\&#123;]/ /g&quot;|sed &quot;s/[ ]*&lt;/&lt;/&quot;| sed &quot;s/&lt;.*&gt;//g&quot; |awk &apos;&#123;split($0,b,&quot; &quot;);print b[2];&#125;&apos;| sort|uniq |sed &quot;/^$/d&quot;|sed &quot;/^init/d&quot; &gt;filter_fun.txt</div></pre></td></tr></table></figure>\n<p>  替换的方式可以直接扫描文件并对文件中的所有内容替换，也可以采用define的方式定义别名。例如：</p>\n  <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">#ifndef setIsBackgroundFetchInterval    </div><div class=\"line\">#define setIsBackgroundFetchInterval setIsN0XsgPe2OVJoyuT5QWAKwaH    </div><div class=\"line\">#endif // setIsBackgroundFetchInterval</div></pre></td></tr></table></figure>\n<h5 id=\"d-开源项目ios-class-guard\"><a href=\"#d-开源项目ios-class-guard\" class=\"headerlink\" title=\"d.开源项目ios-class-guard\"></a>d.开源项目<a href=\"https://github.com/Polidea/ios-class-guard\" target=\"_blank\" rel=\"external\">ios-class-guard</a></h5><p>  该项目是基于class-dump的扩展，和脚本处理类似，是用class-dump扫描出编译后的类名、方法名、属性名等并做替换，只是不支持隐式C方法的替换，有兴趣的同学可以使用下。  </p>\n<h4 id=\"2-代码逻辑混淆\"><a href=\"#2-代码逻辑混淆\" class=\"headerlink\" title=\"2.代码逻辑混淆\"></a>2.代码逻辑混淆</h4><p>  代码逻辑混淆有以下几个方面的含义：<br>  对方法体进行混淆，保证源码被逆向后该部分的代码有很大的迷惑性，因为有一些垃圾代码的存在；<br>  对应用程序逻辑结构进行打乱混排，保证源码可读性降到最低，这很容易把破解者带到沟里去；<br>  它拥有和原始的代码一样的功能，这是最最关键的。<br>  一般使用<a href=\"https://github.com/obfuscator-llvm/obfuscator\" target=\"_blank\" rel=\"external\">obfuscator-llvm</a>来做代码逻辑混淆，或许会对该开源工具做个简单介绍。</p>\n<h4 id=\"3-加固SDK\"><a href=\"#3-加固SDK\" class=\"headerlink\" title=\"3.加固SDK\"></a>3.加固SDK</h4><p>  adr中一般比较常见的加固等操作，iOS也有一些第三方提供这样的服务，但是没有真正使用过，不知道效果如何。   </p>\n<p>  当然还有一些第三方服务的加固产品，基本上都是采用了以上一种或几种混淆方式做的封装，如果想要直接可以拿来使用的服务，可以采用下，常用的一些服务如下：   </p>\n<p>  <a href=\"http://www.ijiami.cn/ios\" target=\"_blank\" rel=\"external\">爱加密iOS加密</a><br>  <a href=\"http://www.safengine.com/mobile/\" target=\"_blank\" rel=\"external\">Safengine</a><br>  <a href=\"http://kiwisec.com/\" target=\"_blank\" rel=\"external\">几维安全</a>   </p>\n<p>  iOS加密可能市场很小，但是存在必有道理，在越狱/开源/极客的眼中，你的APP并没有你想像的那么安全，如果希望你的代码更加安全，在闲暇的精力之外，可以小做研究，说不准你在哪天就会用到它。</p>"},{"title":"iOS11/iPhoneX最新适配指南","date":"2017-09-14T03:47:19.000Z","_content":"\niPhone发布会前，就隐隐感觉到一波适配工作要袭来的赶脚，果然不出所料。  \n新版iPhone的适配工作主要集中在iPhoneX上，相信大家已经对iPhoneX的刘海记忆深刻了，除了吐槽，留给我们的还有比较麻烦的适配工作。下面简单分享下在整理过程中发现的适配注意点。(适配工作主要在UI方面，后续发现的适配点会陆续补充到该文档中)  \n\n![iPhoneX 375x812尺寸图](http://ojca2gwha.bkt.clouddn.com/iPhoneX-Screen.png)  \n\n#### 上下黑边问题\n\n运行新版Xcode的iPhoneX模拟器，你可能发现之前的APP在iPhoneX屏幕没填充满，上下有黑色区域，应该是你的app之前未用LaunchScreen.Storyboard作为启动页面，可以使用LaunchScreen来当做入场页面，这样APP才会自动适配为iPhoneX的大小。或者修改Assets中的LaunchImage，添加iPhoneX的Launch图如下(1125*2436)。\n\n![LaunchImage适配](http://ojca2gwha.bkt.clouddn.com/iOS11-adjust-launch.png)  \n\n#### iOS11新增版本判断API\n\niOS11版本现在有了简单的API，OC也开始支持swfit的@available语法，不用再手写iOS版本判断了。      \n```\n  if (@available(iOS 11.0, *)) {\n    // 版本适配\n  }\n  // 或者\n  #ifdef __IPHONE_11_0   \n  #endif\n```\n\n目前没发现有iPhoneX的机型判断API，暂时可以使用size来做代替判断。  \n\n```\n  #define kDevice_iPhoneX CGSizeEqualToSize(CGSizeMake(375, 812), [[UIScreen mainScreen] bounds].size)\n  // 或者\n  if (UIScreen.mainScreen.bounds.size.height == 812) {\n      NSLog(@\"this is iPhone X\");\n  }\n```\n\n<!--more-->\n\n#### UI适配  \n\n##### 导航栏适配  \n\niPhoneX由于多了大圆角、传感器(齐刘海)以及底部访问主屏幕的指示遮挡，所以需要注意原有这部分内容的设计。\niOS11前导航栏的高度是64，其中statusBar的高度为20，而iPhoneX的statusBar高度变为了44，如果是自定义的NaviBar，这部分需要做相应的适配。  \n\niPhoneX的底部增加了虚拟Home区，由于安全区域的原因默认tabBar的高度由49变为83，增高了34，所以自定义的底部TabBar也需要需改其适配方案。\n可能有部分APP使用了RN来实现页面，不要忘了在RN中修改相应NaviBar/TabBar的高度。\n\n![iPhoneX尺寸](http://ojca2gwha.bkt.clouddn.com/iPhoneX-Area.png)  \n\n\n\n##### 安全区域\n\n安全区域定义了view中可视区域的部分，帮助我们将view放置在整个屏幕的可视的部分。即使把navigationbar设置为透明的，系统也认为安全区域是从navigationbar的bottom开始的。这样保证不被系统的状态栏、或父视图提供的view如导航栏覆盖。\n\n![安全区域](http://ojca2gwha.bkt.clouddn.com/iOS11-safeArea.png)\n\niOS11的UIViewController和UIView新加了`-(void)viewSafeAreaInsetsDidChange`方法，当安全区域改变后该方法会被调用。然后在该方法中根据safeAreaInses属性更新子视图中控件的布局位置。\n当然如果你要改变一个UIViewController的safeAreaInsets值, 可以通过设置`addtionalSafeAreaInsets`属性来实现, 例如你要自定义一些特殊的样式时。\n需要注意的是viewSafeAreaInsetsDidChange在UIViewController中第一次调用的时间是在`-(void)viewWillAppear:(BOOL)animated`调用之后, 在`- (void)viewWillLayoutSubviews`调用之前。所以可以在viewWillAppear里设置受影响的页面的addtionalSafeAreaInsets属性。\n\n```\n- (void)viewSafeAreaInsetsDidChange{\n    [super viewSafeAreaInsetsDidChange];\n    if (@available(iOS 11.0, *)) {\n        NSLog(@\"safeAreaInset list= %@\",NSStringFromUIEdgeInsets(self.view.safeAreaInsets));\n        NSLog(@\"safeAreaLayout list= %@\",self.view.safeAreaLayoutGuide);\n    }\n}\n```\n\n##### UIScrollView & UITableView\n\n测试过程中发现tableView会有20pt/64pt的偏移，其原因是由于iOS 11废弃了UIViewController的`automaticallyAdjustsScrollViewInsets`属性，新增了contentInsetAdjustmentBehavior属性，所以当超出安全区域时系统自动调整了SafeAreaInsets，进而影响了adjustedContentInset，在iOS11中决定tableView内容与边缘距离的是adjustedContentInset，所以需要设置UIScrollView的contentInsetAdjustmentBehavior属性。  \n\n1.手动适配    \n如果你使用了UITableView、UIScrollView，可以直接使用以下代码做适配，这样系统就不会主动为你设置边缘距离，但是你可能需要手动适配UITableView的contenteInset。   \n\n```\n  #ifdef __IPHONE_11_0  \n  // 单独作用与某个tableView\n  if ([tableView respondsToSelector:@selector(setContentInsetAdjustmentBehavior:)]) {\n    tableView.contentInsetAdjustmentBehavior = UIScrollViewContentInsetAdjustmentNever;\n  }\n  // 作用与所有的UIScrollView\n  UIScrollView.appearance.contentInsetAdjustmentBehavior = UIScrollViewContentInsetAdjustmentNever;\n  // 设置view的宽高\n  tableView.contentInset = UIEdgeInsetsMake(0, 0, 34, 0);\n  #endif\n```\n\n2.自动适配  \n设置`contentInsetAdjustmentBehavior`属性为UIScrollViewContentInsetAdjustmentAutomatic，则系统会自动计算contentView的偏移量。\n\n3.设置安全区域的addtionalSafeAreaInset  \n某些情况下，你需要顶部区域，比如广告区域覆盖Status，则可以设置相应页面的addtionalSafeAreaInset属性，这样系统不会将safeArea上调到从status开始。这样可以提供更好的用户体验。\n例如如果你的SafeAreaInset值为(44,0,0,0)，则需要设置相应的additionalSafeAreaInsets值为(-44,0,0,0)。\n\n```\n  if (@available(iOS 11.0, *)) {\n      self.additionalSafeAreaInsets = UIEdgeInsetsMake(-44, 0, 0, 0);\n  } else {\n      // Fallback on earlier versions\n  }\n```\n\n4.iOS11开始UITableView开启了自动估算行高，estimatedRowHeight estimatedSectionHeaderHeight estimatedSectionFooterHeight三个高度估算属性由默认的0变成了UITableViewAutomaticDimension，所以heightForHeaderInSection和viewForHeaderInSection应该一起使用，不然tableView顶部滑动的时候会有空白。\n在适配过程中发现UITableView会在Header/Footer返回size为负值的情况下会(之前遗漏的bug)崩溃，这块可以自查下，而iOS11之前的版本不会。\n\n##### 其他方案......\n\n另外有人对iPhoneX整个UIWindow做了内容的调整，只是UI还是有点丑，感兴趣的同学可以去看看[该GitHub](https://github.com/HarshilShah/NotchKit)，不过可能这样的设计方案不会通过APPLE的审核。\n\n#### API适配\n\n##### LocalAuthentication 本地认证    \n\n本地认证框架提供了从具有指定安全策略(密码或生物学特征)的用户请求身份验证的功能。例如，要求用户仅使用Face ID或Touch ID进行身份验证，可使用以下代码：  \n\n```\n  let myContext = LAContext()   \n  let myLocalizedReasonString = <#String explaining why app needs authentication#>    \n  var authError: NSError?   \n  if #available(iOS 8.0, macOS 10.12.1, *) {   \n      if myContext.canEvaluatePolicy(.deviceOwnerAuthenticationWithBiometrics, error: &authError) {   \n          myContext.evaluatePolicy(.deviceOwnerAuthenticationWithBiometrics, localizedReason: myLocalizedReasonString) { success, evaluateError in\n              if success {  \n                  // 用户验证通过  \n              } else {  \n                  // 用户验证失败，处理失败信息  \n              }  \n          }  \n      } else {  \n          // 不能执行策略验证，处理验证错误信息  \n      }  \n  } else {  \n      // Fallback on earlier versions\n  }\n```\n\nLAContext新增API如下：  \n1. biometryType属性返回当前设备支持的生物学特征验证方式，他的值可以分别为typeFaceID、typeTouchID或者none。  \n2. localizedReason需要验证时展示在弹框上的提示信息\n\n\n\n##### 参考文档  \n1. https://developer.apple.com/videos/fall2017/\n2. https://developer.apple.com/iphone/\n3. https://developer.apple.com/ios/human-interface-guidelines/overview/iphone-x/\n\n\n##### Tips\niPhone X 侧边按钮的使用方式：  \n- 按一下锁屏；\n- 按两下 Apple Pay；\n- 按三下辅助功能快捷键（比如 VoiceOver）；\n- 按五下 SOS；\n- 短按 Siri；\n- 长按关机；\n- 按一下+Volume Up 截屏。\n","source":"_posts/iOS11-UI-adjust.md","raw":"---\ntitle: iOS11/iPhoneX最新适配指南\ndate: 2017-09-14 11:47:19\ntags: iOS 11\ncategories: iOS\n---\n\niPhone发布会前，就隐隐感觉到一波适配工作要袭来的赶脚，果然不出所料。  \n新版iPhone的适配工作主要集中在iPhoneX上，相信大家已经对iPhoneX的刘海记忆深刻了，除了吐槽，留给我们的还有比较麻烦的适配工作。下面简单分享下在整理过程中发现的适配注意点。(适配工作主要在UI方面，后续发现的适配点会陆续补充到该文档中)  \n\n![iPhoneX 375x812尺寸图](http://ojca2gwha.bkt.clouddn.com/iPhoneX-Screen.png)  \n\n#### 上下黑边问题\n\n运行新版Xcode的iPhoneX模拟器，你可能发现之前的APP在iPhoneX屏幕没填充满，上下有黑色区域，应该是你的app之前未用LaunchScreen.Storyboard作为启动页面，可以使用LaunchScreen来当做入场页面，这样APP才会自动适配为iPhoneX的大小。或者修改Assets中的LaunchImage，添加iPhoneX的Launch图如下(1125*2436)。\n\n![LaunchImage适配](http://ojca2gwha.bkt.clouddn.com/iOS11-adjust-launch.png)  \n\n#### iOS11新增版本判断API\n\niOS11版本现在有了简单的API，OC也开始支持swfit的@available语法，不用再手写iOS版本判断了。      \n```\n  if (@available(iOS 11.0, *)) {\n    // 版本适配\n  }\n  // 或者\n  #ifdef __IPHONE_11_0   \n  #endif\n```\n\n目前没发现有iPhoneX的机型判断API，暂时可以使用size来做代替判断。  \n\n```\n  #define kDevice_iPhoneX CGSizeEqualToSize(CGSizeMake(375, 812), [[UIScreen mainScreen] bounds].size)\n  // 或者\n  if (UIScreen.mainScreen.bounds.size.height == 812) {\n      NSLog(@\"this is iPhone X\");\n  }\n```\n\n<!--more-->\n\n#### UI适配  \n\n##### 导航栏适配  \n\niPhoneX由于多了大圆角、传感器(齐刘海)以及底部访问主屏幕的指示遮挡，所以需要注意原有这部分内容的设计。\niOS11前导航栏的高度是64，其中statusBar的高度为20，而iPhoneX的statusBar高度变为了44，如果是自定义的NaviBar，这部分需要做相应的适配。  \n\niPhoneX的底部增加了虚拟Home区，由于安全区域的原因默认tabBar的高度由49变为83，增高了34，所以自定义的底部TabBar也需要需改其适配方案。\n可能有部分APP使用了RN来实现页面，不要忘了在RN中修改相应NaviBar/TabBar的高度。\n\n![iPhoneX尺寸](http://ojca2gwha.bkt.clouddn.com/iPhoneX-Area.png)  \n\n\n\n##### 安全区域\n\n安全区域定义了view中可视区域的部分，帮助我们将view放置在整个屏幕的可视的部分。即使把navigationbar设置为透明的，系统也认为安全区域是从navigationbar的bottom开始的。这样保证不被系统的状态栏、或父视图提供的view如导航栏覆盖。\n\n![安全区域](http://ojca2gwha.bkt.clouddn.com/iOS11-safeArea.png)\n\niOS11的UIViewController和UIView新加了`-(void)viewSafeAreaInsetsDidChange`方法，当安全区域改变后该方法会被调用。然后在该方法中根据safeAreaInses属性更新子视图中控件的布局位置。\n当然如果你要改变一个UIViewController的safeAreaInsets值, 可以通过设置`addtionalSafeAreaInsets`属性来实现, 例如你要自定义一些特殊的样式时。\n需要注意的是viewSafeAreaInsetsDidChange在UIViewController中第一次调用的时间是在`-(void)viewWillAppear:(BOOL)animated`调用之后, 在`- (void)viewWillLayoutSubviews`调用之前。所以可以在viewWillAppear里设置受影响的页面的addtionalSafeAreaInsets属性。\n\n```\n- (void)viewSafeAreaInsetsDidChange{\n    [super viewSafeAreaInsetsDidChange];\n    if (@available(iOS 11.0, *)) {\n        NSLog(@\"safeAreaInset list= %@\",NSStringFromUIEdgeInsets(self.view.safeAreaInsets));\n        NSLog(@\"safeAreaLayout list= %@\",self.view.safeAreaLayoutGuide);\n    }\n}\n```\n\n##### UIScrollView & UITableView\n\n测试过程中发现tableView会有20pt/64pt的偏移，其原因是由于iOS 11废弃了UIViewController的`automaticallyAdjustsScrollViewInsets`属性，新增了contentInsetAdjustmentBehavior属性，所以当超出安全区域时系统自动调整了SafeAreaInsets，进而影响了adjustedContentInset，在iOS11中决定tableView内容与边缘距离的是adjustedContentInset，所以需要设置UIScrollView的contentInsetAdjustmentBehavior属性。  \n\n1.手动适配    \n如果你使用了UITableView、UIScrollView，可以直接使用以下代码做适配，这样系统就不会主动为你设置边缘距离，但是你可能需要手动适配UITableView的contenteInset。   \n\n```\n  #ifdef __IPHONE_11_0  \n  // 单独作用与某个tableView\n  if ([tableView respondsToSelector:@selector(setContentInsetAdjustmentBehavior:)]) {\n    tableView.contentInsetAdjustmentBehavior = UIScrollViewContentInsetAdjustmentNever;\n  }\n  // 作用与所有的UIScrollView\n  UIScrollView.appearance.contentInsetAdjustmentBehavior = UIScrollViewContentInsetAdjustmentNever;\n  // 设置view的宽高\n  tableView.contentInset = UIEdgeInsetsMake(0, 0, 34, 0);\n  #endif\n```\n\n2.自动适配  \n设置`contentInsetAdjustmentBehavior`属性为UIScrollViewContentInsetAdjustmentAutomatic，则系统会自动计算contentView的偏移量。\n\n3.设置安全区域的addtionalSafeAreaInset  \n某些情况下，你需要顶部区域，比如广告区域覆盖Status，则可以设置相应页面的addtionalSafeAreaInset属性，这样系统不会将safeArea上调到从status开始。这样可以提供更好的用户体验。\n例如如果你的SafeAreaInset值为(44,0,0,0)，则需要设置相应的additionalSafeAreaInsets值为(-44,0,0,0)。\n\n```\n  if (@available(iOS 11.0, *)) {\n      self.additionalSafeAreaInsets = UIEdgeInsetsMake(-44, 0, 0, 0);\n  } else {\n      // Fallback on earlier versions\n  }\n```\n\n4.iOS11开始UITableView开启了自动估算行高，estimatedRowHeight estimatedSectionHeaderHeight estimatedSectionFooterHeight三个高度估算属性由默认的0变成了UITableViewAutomaticDimension，所以heightForHeaderInSection和viewForHeaderInSection应该一起使用，不然tableView顶部滑动的时候会有空白。\n在适配过程中发现UITableView会在Header/Footer返回size为负值的情况下会(之前遗漏的bug)崩溃，这块可以自查下，而iOS11之前的版本不会。\n\n##### 其他方案......\n\n另外有人对iPhoneX整个UIWindow做了内容的调整，只是UI还是有点丑，感兴趣的同学可以去看看[该GitHub](https://github.com/HarshilShah/NotchKit)，不过可能这样的设计方案不会通过APPLE的审核。\n\n#### API适配\n\n##### LocalAuthentication 本地认证    \n\n本地认证框架提供了从具有指定安全策略(密码或生物学特征)的用户请求身份验证的功能。例如，要求用户仅使用Face ID或Touch ID进行身份验证，可使用以下代码：  \n\n```\n  let myContext = LAContext()   \n  let myLocalizedReasonString = <#String explaining why app needs authentication#>    \n  var authError: NSError?   \n  if #available(iOS 8.0, macOS 10.12.1, *) {   \n      if myContext.canEvaluatePolicy(.deviceOwnerAuthenticationWithBiometrics, error: &authError) {   \n          myContext.evaluatePolicy(.deviceOwnerAuthenticationWithBiometrics, localizedReason: myLocalizedReasonString) { success, evaluateError in\n              if success {  \n                  // 用户验证通过  \n              } else {  \n                  // 用户验证失败，处理失败信息  \n              }  \n          }  \n      } else {  \n          // 不能执行策略验证，处理验证错误信息  \n      }  \n  } else {  \n      // Fallback on earlier versions\n  }\n```\n\nLAContext新增API如下：  \n1. biometryType属性返回当前设备支持的生物学特征验证方式，他的值可以分别为typeFaceID、typeTouchID或者none。  \n2. localizedReason需要验证时展示在弹框上的提示信息\n\n\n\n##### 参考文档  \n1. https://developer.apple.com/videos/fall2017/\n2. https://developer.apple.com/iphone/\n3. https://developer.apple.com/ios/human-interface-guidelines/overview/iphone-x/\n\n\n##### Tips\niPhone X 侧边按钮的使用方式：  \n- 按一下锁屏；\n- 按两下 Apple Pay；\n- 按三下辅助功能快捷键（比如 VoiceOver）；\n- 按五下 SOS；\n- 短按 Siri；\n- 长按关机；\n- 按一下+Volume Up 截屏。\n","slug":"iOS11-UI-adjust","published":1,"updated":"2017-09-25T12:08:19.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj81l545x000nwluv4tufpnmt","content":"<p>iPhone发布会前，就隐隐感觉到一波适配工作要袭来的赶脚，果然不出所料。<br>新版iPhone的适配工作主要集中在iPhoneX上，相信大家已经对iPhoneX的刘海记忆深刻了，除了吐槽，留给我们的还有比较麻烦的适配工作。下面简单分享下在整理过程中发现的适配注意点。(适配工作主要在UI方面，后续发现的适配点会陆续补充到该文档中)  </p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/iPhoneX-Screen.png\" alt=\"iPhoneX 375x812尺寸图\">  </p>\n<h4 id=\"上下黑边问题\"><a href=\"#上下黑边问题\" class=\"headerlink\" title=\"上下黑边问题\"></a>上下黑边问题</h4><p>运行新版Xcode的iPhoneX模拟器，你可能发现之前的APP在iPhoneX屏幕没填充满，上下有黑色区域，应该是你的app之前未用LaunchScreen.Storyboard作为启动页面，可以使用LaunchScreen来当做入场页面，这样APP才会自动适配为iPhoneX的大小。或者修改Assets中的LaunchImage，添加iPhoneX的Launch图如下(1125*2436)。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/iOS11-adjust-launch.png\" alt=\"LaunchImage适配\">  </p>\n<h4 id=\"iOS11新增版本判断API\"><a href=\"#iOS11新增版本判断API\" class=\"headerlink\" title=\"iOS11新增版本判断API\"></a>iOS11新增版本判断API</h4><p>iOS11版本现在有了简单的API，OC也开始支持swfit的@available语法，不用再手写iOS版本判断了。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">if (@available(iOS 11.0, *)) &#123;</div><div class=\"line\">  // 版本适配</div><div class=\"line\">&#125;</div><div class=\"line\">// 或者</div><div class=\"line\">#ifdef __IPHONE_11_0   </div><div class=\"line\">#endif</div></pre></td></tr></table></figure></p>\n<p>目前没发现有iPhoneX的机型判断API，暂时可以使用size来做代替判断。  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">#define kDevice_iPhoneX CGSizeEqualToSize(CGSizeMake(375, 812), [[UIScreen mainScreen] bounds].size)</div><div class=\"line\">// 或者</div><div class=\"line\">if (UIScreen.mainScreen.bounds.size.height == 812) &#123;</div><div class=\"line\">    NSLog(@&quot;this is iPhone X&quot;);</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<a id=\"more\"></a>\n<h4 id=\"UI适配\"><a href=\"#UI适配\" class=\"headerlink\" title=\"UI适配\"></a>UI适配</h4><h5 id=\"导航栏适配\"><a href=\"#导航栏适配\" class=\"headerlink\" title=\"导航栏适配\"></a>导航栏适配</h5><p>iPhoneX由于多了大圆角、传感器(齐刘海)以及底部访问主屏幕的指示遮挡，所以需要注意原有这部分内容的设计。<br>iOS11前导航栏的高度是64，其中statusBar的高度为20，而iPhoneX的statusBar高度变为了44，如果是自定义的NaviBar，这部分需要做相应的适配。  </p>\n<p>iPhoneX的底部增加了虚拟Home区，由于安全区域的原因默认tabBar的高度由49变为83，增高了34，所以自定义的底部TabBar也需要需改其适配方案。<br>可能有部分APP使用了RN来实现页面，不要忘了在RN中修改相应NaviBar/TabBar的高度。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/iPhoneX-Area.png\" alt=\"iPhoneX尺寸\">  </p>\n<h5 id=\"安全区域\"><a href=\"#安全区域\" class=\"headerlink\" title=\"安全区域\"></a>安全区域</h5><p>安全区域定义了view中可视区域的部分，帮助我们将view放置在整个屏幕的可视的部分。即使把navigationbar设置为透明的，系统也认为安全区域是从navigationbar的bottom开始的。这样保证不被系统的状态栏、或父视图提供的view如导航栏覆盖。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/iOS11-safeArea.png\" alt=\"安全区域\"></p>\n<p>iOS11的UIViewController和UIView新加了<code>-(void)viewSafeAreaInsetsDidChange</code>方法，当安全区域改变后该方法会被调用。然后在该方法中根据safeAreaInses属性更新子视图中控件的布局位置。<br>当然如果你要改变一个UIViewController的safeAreaInsets值, 可以通过设置<code>addtionalSafeAreaInsets</code>属性来实现, 例如你要自定义一些特殊的样式时。<br>需要注意的是viewSafeAreaInsetsDidChange在UIViewController中第一次调用的时间是在<code>-(void)viewWillAppear:(BOOL)animated</code>调用之后, 在<code>- (void)viewWillLayoutSubviews</code>调用之前。所以可以在viewWillAppear里设置受影响的页面的addtionalSafeAreaInsets属性。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">- (void)viewSafeAreaInsetsDidChange&#123;</div><div class=\"line\">    [super viewSafeAreaInsetsDidChange];</div><div class=\"line\">    if (@available(iOS 11.0, *)) &#123;</div><div class=\"line\">        NSLog(@&quot;safeAreaInset list= %@&quot;,NSStringFromUIEdgeInsets(self.view.safeAreaInsets));</div><div class=\"line\">        NSLog(@&quot;safeAreaLayout list= %@&quot;,self.view.safeAreaLayoutGuide);</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h5 id=\"UIScrollView-amp-UITableView\"><a href=\"#UIScrollView-amp-UITableView\" class=\"headerlink\" title=\"UIScrollView &amp; UITableView\"></a>UIScrollView &amp; UITableView</h5><p>测试过程中发现tableView会有20pt/64pt的偏移，其原因是由于iOS 11废弃了UIViewController的<code>automaticallyAdjustsScrollViewInsets</code>属性，新增了contentInsetAdjustmentBehavior属性，所以当超出安全区域时系统自动调整了SafeAreaInsets，进而影响了adjustedContentInset，在iOS11中决定tableView内容与边缘距离的是adjustedContentInset，所以需要设置UIScrollView的contentInsetAdjustmentBehavior属性。  </p>\n<p>1.手动适配<br>如果你使用了UITableView、UIScrollView，可以直接使用以下代码做适配，这样系统就不会主动为你设置边缘距离，但是你可能需要手动适配UITableView的contenteInset。   </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">#ifdef __IPHONE_11_0  </div><div class=\"line\">// 单独作用与某个tableView</div><div class=\"line\">if ([tableView respondsToSelector:@selector(setContentInsetAdjustmentBehavior:)]) &#123;</div><div class=\"line\">  tableView.contentInsetAdjustmentBehavior = UIScrollViewContentInsetAdjustmentNever;</div><div class=\"line\">&#125;</div><div class=\"line\">// 作用与所有的UIScrollView</div><div class=\"line\">UIScrollView.appearance.contentInsetAdjustmentBehavior = UIScrollViewContentInsetAdjustmentNever;</div><div class=\"line\">// 设置view的宽高</div><div class=\"line\">tableView.contentInset = UIEdgeInsetsMake(0, 0, 34, 0);</div><div class=\"line\">#endif</div></pre></td></tr></table></figure>\n<p>2.自动适配<br>设置<code>contentInsetAdjustmentBehavior</code>属性为UIScrollViewContentInsetAdjustmentAutomatic，则系统会自动计算contentView的偏移量。</p>\n<p>3.设置安全区域的addtionalSafeAreaInset<br>某些情况下，你需要顶部区域，比如广告区域覆盖Status，则可以设置相应页面的addtionalSafeAreaInset属性，这样系统不会将safeArea上调到从status开始。这样可以提供更好的用户体验。<br>例如如果你的SafeAreaInset值为(44,0,0,0)，则需要设置相应的additionalSafeAreaInsets值为(-44,0,0,0)。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">if (@available(iOS 11.0, *)) &#123;</div><div class=\"line\">    self.additionalSafeAreaInsets = UIEdgeInsetsMake(-44, 0, 0, 0);</div><div class=\"line\">&#125; else &#123;</div><div class=\"line\">    // Fallback on earlier versions</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>4.iOS11开始UITableView开启了自动估算行高，estimatedRowHeight estimatedSectionHeaderHeight estimatedSectionFooterHeight三个高度估算属性由默认的0变成了UITableViewAutomaticDimension，所以heightForHeaderInSection和viewForHeaderInSection应该一起使用，不然tableView顶部滑动的时候会有空白。<br>在适配过程中发现UITableView会在Header/Footer返回size为负值的情况下会(之前遗漏的bug)崩溃，这块可以自查下，而iOS11之前的版本不会。</p>\n<h5 id=\"其他方案……\"><a href=\"#其他方案……\" class=\"headerlink\" title=\"其他方案……\"></a>其他方案……</h5><p>另外有人对iPhoneX整个UIWindow做了内容的调整，只是UI还是有点丑，感兴趣的同学可以去看看<a href=\"https://github.com/HarshilShah/NotchKit\" target=\"_blank\" rel=\"external\">该GitHub</a>，不过可能这样的设计方案不会通过APPLE的审核。</p>\n<h4 id=\"API适配\"><a href=\"#API适配\" class=\"headerlink\" title=\"API适配\"></a>API适配</h4><h5 id=\"LocalAuthentication-本地认证\"><a href=\"#LocalAuthentication-本地认证\" class=\"headerlink\" title=\"LocalAuthentication 本地认证\"></a>LocalAuthentication 本地认证</h5><p>本地认证框架提供了从具有指定安全策略(密码或生物学特征)的用户请求身份验证的功能。例如，要求用户仅使用Face ID或Touch ID进行身份验证，可使用以下代码：  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">let myContext = LAContext()   </div><div class=\"line\">let myLocalizedReasonString = &lt;#String explaining why app needs authentication#&gt;    </div><div class=\"line\">var authError: NSError?   </div><div class=\"line\">if #available(iOS 8.0, macOS 10.12.1, *) &#123;   </div><div class=\"line\">    if myContext.canEvaluatePolicy(.deviceOwnerAuthenticationWithBiometrics, error: &amp;authError) &#123;   </div><div class=\"line\">        myContext.evaluatePolicy(.deviceOwnerAuthenticationWithBiometrics, localizedReason: myLocalizedReasonString) &#123; success, evaluateError in</div><div class=\"line\">            if success &#123;  </div><div class=\"line\">                // 用户验证通过  </div><div class=\"line\">            &#125; else &#123;  </div><div class=\"line\">                // 用户验证失败，处理失败信息  </div><div class=\"line\">            &#125;  </div><div class=\"line\">        &#125;  </div><div class=\"line\">    &#125; else &#123;  </div><div class=\"line\">        // 不能执行策略验证，处理验证错误信息  </div><div class=\"line\">    &#125;  </div><div class=\"line\">&#125; else &#123;  </div><div class=\"line\">    // Fallback on earlier versions</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>LAContext新增API如下：  </p>\n<ol>\n<li>biometryType属性返回当前设备支持的生物学特征验证方式，他的值可以分别为typeFaceID、typeTouchID或者none。  </li>\n<li>localizedReason需要验证时展示在弹框上的提示信息</li>\n</ol>\n<h5 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h5><ol>\n<li><a href=\"https://developer.apple.com/videos/fall2017/\" target=\"_blank\" rel=\"external\">https://developer.apple.com/videos/fall2017/</a></li>\n<li><a href=\"https://developer.apple.com/iphone/\" target=\"_blank\" rel=\"external\">https://developer.apple.com/iphone/</a></li>\n<li><a href=\"https://developer.apple.com/ios/human-interface-guidelines/overview/iphone-x/\" target=\"_blank\" rel=\"external\">https://developer.apple.com/ios/human-interface-guidelines/overview/iphone-x/</a></li>\n</ol>\n<h5 id=\"Tips\"><a href=\"#Tips\" class=\"headerlink\" title=\"Tips\"></a>Tips</h5><p>iPhone X 侧边按钮的使用方式：  </p>\n<ul>\n<li>按一下锁屏；</li>\n<li>按两下 Apple Pay；</li>\n<li>按三下辅助功能快捷键（比如 VoiceOver）；</li>\n<li>按五下 SOS；</li>\n<li>短按 Siri；</li>\n<li>长按关机；</li>\n<li>按一下+Volume Up 截屏。</li>\n</ul>\n","site":{"data":{}},"excerpt":"<p>iPhone发布会前，就隐隐感觉到一波适配工作要袭来的赶脚，果然不出所料。<br>新版iPhone的适配工作主要集中在iPhoneX上，相信大家已经对iPhoneX的刘海记忆深刻了，除了吐槽，留给我们的还有比较麻烦的适配工作。下面简单分享下在整理过程中发现的适配注意点。(适配工作主要在UI方面，后续发现的适配点会陆续补充到该文档中)  </p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/iPhoneX-Screen.png\" alt=\"iPhoneX 375x812尺寸图\">  </p>\n<h4 id=\"上下黑边问题\"><a href=\"#上下黑边问题\" class=\"headerlink\" title=\"上下黑边问题\"></a>上下黑边问题</h4><p>运行新版Xcode的iPhoneX模拟器，你可能发现之前的APP在iPhoneX屏幕没填充满，上下有黑色区域，应该是你的app之前未用LaunchScreen.Storyboard作为启动页面，可以使用LaunchScreen来当做入场页面，这样APP才会自动适配为iPhoneX的大小。或者修改Assets中的LaunchImage，添加iPhoneX的Launch图如下(1125*2436)。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/iOS11-adjust-launch.png\" alt=\"LaunchImage适配\">  </p>\n<h4 id=\"iOS11新增版本判断API\"><a href=\"#iOS11新增版本判断API\" class=\"headerlink\" title=\"iOS11新增版本判断API\"></a>iOS11新增版本判断API</h4><p>iOS11版本现在有了简单的API，OC也开始支持swfit的@available语法，不用再手写iOS版本判断了。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">if (@available(iOS 11.0, *)) &#123;</div><div class=\"line\">  // 版本适配</div><div class=\"line\">&#125;</div><div class=\"line\">// 或者</div><div class=\"line\">#ifdef __IPHONE_11_0   </div><div class=\"line\">#endif</div></pre></td></tr></table></figure></p>\n<p>目前没发现有iPhoneX的机型判断API，暂时可以使用size来做代替判断。  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">#define kDevice_iPhoneX CGSizeEqualToSize(CGSizeMake(375, 812), [[UIScreen mainScreen] bounds].size)</div><div class=\"line\">// 或者</div><div class=\"line\">if (UIScreen.mainScreen.bounds.size.height == 812) &#123;</div><div class=\"line\">    NSLog(@&quot;this is iPhone X&quot;);</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>","more":"<h4 id=\"UI适配\"><a href=\"#UI适配\" class=\"headerlink\" title=\"UI适配\"></a>UI适配</h4><h5 id=\"导航栏适配\"><a href=\"#导航栏适配\" class=\"headerlink\" title=\"导航栏适配\"></a>导航栏适配</h5><p>iPhoneX由于多了大圆角、传感器(齐刘海)以及底部访问主屏幕的指示遮挡，所以需要注意原有这部分内容的设计。<br>iOS11前导航栏的高度是64，其中statusBar的高度为20，而iPhoneX的statusBar高度变为了44，如果是自定义的NaviBar，这部分需要做相应的适配。  </p>\n<p>iPhoneX的底部增加了虚拟Home区，由于安全区域的原因默认tabBar的高度由49变为83，增高了34，所以自定义的底部TabBar也需要需改其适配方案。<br>可能有部分APP使用了RN来实现页面，不要忘了在RN中修改相应NaviBar/TabBar的高度。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/iPhoneX-Area.png\" alt=\"iPhoneX尺寸\">  </p>\n<h5 id=\"安全区域\"><a href=\"#安全区域\" class=\"headerlink\" title=\"安全区域\"></a>安全区域</h5><p>安全区域定义了view中可视区域的部分，帮助我们将view放置在整个屏幕的可视的部分。即使把navigationbar设置为透明的，系统也认为安全区域是从navigationbar的bottom开始的。这样保证不被系统的状态栏、或父视图提供的view如导航栏覆盖。</p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/iOS11-safeArea.png\" alt=\"安全区域\"></p>\n<p>iOS11的UIViewController和UIView新加了<code>-(void)viewSafeAreaInsetsDidChange</code>方法，当安全区域改变后该方法会被调用。然后在该方法中根据safeAreaInses属性更新子视图中控件的布局位置。<br>当然如果你要改变一个UIViewController的safeAreaInsets值, 可以通过设置<code>addtionalSafeAreaInsets</code>属性来实现, 例如你要自定义一些特殊的样式时。<br>需要注意的是viewSafeAreaInsetsDidChange在UIViewController中第一次调用的时间是在<code>-(void)viewWillAppear:(BOOL)animated</code>调用之后, 在<code>- (void)viewWillLayoutSubviews</code>调用之前。所以可以在viewWillAppear里设置受影响的页面的addtionalSafeAreaInsets属性。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">- (void)viewSafeAreaInsetsDidChange&#123;</div><div class=\"line\">    [super viewSafeAreaInsetsDidChange];</div><div class=\"line\">    if (@available(iOS 11.0, *)) &#123;</div><div class=\"line\">        NSLog(@&quot;safeAreaInset list= %@&quot;,NSStringFromUIEdgeInsets(self.view.safeAreaInsets));</div><div class=\"line\">        NSLog(@&quot;safeAreaLayout list= %@&quot;,self.view.safeAreaLayoutGuide);</div><div class=\"line\">    &#125;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<h5 id=\"UIScrollView-amp-UITableView\"><a href=\"#UIScrollView-amp-UITableView\" class=\"headerlink\" title=\"UIScrollView &amp; UITableView\"></a>UIScrollView &amp; UITableView</h5><p>测试过程中发现tableView会有20pt/64pt的偏移，其原因是由于iOS 11废弃了UIViewController的<code>automaticallyAdjustsScrollViewInsets</code>属性，新增了contentInsetAdjustmentBehavior属性，所以当超出安全区域时系统自动调整了SafeAreaInsets，进而影响了adjustedContentInset，在iOS11中决定tableView内容与边缘距离的是adjustedContentInset，所以需要设置UIScrollView的contentInsetAdjustmentBehavior属性。  </p>\n<p>1.手动适配<br>如果你使用了UITableView、UIScrollView，可以直接使用以下代码做适配，这样系统就不会主动为你设置边缘距离，但是你可能需要手动适配UITableView的contenteInset。   </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\">#ifdef __IPHONE_11_0  </div><div class=\"line\">// 单独作用与某个tableView</div><div class=\"line\">if ([tableView respondsToSelector:@selector(setContentInsetAdjustmentBehavior:)]) &#123;</div><div class=\"line\">  tableView.contentInsetAdjustmentBehavior = UIScrollViewContentInsetAdjustmentNever;</div><div class=\"line\">&#125;</div><div class=\"line\">// 作用与所有的UIScrollView</div><div class=\"line\">UIScrollView.appearance.contentInsetAdjustmentBehavior = UIScrollViewContentInsetAdjustmentNever;</div><div class=\"line\">// 设置view的宽高</div><div class=\"line\">tableView.contentInset = UIEdgeInsetsMake(0, 0, 34, 0);</div><div class=\"line\">#endif</div></pre></td></tr></table></figure>\n<p>2.自动适配<br>设置<code>contentInsetAdjustmentBehavior</code>属性为UIScrollViewContentInsetAdjustmentAutomatic，则系统会自动计算contentView的偏移量。</p>\n<p>3.设置安全区域的addtionalSafeAreaInset<br>某些情况下，你需要顶部区域，比如广告区域覆盖Status，则可以设置相应页面的addtionalSafeAreaInset属性，这样系统不会将safeArea上调到从status开始。这样可以提供更好的用户体验。<br>例如如果你的SafeAreaInset值为(44,0,0,0)，则需要设置相应的additionalSafeAreaInsets值为(-44,0,0,0)。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">if (@available(iOS 11.0, *)) &#123;</div><div class=\"line\">    self.additionalSafeAreaInsets = UIEdgeInsetsMake(-44, 0, 0, 0);</div><div class=\"line\">&#125; else &#123;</div><div class=\"line\">    // Fallback on earlier versions</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>4.iOS11开始UITableView开启了自动估算行高，estimatedRowHeight estimatedSectionHeaderHeight estimatedSectionFooterHeight三个高度估算属性由默认的0变成了UITableViewAutomaticDimension，所以heightForHeaderInSection和viewForHeaderInSection应该一起使用，不然tableView顶部滑动的时候会有空白。<br>在适配过程中发现UITableView会在Header/Footer返回size为负值的情况下会(之前遗漏的bug)崩溃，这块可以自查下，而iOS11之前的版本不会。</p>\n<h5 id=\"其他方案……\"><a href=\"#其他方案……\" class=\"headerlink\" title=\"其他方案……\"></a>其他方案……</h5><p>另外有人对iPhoneX整个UIWindow做了内容的调整，只是UI还是有点丑，感兴趣的同学可以去看看<a href=\"https://github.com/HarshilShah/NotchKit\" target=\"_blank\" rel=\"external\">该GitHub</a>，不过可能这样的设计方案不会通过APPLE的审核。</p>\n<h4 id=\"API适配\"><a href=\"#API适配\" class=\"headerlink\" title=\"API适配\"></a>API适配</h4><h5 id=\"LocalAuthentication-本地认证\"><a href=\"#LocalAuthentication-本地认证\" class=\"headerlink\" title=\"LocalAuthentication 本地认证\"></a>LocalAuthentication 本地认证</h5><p>本地认证框架提供了从具有指定安全策略(密码或生物学特征)的用户请求身份验证的功能。例如，要求用户仅使用Face ID或Touch ID进行身份验证，可使用以下代码：  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\">let myContext = LAContext()   </div><div class=\"line\">let myLocalizedReasonString = &lt;#String explaining why app needs authentication#&gt;    </div><div class=\"line\">var authError: NSError?   </div><div class=\"line\">if #available(iOS 8.0, macOS 10.12.1, *) &#123;   </div><div class=\"line\">    if myContext.canEvaluatePolicy(.deviceOwnerAuthenticationWithBiometrics, error: &amp;authError) &#123;   </div><div class=\"line\">        myContext.evaluatePolicy(.deviceOwnerAuthenticationWithBiometrics, localizedReason: myLocalizedReasonString) &#123; success, evaluateError in</div><div class=\"line\">            if success &#123;  </div><div class=\"line\">                // 用户验证通过  </div><div class=\"line\">            &#125; else &#123;  </div><div class=\"line\">                // 用户验证失败，处理失败信息  </div><div class=\"line\">            &#125;  </div><div class=\"line\">        &#125;  </div><div class=\"line\">    &#125; else &#123;  </div><div class=\"line\">        // 不能执行策略验证，处理验证错误信息  </div><div class=\"line\">    &#125;  </div><div class=\"line\">&#125; else &#123;  </div><div class=\"line\">    // Fallback on earlier versions</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>LAContext新增API如下：  </p>\n<ol>\n<li>biometryType属性返回当前设备支持的生物学特征验证方式，他的值可以分别为typeFaceID、typeTouchID或者none。  </li>\n<li>localizedReason需要验证时展示在弹框上的提示信息</li>\n</ol>\n<h5 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h5><ol>\n<li><a href=\"https://developer.apple.com/videos/fall2017/\" target=\"_blank\" rel=\"external\">https://developer.apple.com/videos/fall2017/</a></li>\n<li><a href=\"https://developer.apple.com/iphone/\" target=\"_blank\" rel=\"external\">https://developer.apple.com/iphone/</a></li>\n<li><a href=\"https://developer.apple.com/ios/human-interface-guidelines/overview/iphone-x/\" target=\"_blank\" rel=\"external\">https://developer.apple.com/ios/human-interface-guidelines/overview/iphone-x/</a></li>\n</ol>\n<h5 id=\"Tips\"><a href=\"#Tips\" class=\"headerlink\" title=\"Tips\"></a>Tips</h5><p>iPhone X 侧边按钮的使用方式：  </p>\n<ul>\n<li>按一下锁屏；</li>\n<li>按两下 Apple Pay；</li>\n<li>按三下辅助功能快捷键（比如 VoiceOver）；</li>\n<li>按五下 SOS；</li>\n<li>短按 Siri；</li>\n<li>长按关机；</li>\n<li>按一下+Volume Up 截屏。</li>\n</ul>"},{"title":"iOS混淆--OLLVM在iOS中的实践","date":"2017-09-07T04:15:18.000Z","comments":1,"_content":"\n\n### OLLVM简介\n\n[OLLVM（Obfuscator-LLVM）](https://github.com/obfuscator-llvm/obfuscator)是瑞士西北应用科技大学安全实验室于2010年6月份发起的一个项目，该项目旨在提供一套开源的针对LLVM的代码混淆工具，以增加对逆向工程的难度。后期转向商业项目[strong.protect](http://link.zhihu.com/?target=https%3A//strong.codes/)。目前，OLLVM已经支持LLVM-4.0版本。\n\nLLVM是一个优秀的编译器框架，它也采用经典的三段式设计。前端可以使用不同的编译工具对代码文件做词法分析以形成抽象语法树AST，然后将分析好的代码转换成LLVM的中间表示IR（intermediate representation）；中间部分的优化器只对中间表示IR操作，通过一系列的Pass对IR做优化；后端负责将优化好的IR解释成对应平台的机器码。LLVM的优点在于，中间表示IR代码编写良好，而且不同的前端语言最终都转换成同一种的IR。\n\n![](http://upload-images.jianshu.io/upload_images/1944396-3ce371d488ad67ac.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\nLLVM IR 是LLVM的中间表示，优化器就是对IR进行操作的，具体的优化操作由一些列的Pass来完成，当前端生成初级IR后，Pass会依次对IR进行处理，最终生成后端可用的IR。下图可以说明这个过程：\n![](http://upload-images.jianshu.io/upload_images/1944396-20cd55c8ee11762d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\nOLLVM的混淆操作就是在中间表示IR层，通过编写Pass来混淆IR，然后后端依据IR来生成的目标代码也就被混淆了。得益于LLVM的设计，OLLVM适用LLVM支持的所有语言（C,C++,Objective-C,Ada,Fortran）和目标平台（x86,x86-64,PowerPC,PowerPC-64, ARM, Thumb, SPARC, Alpha, CellSPU, MIPS, MSP430, SystemZ, 和 XCore）\n<!--more-->\n#### OLLVM iOS编译环境搭建\n以下，介绍OLLVM iOS环境的插件创建过程。\n首先下载源码，编译OLLVM混淆器，这里采用LLVM的版本是4.0。下载编译过程如下：\n\n ```\n $ git clone -b llvm-4.0 https://github.com/obfuscator-llvm/obfuscator.git  \n $ mkdir build  \n $ cd build  \n $ cmake -DCMAKE_BUILD_TYPE=Release ../obfuscator/  \n $ make -j7  \n ```\n\n下载的源码里已经包含了LLVM和Clang，编译完成后，编译好的二进制程序都存在在build/bin目录下。\n\n依据github上的wiki，bin目录下编译好的工具链可以直接用来编译混淆linux下的程序，就像我们常用的gcc那样。若想使用OLLVM来混淆iOS程序，还需将bin目录下的工具链整合进Xcode插件中，具体步骤如下。\n\n配置Xcode--新建Obfuscator插件\n\n```\n$ cd /Applications/Xcode.app/Contents/PlugIns/Xcode3Core.ideplugin/Contents/SharedSupport/Developer/Library/Xcode/Plug-ins/  \n$ sudo cp -r Clang\\ LLVM\\ 1.0.xcplugin/ Obfuscator.xcplugin  \n$ cd Obfuscator.xcplugin/Contents/  \n$ sudo plutil -convert xml1 Info.plist  \n$ sudo vim Info.plist  \n```\n修改Info.plist中的对应内容：\n\n```\n<string>com.apple.compilers.clang</string> -> <string>com.apple.compilers.obfuscator</string>  \n<string>Clang LLVM 1.0 Compiler Xcode Plug-in</string> -> <string>Obfuscator Xcode Plug-in</string>  \n```\n\n修改Obfuscator.xcspec文件\n\n```\n$ sudo plutil -convert binary1 Info.plist  \n$ cd Resources/  \n$ sudo mv Clang\\ LLVM\\ 1.0.xcspec Obfuscator.xcspec  \n$ sudo vim Obfuscator.xcspec  \n```\n修改ExecPath的地址为当前build/bin的地址(!重点)\n\n```\nIdentifier = \"com.apple.compilers.llvm.clang.1_0\"; -> Identifier = \"com.apple.compilers.llvm.obfuscator.4_0\";  \nName = \"Apple LLVM 8.0\"; -> Name = \"Obfuscator 4.0\";  \nDescription = \"Apple LLVM 8.0 compiler\"; -> Description = \"Obfuscator 4.0\";  \nVendor = Apple; -> Vendor = HEIG-VD;  \nVersion = \"7.0\"; -> Version = \"4.0\";  \nExecPath = \"clang\"; -> ExecPath = \"/path/to/obfuscator_bin/clang\";  \n```\n\n修改 Obfuscator 4.0 Strings\n\n```\n$ cd English.lproj/  \n$ sudo mv Apple\\ LLVM\\ 8.0.strings \"Obfuscator 4.0.strings\"  \n$ sudo plutil -convert xml1 Obfuscator\\ 4.0.strings  \n$ sudo vim Obfuscator\\ 4.0.strings  \n```\n\n```\n\"Description\" = \"Apple LLVM 8.0 Compiler\"; -> \"Description\" = \"Obfuscator 4.0\";  \n\"Name\" = \"Apple LLVM 8.0\"; -> \"Name\" = \"Obfuscator 4.0\";  \n\"Vendor\" = \"Apple\"; -> \"Vendor\" = \"HEIG-VD\";  \n\"Version\" = \"8.0\"; -> \"Version\" = \"4.0\";  \n```\n`sudo plutil -convert binary1 Obfuscator\\ 4.0.strings`  \n\n\n现在，你可以打开Xcode在项目配置里来选择新的编译器，并且可以在C Flags或C++ Flags下添加混淆标签。\n\n![选择编译器](http://upload-images.jianshu.io/upload_images/1944396-a27167d3a47b3bc7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n![添加混淆标签](http://upload-images.jianshu.io/upload_images/1944396-76e1b58511f4a559.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n这样配置完成后，就可以编译项目生成混淆后的程序。\n\n#### ollvm混淆使用\n\n接下来使用以下demo介绍混淆功能的具体使用。  \n```\nint main(){  \n    int a = 1;  \n    int b = 0;  \n    int c = 0;  \n    if(a > b){  \n        a = 100;    \n        b = 50;    \n        c = a - b;    \n        int d = a + b;    \n        int e = a & b;    \n        int f = a ^ b;    \n        printf(\"c = %d\\n\",c);    \n        printf(\"d = %d\\n\",d);    \n        printf(\"e = %d\\n\",e);    \n        printf(\"f = %d\\n\",f);    \n        printf(\"a > b\\n\");    \n    }else{  \n        printf(\"a < b\\n\");    \n    }  \n    return 0;  \n}\n```\n\nOLLVM默认支持-fla -sub -bcf 三个混淆参数，这三个参数可以单独使用，也可以配合着使用。-fla 参数表示使用控制流平展（Control Flow Flattening）模式， -sub 参数表示使用指令替换（Instructions Substitution）模式， -bcf 参数表示使用控制流伪造（Bogus Control Flow）模式。\n\n##### Instructions Substitution\n\n指令替换模式主要是将正常的运算操作（+，-，&，|等）替换成功能相等但表述更复杂的形式。比如，对于表达式 a = b + c，它的等价式可以有 a = – ( -b – c), a = b – (-c) 或 a = -(-b) + c 等，原表达式可以替换成任意相等式，或者通过随机数在多个相等式中做选择。SUB模式目前只支持整数运算操作，支持 + , – , & , | 和 ^ 操作，还是比较局限的。编译时，使用 -mllvm -sub 参数即可。\n\n```\n-mllvm -sub: 启用instructions substitution  \n-mllvm -sub_loop=3: 对每个函数混淆3次，默认1词  \n```\n![](http://upload-images.jianshu.io/upload_images/1944396-d3ef62eb9e13ae93.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n![](http://upload-images.jianshu.io/upload_images/1944396-a8aff8dc34d9a432.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n##### Control Flow Flattening\n\n控制流平展模式可以完全改变程序原本的控制流图。如下示例代码是简单的if-else分支语句，正常编译后其控制流图在IDA中下图所示，是正常的if-else分支，使用 -mllvm -fla参数混淆后，在IDA中显示的控制流图如下：\n![](http://upload-images.jianshu.io/upload_images/1944396-4a84eba4712effb8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n![](http://upload-images.jianshu.io/upload_images/1944396-47b61ea46b1eee67.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n经FLA模式混淆后，程序的执行流程已经被打乱，出现许多代码分支。通过仔细对比程序混淆前后，可以发现上图着色区域是相对应的，也就是说，FLA模式只去更改代码分支，而不会对单个代码块做处理。\n\n```\n-mllvm -fla: 启用control flow flattening\n-mllvm -split: 启用block切分，提升平展程度\n-mllvm -split_num=3: 对每个block混淆3次，默认1词\n```\n\n##### Bogus Control Flow\n\n控制流伪造模式也是对程序的控制流做操作，不同的是，BCF模式会在原代码块的前后随机插入新的代码块，新插入的代码块不是确定的，然后新代码块再通过条件判断跳转到原代码块中。更要命地是，原代码块可能会被克隆并插入随机的垃圾指令。这么多不确定性，就导致对同一份代码多次做BCF模式的混淆时，得到的是不同的混淆效果。可见，BCF混淆模式还是很强大的，不同于FLA那种较确定的混淆模式。使用BCF模式编译时配置参数 -mllvm -bcf即可，此外，BCF模式还支持其它几个参数，下面参数与-mllvm -bcf参数配合使用。  \n```\n-mllvm -bcf: 启用 bogus control flow\n-mllvm -bcf_loop=3: 对一个函数混淆3次，默认1次\n-mllvm -bcf_prob=40: 代码块被混淆的概率是40%，默认30%\n```\n如上图，下面两个着色的代码块就是有上面两个代码块克隆而来，而且其中被插入了一些垃圾指令，类似于这样：\n\n\n当然，上述介绍的三种混淆模式可以搭配使用，同时使用三个参数混淆后，原本简单的if-else分支代码将会变得异常复杂，这无疑给逆向分析增加巨大的难度。\n\n##### Functions annotations\n\n有的时候，由于效率或其他原因的考虑，我们只想给指定的函数混淆或不混淆该函数，OLLVM也提供了对这一特性的支持，你只需要给对应的函数添加attributes即可。比如，想对函数foo()使用fla混淆，只需要给函数foo()增加fla属性即可。  \n\n```\nint foo() __attribute((__annotate__((\"fla\"))));\nint foo() {\n   return 2;\n}\n```\n\n你可以给函数添加一个或多个注释。如果你不想混淆某个函数，你可以使用否定标签。例如如果不想对func()函数使用bcf属性，那标记为“nobcf”即可。\n\n\n\n#### 错误处理\n1.编译时报错，提示信息如下：  \n\n```\nclang-3.6: error: unknown argument: '-gmodules'\nclang-3.6: error: unknown argument: '-fembed-bitcode-marker'\nCommand /Users/dream/ollvm/build/bin/clang failed with exit code 1\n```\n在Build Settings中搜索并修改：\n-gmodules: Obfuscator 4.0 - Code Generation: Generate Debug Symbols: 原来yes，改成no\n-fembed-bitcode-marker: Build Option: Enable Bitcode: 原来yes，改成no\n\n\n你可以在该[git地址]()下找到最新的插件和build编译器文件，该编译器所使用的Xcode版本是8.3.3。\n","source":"_posts/ollvm-in-iOS.md","raw":"---\ntitle: iOS混淆--OLLVM在iOS中的实践\ndate: 2017-09-07 12:15:18\ntags: 安全\ncomments: true\ncategories: LLVM\n---\n\n\n### OLLVM简介\n\n[OLLVM（Obfuscator-LLVM）](https://github.com/obfuscator-llvm/obfuscator)是瑞士西北应用科技大学安全实验室于2010年6月份发起的一个项目，该项目旨在提供一套开源的针对LLVM的代码混淆工具，以增加对逆向工程的难度。后期转向商业项目[strong.protect](http://link.zhihu.com/?target=https%3A//strong.codes/)。目前，OLLVM已经支持LLVM-4.0版本。\n\nLLVM是一个优秀的编译器框架，它也采用经典的三段式设计。前端可以使用不同的编译工具对代码文件做词法分析以形成抽象语法树AST，然后将分析好的代码转换成LLVM的中间表示IR（intermediate representation）；中间部分的优化器只对中间表示IR操作，通过一系列的Pass对IR做优化；后端负责将优化好的IR解释成对应平台的机器码。LLVM的优点在于，中间表示IR代码编写良好，而且不同的前端语言最终都转换成同一种的IR。\n\n![](http://upload-images.jianshu.io/upload_images/1944396-3ce371d488ad67ac.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\nLLVM IR 是LLVM的中间表示，优化器就是对IR进行操作的，具体的优化操作由一些列的Pass来完成，当前端生成初级IR后，Pass会依次对IR进行处理，最终生成后端可用的IR。下图可以说明这个过程：\n![](http://upload-images.jianshu.io/upload_images/1944396-20cd55c8ee11762d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\nOLLVM的混淆操作就是在中间表示IR层，通过编写Pass来混淆IR，然后后端依据IR来生成的目标代码也就被混淆了。得益于LLVM的设计，OLLVM适用LLVM支持的所有语言（C,C++,Objective-C,Ada,Fortran）和目标平台（x86,x86-64,PowerPC,PowerPC-64, ARM, Thumb, SPARC, Alpha, CellSPU, MIPS, MSP430, SystemZ, 和 XCore）\n<!--more-->\n#### OLLVM iOS编译环境搭建\n以下，介绍OLLVM iOS环境的插件创建过程。\n首先下载源码，编译OLLVM混淆器，这里采用LLVM的版本是4.0。下载编译过程如下：\n\n ```\n $ git clone -b llvm-4.0 https://github.com/obfuscator-llvm/obfuscator.git  \n $ mkdir build  \n $ cd build  \n $ cmake -DCMAKE_BUILD_TYPE=Release ../obfuscator/  \n $ make -j7  \n ```\n\n下载的源码里已经包含了LLVM和Clang，编译完成后，编译好的二进制程序都存在在build/bin目录下。\n\n依据github上的wiki，bin目录下编译好的工具链可以直接用来编译混淆linux下的程序，就像我们常用的gcc那样。若想使用OLLVM来混淆iOS程序，还需将bin目录下的工具链整合进Xcode插件中，具体步骤如下。\n\n配置Xcode--新建Obfuscator插件\n\n```\n$ cd /Applications/Xcode.app/Contents/PlugIns/Xcode3Core.ideplugin/Contents/SharedSupport/Developer/Library/Xcode/Plug-ins/  \n$ sudo cp -r Clang\\ LLVM\\ 1.0.xcplugin/ Obfuscator.xcplugin  \n$ cd Obfuscator.xcplugin/Contents/  \n$ sudo plutil -convert xml1 Info.plist  \n$ sudo vim Info.plist  \n```\n修改Info.plist中的对应内容：\n\n```\n<string>com.apple.compilers.clang</string> -> <string>com.apple.compilers.obfuscator</string>  \n<string>Clang LLVM 1.0 Compiler Xcode Plug-in</string> -> <string>Obfuscator Xcode Plug-in</string>  \n```\n\n修改Obfuscator.xcspec文件\n\n```\n$ sudo plutil -convert binary1 Info.plist  \n$ cd Resources/  \n$ sudo mv Clang\\ LLVM\\ 1.0.xcspec Obfuscator.xcspec  \n$ sudo vim Obfuscator.xcspec  \n```\n修改ExecPath的地址为当前build/bin的地址(!重点)\n\n```\nIdentifier = \"com.apple.compilers.llvm.clang.1_0\"; -> Identifier = \"com.apple.compilers.llvm.obfuscator.4_0\";  \nName = \"Apple LLVM 8.0\"; -> Name = \"Obfuscator 4.0\";  \nDescription = \"Apple LLVM 8.0 compiler\"; -> Description = \"Obfuscator 4.0\";  \nVendor = Apple; -> Vendor = HEIG-VD;  \nVersion = \"7.0\"; -> Version = \"4.0\";  \nExecPath = \"clang\"; -> ExecPath = \"/path/to/obfuscator_bin/clang\";  \n```\n\n修改 Obfuscator 4.0 Strings\n\n```\n$ cd English.lproj/  \n$ sudo mv Apple\\ LLVM\\ 8.0.strings \"Obfuscator 4.0.strings\"  \n$ sudo plutil -convert xml1 Obfuscator\\ 4.0.strings  \n$ sudo vim Obfuscator\\ 4.0.strings  \n```\n\n```\n\"Description\" = \"Apple LLVM 8.0 Compiler\"; -> \"Description\" = \"Obfuscator 4.0\";  \n\"Name\" = \"Apple LLVM 8.0\"; -> \"Name\" = \"Obfuscator 4.0\";  \n\"Vendor\" = \"Apple\"; -> \"Vendor\" = \"HEIG-VD\";  \n\"Version\" = \"8.0\"; -> \"Version\" = \"4.0\";  \n```\n`sudo plutil -convert binary1 Obfuscator\\ 4.0.strings`  \n\n\n现在，你可以打开Xcode在项目配置里来选择新的编译器，并且可以在C Flags或C++ Flags下添加混淆标签。\n\n![选择编译器](http://upload-images.jianshu.io/upload_images/1944396-a27167d3a47b3bc7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n![添加混淆标签](http://upload-images.jianshu.io/upload_images/1944396-76e1b58511f4a559.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n这样配置完成后，就可以编译项目生成混淆后的程序。\n\n#### ollvm混淆使用\n\n接下来使用以下demo介绍混淆功能的具体使用。  \n```\nint main(){  \n    int a = 1;  \n    int b = 0;  \n    int c = 0;  \n    if(a > b){  \n        a = 100;    \n        b = 50;    \n        c = a - b;    \n        int d = a + b;    \n        int e = a & b;    \n        int f = a ^ b;    \n        printf(\"c = %d\\n\",c);    \n        printf(\"d = %d\\n\",d);    \n        printf(\"e = %d\\n\",e);    \n        printf(\"f = %d\\n\",f);    \n        printf(\"a > b\\n\");    \n    }else{  \n        printf(\"a < b\\n\");    \n    }  \n    return 0;  \n}\n```\n\nOLLVM默认支持-fla -sub -bcf 三个混淆参数，这三个参数可以单独使用，也可以配合着使用。-fla 参数表示使用控制流平展（Control Flow Flattening）模式， -sub 参数表示使用指令替换（Instructions Substitution）模式， -bcf 参数表示使用控制流伪造（Bogus Control Flow）模式。\n\n##### Instructions Substitution\n\n指令替换模式主要是将正常的运算操作（+，-，&，|等）替换成功能相等但表述更复杂的形式。比如，对于表达式 a = b + c，它的等价式可以有 a = – ( -b – c), a = b – (-c) 或 a = -(-b) + c 等，原表达式可以替换成任意相等式，或者通过随机数在多个相等式中做选择。SUB模式目前只支持整数运算操作，支持 + , – , & , | 和 ^ 操作，还是比较局限的。编译时，使用 -mllvm -sub 参数即可。\n\n```\n-mllvm -sub: 启用instructions substitution  \n-mllvm -sub_loop=3: 对每个函数混淆3次，默认1词  \n```\n![](http://upload-images.jianshu.io/upload_images/1944396-d3ef62eb9e13ae93.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n![](http://upload-images.jianshu.io/upload_images/1944396-a8aff8dc34d9a432.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n##### Control Flow Flattening\n\n控制流平展模式可以完全改变程序原本的控制流图。如下示例代码是简单的if-else分支语句，正常编译后其控制流图在IDA中下图所示，是正常的if-else分支，使用 -mllvm -fla参数混淆后，在IDA中显示的控制流图如下：\n![](http://upload-images.jianshu.io/upload_images/1944396-4a84eba4712effb8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n![](http://upload-images.jianshu.io/upload_images/1944396-47b61ea46b1eee67.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n\n经FLA模式混淆后，程序的执行流程已经被打乱，出现许多代码分支。通过仔细对比程序混淆前后，可以发现上图着色区域是相对应的，也就是说，FLA模式只去更改代码分支，而不会对单个代码块做处理。\n\n```\n-mllvm -fla: 启用control flow flattening\n-mllvm -split: 启用block切分，提升平展程度\n-mllvm -split_num=3: 对每个block混淆3次，默认1词\n```\n\n##### Bogus Control Flow\n\n控制流伪造模式也是对程序的控制流做操作，不同的是，BCF模式会在原代码块的前后随机插入新的代码块，新插入的代码块不是确定的，然后新代码块再通过条件判断跳转到原代码块中。更要命地是，原代码块可能会被克隆并插入随机的垃圾指令。这么多不确定性，就导致对同一份代码多次做BCF模式的混淆时，得到的是不同的混淆效果。可见，BCF混淆模式还是很强大的，不同于FLA那种较确定的混淆模式。使用BCF模式编译时配置参数 -mllvm -bcf即可，此外，BCF模式还支持其它几个参数，下面参数与-mllvm -bcf参数配合使用。  \n```\n-mllvm -bcf: 启用 bogus control flow\n-mllvm -bcf_loop=3: 对一个函数混淆3次，默认1次\n-mllvm -bcf_prob=40: 代码块被混淆的概率是40%，默认30%\n```\n如上图，下面两个着色的代码块就是有上面两个代码块克隆而来，而且其中被插入了一些垃圾指令，类似于这样：\n\n\n当然，上述介绍的三种混淆模式可以搭配使用，同时使用三个参数混淆后，原本简单的if-else分支代码将会变得异常复杂，这无疑给逆向分析增加巨大的难度。\n\n##### Functions annotations\n\n有的时候，由于效率或其他原因的考虑，我们只想给指定的函数混淆或不混淆该函数，OLLVM也提供了对这一特性的支持，你只需要给对应的函数添加attributes即可。比如，想对函数foo()使用fla混淆，只需要给函数foo()增加fla属性即可。  \n\n```\nint foo() __attribute((__annotate__((\"fla\"))));\nint foo() {\n   return 2;\n}\n```\n\n你可以给函数添加一个或多个注释。如果你不想混淆某个函数，你可以使用否定标签。例如如果不想对func()函数使用bcf属性，那标记为“nobcf”即可。\n\n\n\n#### 错误处理\n1.编译时报错，提示信息如下：  \n\n```\nclang-3.6: error: unknown argument: '-gmodules'\nclang-3.6: error: unknown argument: '-fembed-bitcode-marker'\nCommand /Users/dream/ollvm/build/bin/clang failed with exit code 1\n```\n在Build Settings中搜索并修改：\n-gmodules: Obfuscator 4.0 - Code Generation: Generate Debug Symbols: 原来yes，改成no\n-fembed-bitcode-marker: Build Option: Enable Bitcode: 原来yes，改成no\n\n\n你可以在该[git地址]()下找到最新的插件和build编译器文件，该编译器所使用的Xcode版本是8.3.3。\n","slug":"ollvm-in-iOS","published":1,"updated":"2017-09-25T12:21:59.000Z","layout":"post","photos":[],"link":"","_id":"cj81l5461000swluvavmebn49","content":"<h3 id=\"OLLVM简介\"><a href=\"#OLLVM简介\" class=\"headerlink\" title=\"OLLVM简介\"></a>OLLVM简介</h3><p><a href=\"https://github.com/obfuscator-llvm/obfuscator\" target=\"_blank\" rel=\"external\">OLLVM（Obfuscator-LLVM）</a>是瑞士西北应用科技大学安全实验室于2010年6月份发起的一个项目，该项目旨在提供一套开源的针对LLVM的代码混淆工具，以增加对逆向工程的难度。后期转向商业项目<a href=\"http://link.zhihu.com/?target=https%3A//strong.codes/\" target=\"_blank\" rel=\"external\">strong.protect</a>。目前，OLLVM已经支持LLVM-4.0版本。</p>\n<p>LLVM是一个优秀的编译器框架，它也采用经典的三段式设计。前端可以使用不同的编译工具对代码文件做词法分析以形成抽象语法树AST，然后将分析好的代码转换成LLVM的中间表示IR（intermediate representation）；中间部分的优化器只对中间表示IR操作，通过一系列的Pass对IR做优化；后端负责将优化好的IR解释成对应平台的机器码。LLVM的优点在于，中间表示IR代码编写良好，而且不同的前端语言最终都转换成同一种的IR。</p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1944396-3ce371d488ad67ac.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"></p>\n<p>LLVM IR 是LLVM的中间表示，优化器就是对IR进行操作的，具体的优化操作由一些列的Pass来完成，当前端生成初级IR后，Pass会依次对IR进行处理，最终生成后端可用的IR。下图可以说明这个过程：<br><img src=\"http://upload-images.jianshu.io/upload_images/1944396-20cd55c8ee11762d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"></p>\n<p>OLLVM的混淆操作就是在中间表示IR层，通过编写Pass来混淆IR，然后后端依据IR来生成的目标代码也就被混淆了。得益于LLVM的设计，OLLVM适用LLVM支持的所有语言（C,C++,Objective-C,Ada,Fortran）和目标平台（x86,x86-64,PowerPC,PowerPC-64, ARM, Thumb, SPARC, Alpha, CellSPU, MIPS, MSP430, SystemZ, 和 XCore）<br><a id=\"more\"></a></p>\n<h4 id=\"OLLVM-iOS编译环境搭建\"><a href=\"#OLLVM-iOS编译环境搭建\" class=\"headerlink\" title=\"OLLVM iOS编译环境搭建\"></a>OLLVM iOS编译环境搭建</h4><p>以下，介绍OLLVM iOS环境的插件创建过程。<br>首先下载源码，编译OLLVM混淆器，这里采用LLVM的版本是4.0。下载编译过程如下：</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ git clone -b llvm-4.0 https://github.com/obfuscator-llvm/obfuscator.git  </div><div class=\"line\">$ mkdir build  </div><div class=\"line\">$ cd build  </div><div class=\"line\">$ cmake -DCMAKE_BUILD_TYPE=Release ../obfuscator/  </div><div class=\"line\">$ make -j7</div></pre></td></tr></table></figure>\n<p>下载的源码里已经包含了LLVM和Clang，编译完成后，编译好的二进制程序都存在在build/bin目录下。</p>\n<p>依据github上的wiki，bin目录下编译好的工具链可以直接用来编译混淆linux下的程序，就像我们常用的gcc那样。若想使用OLLVM来混淆iOS程序，还需将bin目录下的工具链整合进Xcode插件中，具体步骤如下。</p>\n<p>配置Xcode–新建Obfuscator插件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ cd /Applications/Xcode.app/Contents/PlugIns/Xcode3Core.ideplugin/Contents/SharedSupport/Developer/Library/Xcode/Plug-ins/  </div><div class=\"line\">$ sudo cp -r Clang\\ LLVM\\ 1.0.xcplugin/ Obfuscator.xcplugin  </div><div class=\"line\">$ cd Obfuscator.xcplugin/Contents/  </div><div class=\"line\">$ sudo plutil -convert xml1 Info.plist  </div><div class=\"line\">$ sudo vim Info.plist</div></pre></td></tr></table></figure>\n<p>修改Info.plist中的对应内容：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;string&gt;com.apple.compilers.clang&lt;/string&gt; -&gt; &lt;string&gt;com.apple.compilers.obfuscator&lt;/string&gt;  </div><div class=\"line\">&lt;string&gt;Clang LLVM 1.0 Compiler Xcode Plug-in&lt;/string&gt; -&gt; &lt;string&gt;Obfuscator Xcode Plug-in&lt;/string&gt;</div></pre></td></tr></table></figure>\n<p>修改Obfuscator.xcspec文件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ sudo plutil -convert binary1 Info.plist  </div><div class=\"line\">$ cd Resources/  </div><div class=\"line\">$ sudo mv Clang\\ LLVM\\ 1.0.xcspec Obfuscator.xcspec  </div><div class=\"line\">$ sudo vim Obfuscator.xcspec</div></pre></td></tr></table></figure>\n<p>修改ExecPath的地址为当前build/bin的地址(!重点)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">Identifier = &quot;com.apple.compilers.llvm.clang.1_0&quot;; -&gt; Identifier = &quot;com.apple.compilers.llvm.obfuscator.4_0&quot;;  </div><div class=\"line\">Name = &quot;Apple LLVM 8.0&quot;; -&gt; Name = &quot;Obfuscator 4.0&quot;;  </div><div class=\"line\">Description = &quot;Apple LLVM 8.0 compiler&quot;; -&gt; Description = &quot;Obfuscator 4.0&quot;;  </div><div class=\"line\">Vendor = Apple; -&gt; Vendor = HEIG-VD;  </div><div class=\"line\">Version = &quot;7.0&quot;; -&gt; Version = &quot;4.0&quot;;  </div><div class=\"line\">ExecPath = &quot;clang&quot;; -&gt; ExecPath = &quot;/path/to/obfuscator_bin/clang&quot;;</div></pre></td></tr></table></figure>\n<p>修改 Obfuscator 4.0 Strings</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ cd English.lproj/  </div><div class=\"line\">$ sudo mv Apple\\ LLVM\\ 8.0.strings &quot;Obfuscator 4.0.strings&quot;  </div><div class=\"line\">$ sudo plutil -convert xml1 Obfuscator\\ 4.0.strings  </div><div class=\"line\">$ sudo vim Obfuscator\\ 4.0.strings</div></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">&quot;Description&quot; = &quot;Apple LLVM 8.0 Compiler&quot;; -&gt; &quot;Description&quot; = &quot;Obfuscator 4.0&quot;;  </div><div class=\"line\">&quot;Name&quot; = &quot;Apple LLVM 8.0&quot;; -&gt; &quot;Name&quot; = &quot;Obfuscator 4.0&quot;;  </div><div class=\"line\">&quot;Vendor&quot; = &quot;Apple&quot;; -&gt; &quot;Vendor&quot; = &quot;HEIG-VD&quot;;  </div><div class=\"line\">&quot;Version&quot; = &quot;8.0&quot;; -&gt; &quot;Version&quot; = &quot;4.0&quot;;</div></pre></td></tr></table></figure>\n<p><code>sudo plutil -convert binary1 Obfuscator\\ 4.0.strings</code>  </p>\n<p>现在，你可以打开Xcode在项目配置里来选择新的编译器，并且可以在C Flags或C++ Flags下添加混淆标签。</p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1944396-a27167d3a47b3bc7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"选择编译器\"><br><img src=\"http://upload-images.jianshu.io/upload_images/1944396-76e1b58511f4a559.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"添加混淆标签\"></p>\n<p>这样配置完成后，就可以编译项目生成混淆后的程序。</p>\n<h4 id=\"ollvm混淆使用\"><a href=\"#ollvm混淆使用\" class=\"headerlink\" title=\"ollvm混淆使用\"></a>ollvm混淆使用</h4><p>接下来使用以下demo介绍混淆功能的具体使用。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\">int main()&#123;  </div><div class=\"line\">    int a = 1;  </div><div class=\"line\">    int b = 0;  </div><div class=\"line\">    int c = 0;  </div><div class=\"line\">    if(a &gt; b)&#123;  </div><div class=\"line\">        a = 100;    </div><div class=\"line\">        b = 50;    </div><div class=\"line\">        c = a - b;    </div><div class=\"line\">        int d = a + b;    </div><div class=\"line\">        int e = a &amp; b;    </div><div class=\"line\">        int f = a ^ b;    </div><div class=\"line\">        printf(&quot;c = %d\\n&quot;,c);    </div><div class=\"line\">        printf(&quot;d = %d\\n&quot;,d);    </div><div class=\"line\">        printf(&quot;e = %d\\n&quot;,e);    </div><div class=\"line\">        printf(&quot;f = %d\\n&quot;,f);    </div><div class=\"line\">        printf(&quot;a &gt; b\\n&quot;);    </div><div class=\"line\">    &#125;else&#123;  </div><div class=\"line\">        printf(&quot;a &lt; b\\n&quot;);    </div><div class=\"line\">    &#125;  </div><div class=\"line\">    return 0;  </div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>OLLVM默认支持-fla -sub -bcf 三个混淆参数，这三个参数可以单独使用，也可以配合着使用。-fla 参数表示使用控制流平展（Control Flow Flattening）模式， -sub 参数表示使用指令替换（Instructions Substitution）模式， -bcf 参数表示使用控制流伪造（Bogus Control Flow）模式。</p>\n<h5 id=\"Instructions-Substitution\"><a href=\"#Instructions-Substitution\" class=\"headerlink\" title=\"Instructions Substitution\"></a>Instructions Substitution</h5><p>指令替换模式主要是将正常的运算操作（+，-，&amp;，|等）替换成功能相等但表述更复杂的形式。比如，对于表达式 a = b + c，它的等价式可以有 a = – ( -b – c), a = b – (-c) 或 a = -(-b) + c 等，原表达式可以替换成任意相等式，或者通过随机数在多个相等式中做选择。SUB模式目前只支持整数运算操作，支持 + , – , &amp; , | 和 ^ 操作，还是比较局限的。编译时，使用 -mllvm -sub 参数即可。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">-mllvm -sub: 启用instructions substitution  </div><div class=\"line\">-mllvm -sub_loop=3: 对每个函数混淆3次，默认1词</div></pre></td></tr></table></figure>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1944396-d3ef62eb9e13ae93.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"><br><img src=\"http://upload-images.jianshu.io/upload_images/1944396-a8aff8dc34d9a432.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"></p>\n<h5 id=\"Control-Flow-Flattening\"><a href=\"#Control-Flow-Flattening\" class=\"headerlink\" title=\"Control Flow Flattening\"></a>Control Flow Flattening</h5><p>控制流平展模式可以完全改变程序原本的控制流图。如下示例代码是简单的if-else分支语句，正常编译后其控制流图在IDA中下图所示，是正常的if-else分支，使用 -mllvm -fla参数混淆后，在IDA中显示的控制流图如下：<br><img src=\"http://upload-images.jianshu.io/upload_images/1944396-4a84eba4712effb8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"><br><img src=\"http://upload-images.jianshu.io/upload_images/1944396-47b61ea46b1eee67.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"></p>\n<p>经FLA模式混淆后，程序的执行流程已经被打乱，出现许多代码分支。通过仔细对比程序混淆前后，可以发现上图着色区域是相对应的，也就是说，FLA模式只去更改代码分支，而不会对单个代码块做处理。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">-mllvm -fla: 启用control flow flattening</div><div class=\"line\">-mllvm -split: 启用block切分，提升平展程度</div><div class=\"line\">-mllvm -split_num=3: 对每个block混淆3次，默认1词</div></pre></td></tr></table></figure>\n<h5 id=\"Bogus-Control-Flow\"><a href=\"#Bogus-Control-Flow\" class=\"headerlink\" title=\"Bogus Control Flow\"></a>Bogus Control Flow</h5><p>控制流伪造模式也是对程序的控制流做操作，不同的是，BCF模式会在原代码块的前后随机插入新的代码块，新插入的代码块不是确定的，然后新代码块再通过条件判断跳转到原代码块中。更要命地是，原代码块可能会被克隆并插入随机的垃圾指令。这么多不确定性，就导致对同一份代码多次做BCF模式的混淆时，得到的是不同的混淆效果。可见，BCF混淆模式还是很强大的，不同于FLA那种较确定的混淆模式。使用BCF模式编译时配置参数 -mllvm -bcf即可，此外，BCF模式还支持其它几个参数，下面参数与-mllvm -bcf参数配合使用。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">-mllvm -bcf: 启用 bogus control flow</div><div class=\"line\">-mllvm -bcf_loop=3: 对一个函数混淆3次，默认1次</div><div class=\"line\">-mllvm -bcf_prob=40: 代码块被混淆的概率是40%，默认30%</div></pre></td></tr></table></figure></p>\n<p>如上图，下面两个着色的代码块就是有上面两个代码块克隆而来，而且其中被插入了一些垃圾指令，类似于这样：</p>\n<p>当然，上述介绍的三种混淆模式可以搭配使用，同时使用三个参数混淆后，原本简单的if-else分支代码将会变得异常复杂，这无疑给逆向分析增加巨大的难度。</p>\n<h5 id=\"Functions-annotations\"><a href=\"#Functions-annotations\" class=\"headerlink\" title=\"Functions annotations\"></a>Functions annotations</h5><p>有的时候，由于效率或其他原因的考虑，我们只想给指定的函数混淆或不混淆该函数，OLLVM也提供了对这一特性的支持，你只需要给对应的函数添加attributes即可。比如，想对函数foo()使用fla混淆，只需要给函数foo()增加fla属性即可。  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">int foo() __attribute((__annotate__((&quot;fla&quot;))));</div><div class=\"line\">int foo() &#123;</div><div class=\"line\">   return 2;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>你可以给函数添加一个或多个注释。如果你不想混淆某个函数，你可以使用否定标签。例如如果不想对func()函数使用bcf属性，那标记为“nobcf”即可。</p>\n<h4 id=\"错误处理\"><a href=\"#错误处理\" class=\"headerlink\" title=\"错误处理\"></a>错误处理</h4><p>1.编译时报错，提示信息如下：  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">clang-3.6: error: unknown argument: &apos;-gmodules&apos;</div><div class=\"line\">clang-3.6: error: unknown argument: &apos;-fembed-bitcode-marker&apos;</div><div class=\"line\">Command /Users/dream/ollvm/build/bin/clang failed with exit code 1</div></pre></td></tr></table></figure>\n<p>在Build Settings中搜索并修改：<br>-gmodules: Obfuscator 4.0 - Code Generation: Generate Debug Symbols: 原来yes，改成no<br>-fembed-bitcode-marker: Build Option: Enable Bitcode: 原来yes，改成no</p>\n<p>你可以在该<a href=\"\">git地址</a>下找到最新的插件和build编译器文件，该编译器所使用的Xcode版本是8.3.3。</p>\n","site":{"data":{}},"excerpt":"<h3 id=\"OLLVM简介\"><a href=\"#OLLVM简介\" class=\"headerlink\" title=\"OLLVM简介\"></a>OLLVM简介</h3><p><a href=\"https://github.com/obfuscator-llvm/obfuscator\" target=\"_blank\" rel=\"external\">OLLVM（Obfuscator-LLVM）</a>是瑞士西北应用科技大学安全实验室于2010年6月份发起的一个项目，该项目旨在提供一套开源的针对LLVM的代码混淆工具，以增加对逆向工程的难度。后期转向商业项目<a href=\"http://link.zhihu.com/?target=https%3A//strong.codes/\" target=\"_blank\" rel=\"external\">strong.protect</a>。目前，OLLVM已经支持LLVM-4.0版本。</p>\n<p>LLVM是一个优秀的编译器框架，它也采用经典的三段式设计。前端可以使用不同的编译工具对代码文件做词法分析以形成抽象语法树AST，然后将分析好的代码转换成LLVM的中间表示IR（intermediate representation）；中间部分的优化器只对中间表示IR操作，通过一系列的Pass对IR做优化；后端负责将优化好的IR解释成对应平台的机器码。LLVM的优点在于，中间表示IR代码编写良好，而且不同的前端语言最终都转换成同一种的IR。</p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1944396-3ce371d488ad67ac.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"></p>\n<p>LLVM IR 是LLVM的中间表示，优化器就是对IR进行操作的，具体的优化操作由一些列的Pass来完成，当前端生成初级IR后，Pass会依次对IR进行处理，最终生成后端可用的IR。下图可以说明这个过程：<br><img src=\"http://upload-images.jianshu.io/upload_images/1944396-20cd55c8ee11762d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"></p>\n<p>OLLVM的混淆操作就是在中间表示IR层，通过编写Pass来混淆IR，然后后端依据IR来生成的目标代码也就被混淆了。得益于LLVM的设计，OLLVM适用LLVM支持的所有语言（C,C++,Objective-C,Ada,Fortran）和目标平台（x86,x86-64,PowerPC,PowerPC-64, ARM, Thumb, SPARC, Alpha, CellSPU, MIPS, MSP430, SystemZ, 和 XCore）<br>","more":"</p>\n<h4 id=\"OLLVM-iOS编译环境搭建\"><a href=\"#OLLVM-iOS编译环境搭建\" class=\"headerlink\" title=\"OLLVM iOS编译环境搭建\"></a>OLLVM iOS编译环境搭建</h4><p>以下，介绍OLLVM iOS环境的插件创建过程。<br>首先下载源码，编译OLLVM混淆器，这里采用LLVM的版本是4.0。下载编译过程如下：</p>\n <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ git clone -b llvm-4.0 https://github.com/obfuscator-llvm/obfuscator.git  </div><div class=\"line\">$ mkdir build  </div><div class=\"line\">$ cd build  </div><div class=\"line\">$ cmake -DCMAKE_BUILD_TYPE=Release ../obfuscator/  </div><div class=\"line\">$ make -j7</div></pre></td></tr></table></figure>\n<p>下载的源码里已经包含了LLVM和Clang，编译完成后，编译好的二进制程序都存在在build/bin目录下。</p>\n<p>依据github上的wiki，bin目录下编译好的工具链可以直接用来编译混淆linux下的程序，就像我们常用的gcc那样。若想使用OLLVM来混淆iOS程序，还需将bin目录下的工具链整合进Xcode插件中，具体步骤如下。</p>\n<p>配置Xcode–新建Obfuscator插件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ cd /Applications/Xcode.app/Contents/PlugIns/Xcode3Core.ideplugin/Contents/SharedSupport/Developer/Library/Xcode/Plug-ins/  </div><div class=\"line\">$ sudo cp -r Clang\\ LLVM\\ 1.0.xcplugin/ Obfuscator.xcplugin  </div><div class=\"line\">$ cd Obfuscator.xcplugin/Contents/  </div><div class=\"line\">$ sudo plutil -convert xml1 Info.plist  </div><div class=\"line\">$ sudo vim Info.plist</div></pre></td></tr></table></figure>\n<p>修改Info.plist中的对应内容：</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">&lt;string&gt;com.apple.compilers.clang&lt;/string&gt; -&gt; &lt;string&gt;com.apple.compilers.obfuscator&lt;/string&gt;  </div><div class=\"line\">&lt;string&gt;Clang LLVM 1.0 Compiler Xcode Plug-in&lt;/string&gt; -&gt; &lt;string&gt;Obfuscator Xcode Plug-in&lt;/string&gt;</div></pre></td></tr></table></figure>\n<p>修改Obfuscator.xcspec文件</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ sudo plutil -convert binary1 Info.plist  </div><div class=\"line\">$ cd Resources/  </div><div class=\"line\">$ sudo mv Clang\\ LLVM\\ 1.0.xcspec Obfuscator.xcspec  </div><div class=\"line\">$ sudo vim Obfuscator.xcspec</div></pre></td></tr></table></figure>\n<p>修改ExecPath的地址为当前build/bin的地址(!重点)</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">Identifier = &quot;com.apple.compilers.llvm.clang.1_0&quot;; -&gt; Identifier = &quot;com.apple.compilers.llvm.obfuscator.4_0&quot;;  </div><div class=\"line\">Name = &quot;Apple LLVM 8.0&quot;; -&gt; Name = &quot;Obfuscator 4.0&quot;;  </div><div class=\"line\">Description = &quot;Apple LLVM 8.0 compiler&quot;; -&gt; Description = &quot;Obfuscator 4.0&quot;;  </div><div class=\"line\">Vendor = Apple; -&gt; Vendor = HEIG-VD;  </div><div class=\"line\">Version = &quot;7.0&quot;; -&gt; Version = &quot;4.0&quot;;  </div><div class=\"line\">ExecPath = &quot;clang&quot;; -&gt; ExecPath = &quot;/path/to/obfuscator_bin/clang&quot;;</div></pre></td></tr></table></figure>\n<p>修改 Obfuscator 4.0 Strings</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ cd English.lproj/  </div><div class=\"line\">$ sudo mv Apple\\ LLVM\\ 8.0.strings &quot;Obfuscator 4.0.strings&quot;  </div><div class=\"line\">$ sudo plutil -convert xml1 Obfuscator\\ 4.0.strings  </div><div class=\"line\">$ sudo vim Obfuscator\\ 4.0.strings</div></pre></td></tr></table></figure>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">&quot;Description&quot; = &quot;Apple LLVM 8.0 Compiler&quot;; -&gt; &quot;Description&quot; = &quot;Obfuscator 4.0&quot;;  </div><div class=\"line\">&quot;Name&quot; = &quot;Apple LLVM 8.0&quot;; -&gt; &quot;Name&quot; = &quot;Obfuscator 4.0&quot;;  </div><div class=\"line\">&quot;Vendor&quot; = &quot;Apple&quot;; -&gt; &quot;Vendor&quot; = &quot;HEIG-VD&quot;;  </div><div class=\"line\">&quot;Version&quot; = &quot;8.0&quot;; -&gt; &quot;Version&quot; = &quot;4.0&quot;;</div></pre></td></tr></table></figure>\n<p><code>sudo plutil -convert binary1 Obfuscator\\ 4.0.strings</code>  </p>\n<p>现在，你可以打开Xcode在项目配置里来选择新的编译器，并且可以在C Flags或C++ Flags下添加混淆标签。</p>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1944396-a27167d3a47b3bc7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"选择编译器\"><br><img src=\"http://upload-images.jianshu.io/upload_images/1944396-76e1b58511f4a559.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"添加混淆标签\"></p>\n<p>这样配置完成后，就可以编译项目生成混淆后的程序。</p>\n<h4 id=\"ollvm混淆使用\"><a href=\"#ollvm混淆使用\" class=\"headerlink\" title=\"ollvm混淆使用\"></a>ollvm混淆使用</h4><p>接下来使用以下demo介绍混淆功能的具体使用。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div></pre></td><td class=\"code\"><pre><div class=\"line\">int main()&#123;  </div><div class=\"line\">    int a = 1;  </div><div class=\"line\">    int b = 0;  </div><div class=\"line\">    int c = 0;  </div><div class=\"line\">    if(a &gt; b)&#123;  </div><div class=\"line\">        a = 100;    </div><div class=\"line\">        b = 50;    </div><div class=\"line\">        c = a - b;    </div><div class=\"line\">        int d = a + b;    </div><div class=\"line\">        int e = a &amp; b;    </div><div class=\"line\">        int f = a ^ b;    </div><div class=\"line\">        printf(&quot;c = %d\\n&quot;,c);    </div><div class=\"line\">        printf(&quot;d = %d\\n&quot;,d);    </div><div class=\"line\">        printf(&quot;e = %d\\n&quot;,e);    </div><div class=\"line\">        printf(&quot;f = %d\\n&quot;,f);    </div><div class=\"line\">        printf(&quot;a &gt; b\\n&quot;);    </div><div class=\"line\">    &#125;else&#123;  </div><div class=\"line\">        printf(&quot;a &lt; b\\n&quot;);    </div><div class=\"line\">    &#125;  </div><div class=\"line\">    return 0;  </div><div class=\"line\">&#125;</div></pre></td></tr></table></figure></p>\n<p>OLLVM默认支持-fla -sub -bcf 三个混淆参数，这三个参数可以单独使用，也可以配合着使用。-fla 参数表示使用控制流平展（Control Flow Flattening）模式， -sub 参数表示使用指令替换（Instructions Substitution）模式， -bcf 参数表示使用控制流伪造（Bogus Control Flow）模式。</p>\n<h5 id=\"Instructions-Substitution\"><a href=\"#Instructions-Substitution\" class=\"headerlink\" title=\"Instructions Substitution\"></a>Instructions Substitution</h5><p>指令替换模式主要是将正常的运算操作（+，-，&amp;，|等）替换成功能相等但表述更复杂的形式。比如，对于表达式 a = b + c，它的等价式可以有 a = – ( -b – c), a = b – (-c) 或 a = -(-b) + c 等，原表达式可以替换成任意相等式，或者通过随机数在多个相等式中做选择。SUB模式目前只支持整数运算操作，支持 + , – , &amp; , | 和 ^ 操作，还是比较局限的。编译时，使用 -mllvm -sub 参数即可。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">-mllvm -sub: 启用instructions substitution  </div><div class=\"line\">-mllvm -sub_loop=3: 对每个函数混淆3次，默认1词</div></pre></td></tr></table></figure>\n<p><img src=\"http://upload-images.jianshu.io/upload_images/1944396-d3ef62eb9e13ae93.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"><br><img src=\"http://upload-images.jianshu.io/upload_images/1944396-a8aff8dc34d9a432.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"></p>\n<h5 id=\"Control-Flow-Flattening\"><a href=\"#Control-Flow-Flattening\" class=\"headerlink\" title=\"Control Flow Flattening\"></a>Control Flow Flattening</h5><p>控制流平展模式可以完全改变程序原本的控制流图。如下示例代码是简单的if-else分支语句，正常编译后其控制流图在IDA中下图所示，是正常的if-else分支，使用 -mllvm -fla参数混淆后，在IDA中显示的控制流图如下：<br><img src=\"http://upload-images.jianshu.io/upload_images/1944396-4a84eba4712effb8.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"><br><img src=\"http://upload-images.jianshu.io/upload_images/1944396-47b61ea46b1eee67.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240\" alt=\"\"></p>\n<p>经FLA模式混淆后，程序的执行流程已经被打乱，出现许多代码分支。通过仔细对比程序混淆前后，可以发现上图着色区域是相对应的，也就是说，FLA模式只去更改代码分支，而不会对单个代码块做处理。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">-mllvm -fla: 启用control flow flattening</div><div class=\"line\">-mllvm -split: 启用block切分，提升平展程度</div><div class=\"line\">-mllvm -split_num=3: 对每个block混淆3次，默认1词</div></pre></td></tr></table></figure>\n<h5 id=\"Bogus-Control-Flow\"><a href=\"#Bogus-Control-Flow\" class=\"headerlink\" title=\"Bogus Control Flow\"></a>Bogus Control Flow</h5><p>控制流伪造模式也是对程序的控制流做操作，不同的是，BCF模式会在原代码块的前后随机插入新的代码块，新插入的代码块不是确定的，然后新代码块再通过条件判断跳转到原代码块中。更要命地是，原代码块可能会被克隆并插入随机的垃圾指令。这么多不确定性，就导致对同一份代码多次做BCF模式的混淆时，得到的是不同的混淆效果。可见，BCF混淆模式还是很强大的，不同于FLA那种较确定的混淆模式。使用BCF模式编译时配置参数 -mllvm -bcf即可，此外，BCF模式还支持其它几个参数，下面参数与-mllvm -bcf参数配合使用。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">-mllvm -bcf: 启用 bogus control flow</div><div class=\"line\">-mllvm -bcf_loop=3: 对一个函数混淆3次，默认1次</div><div class=\"line\">-mllvm -bcf_prob=40: 代码块被混淆的概率是40%，默认30%</div></pre></td></tr></table></figure></p>\n<p>如上图，下面两个着色的代码块就是有上面两个代码块克隆而来，而且其中被插入了一些垃圾指令，类似于这样：</p>\n<p>当然，上述介绍的三种混淆模式可以搭配使用，同时使用三个参数混淆后，原本简单的if-else分支代码将会变得异常复杂，这无疑给逆向分析增加巨大的难度。</p>\n<h5 id=\"Functions-annotations\"><a href=\"#Functions-annotations\" class=\"headerlink\" title=\"Functions annotations\"></a>Functions annotations</h5><p>有的时候，由于效率或其他原因的考虑，我们只想给指定的函数混淆或不混淆该函数，OLLVM也提供了对这一特性的支持，你只需要给对应的函数添加attributes即可。比如，想对函数foo()使用fla混淆，只需要给函数foo()增加fla属性即可。  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">int foo() __attribute((__annotate__((&quot;fla&quot;))));</div><div class=\"line\">int foo() &#123;</div><div class=\"line\">   return 2;</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p>你可以给函数添加一个或多个注释。如果你不想混淆某个函数，你可以使用否定标签。例如如果不想对func()函数使用bcf属性，那标记为“nobcf”即可。</p>\n<h4 id=\"错误处理\"><a href=\"#错误处理\" class=\"headerlink\" title=\"错误处理\"></a>错误处理</h4><p>1.编译时报错，提示信息如下：  </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">clang-3.6: error: unknown argument: &apos;-gmodules&apos;</div><div class=\"line\">clang-3.6: error: unknown argument: &apos;-fembed-bitcode-marker&apos;</div><div class=\"line\">Command /Users/dream/ollvm/build/bin/clang failed with exit code 1</div></pre></td></tr></table></figure>\n<p>在Build Settings中搜索并修改：<br>-gmodules: Obfuscator 4.0 - Code Generation: Generate Debug Symbols: 原来yes，改成no<br>-fembed-bitcode-marker: Build Option: Enable Bitcode: 原来yes，改成no</p>\n<p>你可以在该<a href=\"\">git地址</a>下找到最新的插件和build编译器文件，该编译器所使用的Xcode版本是8.3.3。</p>"},{"title":"iOS混淆-ollvm中添加对String的混淆","date":"2017-09-18T07:58:09.000Z","_content":"\n之前[研究ollvm](http://fighting300.github.io/2017/09/07/ollvm-in-iOS/)的时候，发现开源的ollvm库中没有对字符串混淆的部分，但是很多APP中都可能会有一些需要加密的字符串。机缘巧合发现上海交大的GoSSIP小组开源了他们设计的基于LLVM4.0的[混淆框架](https://github.com/GoSSIP-SJTU/Armariris),功能包含常量字符串混淆以及ollvm原有的一些功能。[该页面](https://zhuanlan.zhihu.com/p/27617441)有关于他们项目的简介👍。      \n简单分析发现字符串混淆的部分主要由字符串加密的Pass完成，之后我们考虑把字符串混淆的功能加入ollvm中，所以本文简单介绍下如何将字符串加密的Pass继承到ollvm中。Pass其实可以简单的理解为LLVM优化／转换工作的一个最小单元，可以把所有的混淆工作都是由一个一个Pass组成的，想要做具体的了解，可以看下以下[专栏的文章](http://www.nagain.com/activity/article/14/)。\n\n#### Pass集成\n\n首先提取字符串加密文件对应pass文件，该文件所在目录为lib/Transform/Obfuscation。\n![pass文件目录](http://ojca2gwha.bkt.clouddn.com/ollvm-string-cpp.png)\n\n<!--more-->\n提取后放在ollvm相同目录下，并把头文件也复制到对应目录下，该文件所在目录为include/llvm/Transform/Obfuscation。  \n![头文件目录](http://ojca2gwha.bkt.clouddn.com/ollvm-string-h.png)\n\n修改lib/Transform/Obfuscation目录下的CMakeLists.txt文件，将StringObfuscation.cpp添加到编译库中。然后修改Transform/IPO下的PassManagerBuilder.cpp文件，添加字符串加密的编译代码。具体代码如下:\n\n##### 1.添加引用\n`#include \"llvm/Transforms/Obfuscation/StringObfuscation.h\"`\n\n##### 2.插入函数声明，即编译时的编译参数`-mllvm -sobf`\n\n```\nstatic cl::opt<std::string> Seed(\"seed\", cl::init(\"\"),\n                           cl::desc(\"seed for the random\"));\n\nstatic cl::opt<bool> StringObf(\"sobf\", cl::init(false),\n                           cl::desc(\"Enable the string obfuscation\"));\n```\n\n##### 3.在PassManagerBuilder()构造函数中添加随机数因子的初始化  \n\n```\n    if(!Seed.empty()) {\n      llvm::cryptoutils->prng_seed(Seed.c_str());\n    }\n```\n\n![插入随机因子初始化](http://ojca2gwha.bkt.clouddn.com/ollvm-string-seed.png)\n\n##### 4.添加pss到 PassManagerBuilder::populateModulePassManager中\n\n```\n    MPM.add(createStringObfuscation(StringObf));\n```\n\n![添加Pass](http://ojca2gwha.bkt.clouddn.com/ollvm-string-use.png)\n\n##### 5.在主路径下运行编译命令  \n\n```\n  mkdir build\n  cd build\n  cmake -DCMAKE_BUILD_TYPE=Release ../obfuscator/   // 代码所在路径\n  make -j7\n```\n即可生成build最终文件，用于项目编译。我在github上也新建了一个添加了字符串混淆功能的[ollvm版本](https://github.com/fighting300/obfuscator)，想要直接使用的小伙伴可以下载使用。\n\n##### 6.使用效果  \n在OC代码中添加了简单的字符串、混淆后的效果如下图：  \n\n![字符串混淆前](http://ojca2gwha.bkt.clouddn.com/ollvm-string-before.png)\n\n![字符串混淆后](http://ojca2gwha.bkt.clouddn.com/ollvm-string-after.png)\n\n\n#### 问题及解决方案  \n\n编译成功后，则可按照[上篇文章](http://fighting300.github.io/2017/09/07/ollvm-in-iOS/)所述，在XCode中编译项目。   \n\n##### 1. bcf不支持Invoke指令\n在实际使用过程中，发现ollvm目前不支持@synchronized、try...catch等少数语法，然后导致bcf报错。[这些语法](https://llvm.org/docs/LangRef.html#invoke-instruction)会生成invoke指令，目前可以在bcf前过滤包含InvokeInst的方法，具体代码可以参考[该Github地址](https://github.com/fighting300/obfuscator/commit/ae0e5acd873cd9a8c839a013a635422022fd0d6b)。\n\n##### 2.目前该字符串识别还有bug，即不会加密每个函数的第一个字符串。。。[该bug](https://qtfreet.com/?p=313)未经过验证。\n\n若有其他问题，可以联系，或者comment(翻墙才能评论哈。。。)\n\n##### 参考文档\n1. http://bobao.360.cn/learning/detail/4069.html\n2. http://www.nagain.com/activity/article/14/\n","source":"_posts/ollvm-with-StringObfuscate.md","raw":"---\ntitle: iOS混淆-ollvm中添加对String的混淆\ndate: 2017-09-18 15:58:09\ntags: 安全\ncategories: LLVM\n---\n\n之前[研究ollvm](http://fighting300.github.io/2017/09/07/ollvm-in-iOS/)的时候，发现开源的ollvm库中没有对字符串混淆的部分，但是很多APP中都可能会有一些需要加密的字符串。机缘巧合发现上海交大的GoSSIP小组开源了他们设计的基于LLVM4.0的[混淆框架](https://github.com/GoSSIP-SJTU/Armariris),功能包含常量字符串混淆以及ollvm原有的一些功能。[该页面](https://zhuanlan.zhihu.com/p/27617441)有关于他们项目的简介👍。      \n简单分析发现字符串混淆的部分主要由字符串加密的Pass完成，之后我们考虑把字符串混淆的功能加入ollvm中，所以本文简单介绍下如何将字符串加密的Pass继承到ollvm中。Pass其实可以简单的理解为LLVM优化／转换工作的一个最小单元，可以把所有的混淆工作都是由一个一个Pass组成的，想要做具体的了解，可以看下以下[专栏的文章](http://www.nagain.com/activity/article/14/)。\n\n#### Pass集成\n\n首先提取字符串加密文件对应pass文件，该文件所在目录为lib/Transform/Obfuscation。\n![pass文件目录](http://ojca2gwha.bkt.clouddn.com/ollvm-string-cpp.png)\n\n<!--more-->\n提取后放在ollvm相同目录下，并把头文件也复制到对应目录下，该文件所在目录为include/llvm/Transform/Obfuscation。  \n![头文件目录](http://ojca2gwha.bkt.clouddn.com/ollvm-string-h.png)\n\n修改lib/Transform/Obfuscation目录下的CMakeLists.txt文件，将StringObfuscation.cpp添加到编译库中。然后修改Transform/IPO下的PassManagerBuilder.cpp文件，添加字符串加密的编译代码。具体代码如下:\n\n##### 1.添加引用\n`#include \"llvm/Transforms/Obfuscation/StringObfuscation.h\"`\n\n##### 2.插入函数声明，即编译时的编译参数`-mllvm -sobf`\n\n```\nstatic cl::opt<std::string> Seed(\"seed\", cl::init(\"\"),\n                           cl::desc(\"seed for the random\"));\n\nstatic cl::opt<bool> StringObf(\"sobf\", cl::init(false),\n                           cl::desc(\"Enable the string obfuscation\"));\n```\n\n##### 3.在PassManagerBuilder()构造函数中添加随机数因子的初始化  \n\n```\n    if(!Seed.empty()) {\n      llvm::cryptoutils->prng_seed(Seed.c_str());\n    }\n```\n\n![插入随机因子初始化](http://ojca2gwha.bkt.clouddn.com/ollvm-string-seed.png)\n\n##### 4.添加pss到 PassManagerBuilder::populateModulePassManager中\n\n```\n    MPM.add(createStringObfuscation(StringObf));\n```\n\n![添加Pass](http://ojca2gwha.bkt.clouddn.com/ollvm-string-use.png)\n\n##### 5.在主路径下运行编译命令  \n\n```\n  mkdir build\n  cd build\n  cmake -DCMAKE_BUILD_TYPE=Release ../obfuscator/   // 代码所在路径\n  make -j7\n```\n即可生成build最终文件，用于项目编译。我在github上也新建了一个添加了字符串混淆功能的[ollvm版本](https://github.com/fighting300/obfuscator)，想要直接使用的小伙伴可以下载使用。\n\n##### 6.使用效果  \n在OC代码中添加了简单的字符串、混淆后的效果如下图：  \n\n![字符串混淆前](http://ojca2gwha.bkt.clouddn.com/ollvm-string-before.png)\n\n![字符串混淆后](http://ojca2gwha.bkt.clouddn.com/ollvm-string-after.png)\n\n\n#### 问题及解决方案  \n\n编译成功后，则可按照[上篇文章](http://fighting300.github.io/2017/09/07/ollvm-in-iOS/)所述，在XCode中编译项目。   \n\n##### 1. bcf不支持Invoke指令\n在实际使用过程中，发现ollvm目前不支持@synchronized、try...catch等少数语法，然后导致bcf报错。[这些语法](https://llvm.org/docs/LangRef.html#invoke-instruction)会生成invoke指令，目前可以在bcf前过滤包含InvokeInst的方法，具体代码可以参考[该Github地址](https://github.com/fighting300/obfuscator/commit/ae0e5acd873cd9a8c839a013a635422022fd0d6b)。\n\n##### 2.目前该字符串识别还有bug，即不会加密每个函数的第一个字符串。。。[该bug](https://qtfreet.com/?p=313)未经过验证。\n\n若有其他问题，可以联系，或者comment(翻墙才能评论哈。。。)\n\n##### 参考文档\n1. http://bobao.360.cn/learning/detail/4069.html\n2. http://www.nagain.com/activity/article/14/\n","slug":"ollvm-with-StringObfuscate","published":1,"updated":"2017-09-25T12:08:35.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cj81l5465000uwluvduw0esdn","content":"<p>之前<a href=\"http://fighting300.github.io/2017/09/07/ollvm-in-iOS/\" target=\"_blank\" rel=\"external\">研究ollvm</a>的时候，发现开源的ollvm库中没有对字符串混淆的部分，但是很多APP中都可能会有一些需要加密的字符串。机缘巧合发现上海交大的GoSSIP小组开源了他们设计的基于LLVM4.0的<a href=\"https://github.com/GoSSIP-SJTU/Armariris\" target=\"_blank\" rel=\"external\">混淆框架</a>,功能包含常量字符串混淆以及ollvm原有的一些功能。<a href=\"https://zhuanlan.zhihu.com/p/27617441\" target=\"_blank\" rel=\"external\">该页面</a>有关于他们项目的简介👍。<br>简单分析发现字符串混淆的部分主要由字符串加密的Pass完成，之后我们考虑把字符串混淆的功能加入ollvm中，所以本文简单介绍下如何将字符串加密的Pass继承到ollvm中。Pass其实可以简单的理解为LLVM优化／转换工作的一个最小单元，可以把所有的混淆工作都是由一个一个Pass组成的，想要做具体的了解，可以看下以下<a href=\"http://www.nagain.com/activity/article/14/\" target=\"_blank\" rel=\"external\">专栏的文章</a>。</p>\n<h4 id=\"Pass集成\"><a href=\"#Pass集成\" class=\"headerlink\" title=\"Pass集成\"></a>Pass集成</h4><p>首先提取字符串加密文件对应pass文件，该文件所在目录为lib/Transform/Obfuscation。<br><img src=\"http://ojca2gwha.bkt.clouddn.com/ollvm-string-cpp.png\" alt=\"pass文件目录\"></p>\n<a id=\"more\"></a>\n<p>提取后放在ollvm相同目录下，并把头文件也复制到对应目录下，该文件所在目录为include/llvm/Transform/Obfuscation。<br><img src=\"http://ojca2gwha.bkt.clouddn.com/ollvm-string-h.png\" alt=\"头文件目录\"></p>\n<p>修改lib/Transform/Obfuscation目录下的CMakeLists.txt文件，将StringObfuscation.cpp添加到编译库中。然后修改Transform/IPO下的PassManagerBuilder.cpp文件，添加字符串加密的编译代码。具体代码如下:</p>\n<h5 id=\"1-添加引用\"><a href=\"#1-添加引用\" class=\"headerlink\" title=\"1.添加引用\"></a>1.添加引用</h5><p><code>#include &quot;llvm/Transforms/Obfuscation/StringObfuscation.h&quot;</code></p>\n<h5 id=\"2-插入函数声明，即编译时的编译参数-mllvm-sobf\"><a href=\"#2-插入函数声明，即编译时的编译参数-mllvm-sobf\" class=\"headerlink\" title=\"2.插入函数声明，即编译时的编译参数-mllvm -sobf\"></a>2.插入函数声明，即编译时的编译参数<code>-mllvm -sobf</code></h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">static cl::opt&lt;std::string&gt; Seed(&quot;seed&quot;, cl::init(&quot;&quot;),</div><div class=\"line\">                           cl::desc(&quot;seed for the random&quot;));</div><div class=\"line\"></div><div class=\"line\">static cl::opt&lt;bool&gt; StringObf(&quot;sobf&quot;, cl::init(false),</div><div class=\"line\">                           cl::desc(&quot;Enable the string obfuscation&quot;));</div></pre></td></tr></table></figure>\n<h5 id=\"3-在PassManagerBuilder-构造函数中添加随机数因子的初始化\"><a href=\"#3-在PassManagerBuilder-构造函数中添加随机数因子的初始化\" class=\"headerlink\" title=\"3.在PassManagerBuilder()构造函数中添加随机数因子的初始化\"></a>3.在PassManagerBuilder()构造函数中添加随机数因子的初始化</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">if(!Seed.empty()) &#123;</div><div class=\"line\">  llvm::cryptoutils-&gt;prng_seed(Seed.c_str());</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/ollvm-string-seed.png\" alt=\"插入随机因子初始化\"></p>\n<h5 id=\"4-添加pss到-PassManagerBuilder-populateModulePassManager中\"><a href=\"#4-添加pss到-PassManagerBuilder-populateModulePassManager中\" class=\"headerlink\" title=\"4.添加pss到 PassManagerBuilder::populateModulePassManager中\"></a>4.添加pss到 PassManagerBuilder::populateModulePassManager中</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">MPM.add(createStringObfuscation(StringObf));</div></pre></td></tr></table></figure>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/ollvm-string-use.png\" alt=\"添加Pass\"></p>\n<h5 id=\"5-在主路径下运行编译命令\"><a href=\"#5-在主路径下运行编译命令\" class=\"headerlink\" title=\"5.在主路径下运行编译命令\"></a>5.在主路径下运行编译命令</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">mkdir build</div><div class=\"line\">cd build</div><div class=\"line\">cmake -DCMAKE_BUILD_TYPE=Release ../obfuscator/   // 代码所在路径</div><div class=\"line\">make -j7</div></pre></td></tr></table></figure>\n<p>即可生成build最终文件，用于项目编译。我在github上也新建了一个添加了字符串混淆功能的<a href=\"https://github.com/fighting300/obfuscator\" target=\"_blank\" rel=\"external\">ollvm版本</a>，想要直接使用的小伙伴可以下载使用。</p>\n<h5 id=\"6-使用效果\"><a href=\"#6-使用效果\" class=\"headerlink\" title=\"6.使用效果\"></a>6.使用效果</h5><p>在OC代码中添加了简单的字符串、混淆后的效果如下图：  </p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/ollvm-string-before.png\" alt=\"字符串混淆前\"></p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/ollvm-string-after.png\" alt=\"字符串混淆后\"></p>\n<h4 id=\"问题及解决方案\"><a href=\"#问题及解决方案\" class=\"headerlink\" title=\"问题及解决方案\"></a>问题及解决方案</h4><p>编译成功后，则可按照<a href=\"http://fighting300.github.io/2017/09/07/ollvm-in-iOS/\" target=\"_blank\" rel=\"external\">上篇文章</a>所述，在XCode中编译项目。   </p>\n<h5 id=\"1-bcf不支持Invoke指令\"><a href=\"#1-bcf不支持Invoke指令\" class=\"headerlink\" title=\"1. bcf不支持Invoke指令\"></a>1. bcf不支持Invoke指令</h5><p>在实际使用过程中，发现ollvm目前不支持@synchronized、try…catch等少数语法，然后导致bcf报错。<a href=\"https://llvm.org/docs/LangRef.html#invoke-instruction\" target=\"_blank\" rel=\"external\">这些语法</a>会生成invoke指令，目前可以在bcf前过滤包含InvokeInst的方法，具体代码可以参考<a href=\"https://github.com/fighting300/obfuscator/commit/ae0e5acd873cd9a8c839a013a635422022fd0d6b\" target=\"_blank\" rel=\"external\">该Github地址</a>。</p>\n<h5 id=\"2-目前该字符串识别还有bug，即不会加密每个函数的第一个字符串。。。该bug未经过验证。\"><a href=\"#2-目前该字符串识别还有bug，即不会加密每个函数的第一个字符串。。。该bug未经过验证。\" class=\"headerlink\" title=\"2.目前该字符串识别还有bug，即不会加密每个函数的第一个字符串。。。该bug未经过验证。\"></a>2.目前该字符串识别还有bug，即不会加密每个函数的第一个字符串。。。<a href=\"https://qtfreet.com/?p=313\" target=\"_blank\" rel=\"external\">该bug</a>未经过验证。</h5><p>若有其他问题，可以联系，或者comment(翻墙才能评论哈。。。)</p>\n<h5 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h5><ol>\n<li><a href=\"http://bobao.360.cn/learning/detail/4069.html\" target=\"_blank\" rel=\"external\">http://bobao.360.cn/learning/detail/4069.html</a></li>\n<li><a href=\"http://www.nagain.com/activity/article/14/\" target=\"_blank\" rel=\"external\">http://www.nagain.com/activity/article/14/</a></li>\n</ol>\n","site":{"data":{}},"excerpt":"<p>之前<a href=\"http://fighting300.github.io/2017/09/07/ollvm-in-iOS/\" target=\"_blank\" rel=\"external\">研究ollvm</a>的时候，发现开源的ollvm库中没有对字符串混淆的部分，但是很多APP中都可能会有一些需要加密的字符串。机缘巧合发现上海交大的GoSSIP小组开源了他们设计的基于LLVM4.0的<a href=\"https://github.com/GoSSIP-SJTU/Armariris\" target=\"_blank\" rel=\"external\">混淆框架</a>,功能包含常量字符串混淆以及ollvm原有的一些功能。<a href=\"https://zhuanlan.zhihu.com/p/27617441\" target=\"_blank\" rel=\"external\">该页面</a>有关于他们项目的简介👍。<br>简单分析发现字符串混淆的部分主要由字符串加密的Pass完成，之后我们考虑把字符串混淆的功能加入ollvm中，所以本文简单介绍下如何将字符串加密的Pass继承到ollvm中。Pass其实可以简单的理解为LLVM优化／转换工作的一个最小单元，可以把所有的混淆工作都是由一个一个Pass组成的，想要做具体的了解，可以看下以下<a href=\"http://www.nagain.com/activity/article/14/\" target=\"_blank\" rel=\"external\">专栏的文章</a>。</p>\n<h4 id=\"Pass集成\"><a href=\"#Pass集成\" class=\"headerlink\" title=\"Pass集成\"></a>Pass集成</h4><p>首先提取字符串加密文件对应pass文件，该文件所在目录为lib/Transform/Obfuscation。<br><img src=\"http://ojca2gwha.bkt.clouddn.com/ollvm-string-cpp.png\" alt=\"pass文件目录\"></p>","more":"<p>提取后放在ollvm相同目录下，并把头文件也复制到对应目录下，该文件所在目录为include/llvm/Transform/Obfuscation。<br><img src=\"http://ojca2gwha.bkt.clouddn.com/ollvm-string-h.png\" alt=\"头文件目录\"></p>\n<p>修改lib/Transform/Obfuscation目录下的CMakeLists.txt文件，将StringObfuscation.cpp添加到编译库中。然后修改Transform/IPO下的PassManagerBuilder.cpp文件，添加字符串加密的编译代码。具体代码如下:</p>\n<h5 id=\"1-添加引用\"><a href=\"#1-添加引用\" class=\"headerlink\" title=\"1.添加引用\"></a>1.添加引用</h5><p><code>#include &quot;llvm/Transforms/Obfuscation/StringObfuscation.h&quot;</code></p>\n<h5 id=\"2-插入函数声明，即编译时的编译参数-mllvm-sobf\"><a href=\"#2-插入函数声明，即编译时的编译参数-mllvm-sobf\" class=\"headerlink\" title=\"2.插入函数声明，即编译时的编译参数-mllvm -sobf\"></a>2.插入函数声明，即编译时的编译参数<code>-mllvm -sobf</code></h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div></pre></td><td class=\"code\"><pre><div class=\"line\">static cl::opt&lt;std::string&gt; Seed(&quot;seed&quot;, cl::init(&quot;&quot;),</div><div class=\"line\">                           cl::desc(&quot;seed for the random&quot;));</div><div class=\"line\"></div><div class=\"line\">static cl::opt&lt;bool&gt; StringObf(&quot;sobf&quot;, cl::init(false),</div><div class=\"line\">                           cl::desc(&quot;Enable the string obfuscation&quot;));</div></pre></td></tr></table></figure>\n<h5 id=\"3-在PassManagerBuilder-构造函数中添加随机数因子的初始化\"><a href=\"#3-在PassManagerBuilder-构造函数中添加随机数因子的初始化\" class=\"headerlink\" title=\"3.在PassManagerBuilder()构造函数中添加随机数因子的初始化\"></a>3.在PassManagerBuilder()构造函数中添加随机数因子的初始化</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\">if(!Seed.empty()) &#123;</div><div class=\"line\">  llvm::cryptoutils-&gt;prng_seed(Seed.c_str());</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/ollvm-string-seed.png\" alt=\"插入随机因子初始化\"></p>\n<h5 id=\"4-添加pss到-PassManagerBuilder-populateModulePassManager中\"><a href=\"#4-添加pss到-PassManagerBuilder-populateModulePassManager中\" class=\"headerlink\" title=\"4.添加pss到 PassManagerBuilder::populateModulePassManager中\"></a>4.添加pss到 PassManagerBuilder::populateModulePassManager中</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">MPM.add(createStringObfuscation(StringObf));</div></pre></td></tr></table></figure>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/ollvm-string-use.png\" alt=\"添加Pass\"></p>\n<h5 id=\"5-在主路径下运行编译命令\"><a href=\"#5-在主路径下运行编译命令\" class=\"headerlink\" title=\"5.在主路径下运行编译命令\"></a>5.在主路径下运行编译命令</h5><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">mkdir build</div><div class=\"line\">cd build</div><div class=\"line\">cmake -DCMAKE_BUILD_TYPE=Release ../obfuscator/   // 代码所在路径</div><div class=\"line\">make -j7</div></pre></td></tr></table></figure>\n<p>即可生成build最终文件，用于项目编译。我在github上也新建了一个添加了字符串混淆功能的<a href=\"https://github.com/fighting300/obfuscator\" target=\"_blank\" rel=\"external\">ollvm版本</a>，想要直接使用的小伙伴可以下载使用。</p>\n<h5 id=\"6-使用效果\"><a href=\"#6-使用效果\" class=\"headerlink\" title=\"6.使用效果\"></a>6.使用效果</h5><p>在OC代码中添加了简单的字符串、混淆后的效果如下图：  </p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/ollvm-string-before.png\" alt=\"字符串混淆前\"></p>\n<p><img src=\"http://ojca2gwha.bkt.clouddn.com/ollvm-string-after.png\" alt=\"字符串混淆后\"></p>\n<h4 id=\"问题及解决方案\"><a href=\"#问题及解决方案\" class=\"headerlink\" title=\"问题及解决方案\"></a>问题及解决方案</h4><p>编译成功后，则可按照<a href=\"http://fighting300.github.io/2017/09/07/ollvm-in-iOS/\" target=\"_blank\" rel=\"external\">上篇文章</a>所述，在XCode中编译项目。   </p>\n<h5 id=\"1-bcf不支持Invoke指令\"><a href=\"#1-bcf不支持Invoke指令\" class=\"headerlink\" title=\"1. bcf不支持Invoke指令\"></a>1. bcf不支持Invoke指令</h5><p>在实际使用过程中，发现ollvm目前不支持@synchronized、try…catch等少数语法，然后导致bcf报错。<a href=\"https://llvm.org/docs/LangRef.html#invoke-instruction\" target=\"_blank\" rel=\"external\">这些语法</a>会生成invoke指令，目前可以在bcf前过滤包含InvokeInst的方法，具体代码可以参考<a href=\"https://github.com/fighting300/obfuscator/commit/ae0e5acd873cd9a8c839a013a635422022fd0d6b\" target=\"_blank\" rel=\"external\">该Github地址</a>。</p>\n<h5 id=\"2-目前该字符串识别还有bug，即不会加密每个函数的第一个字符串。。。该bug未经过验证。\"><a href=\"#2-目前该字符串识别还有bug，即不会加密每个函数的第一个字符串。。。该bug未经过验证。\" class=\"headerlink\" title=\"2.目前该字符串识别还有bug，即不会加密每个函数的第一个字符串。。。该bug未经过验证。\"></a>2.目前该字符串识别还有bug，即不会加密每个函数的第一个字符串。。。<a href=\"https://qtfreet.com/?p=313\" target=\"_blank\" rel=\"external\">该bug</a>未经过验证。</h5><p>若有其他问题，可以联系，或者comment(翻墙才能评论哈。。。)</p>\n<h5 id=\"参考文档\"><a href=\"#参考文档\" class=\"headerlink\" title=\"参考文档\"></a>参考文档</h5><ol>\n<li><a href=\"http://bobao.360.cn/learning/detail/4069.html\" target=\"_blank\" rel=\"external\">http://bobao.360.cn/learning/detail/4069.html</a></li>\n<li><a href=\"http://www.nagain.com/activity/article/14/\" target=\"_blank\" rel=\"external\">http://www.nagain.com/activity/article/14/</a></li>\n</ol>"}],"PostAsset":[],"PostCategory":[{"post_id":"cj81l545n0009wluvq2avjh7x","category_id":"cj81l545g0006wluvqm55tnr8","_id":"cj81l545v000hwluvbhl0wcue"},{"post_id":"cj81l54580002wluvhp43jb7w","category_id":"cj81l545g0006wluvqm55tnr8","_id":"cj81l545x000mwluvv258m0eg"},{"post_id":"cj81l545p000awluvjaz6jrva","category_id":"cj81l545g0006wluvqm55tnr8","_id":"cj81l545z000owluvlpt5mpe4"},{"post_id":"cj81l545c0004wluvlry474dl","category_id":"cj81l545g0006wluvqm55tnr8","_id":"cj81l5464000twluvm63l7w0w"},{"post_id":"cj81l545t000gwluvkqv3g5lu","category_id":"cj81l545g0006wluvqm55tnr8","_id":"cj81l5466000vwluvi3p2a8tt"},{"post_id":"cj81l545w000lwluv8j2q0kws","category_id":"cj81l545g0006wluvqm55tnr8","_id":"cj81l5468000ywluvziq7oiag"},{"post_id":"cj81l545k0008wluvkcf0ew2d","category_id":"cj81l545g0006wluvqm55tnr8","_id":"cj81l5468000zwluvkj44n9xm"},{"post_id":"cj81l545x000nwluv4tufpnmt","category_id":"cj81l545g0006wluvqm55tnr8","_id":"cj81l546a0012wluvbea3wbwm"},{"post_id":"cj81l545r000ewluvaqchwrc8","category_id":"cj81l545z000pwluvj8c7zemo","_id":"cj81l546a0014wluvb4u8e5rw"},{"post_id":"cj81l5461000swluvavmebn49","category_id":"cj81l5468000xwluvl48hhahh","_id":"cj81l546b0017wluv3tejmm4u"},{"post_id":"cj81l5465000uwluvduw0esdn","category_id":"cj81l5468000xwluvl48hhahh","_id":"cj81l546b001awluveqt8ttbo"}],"PostTag":[{"post_id":"cj81l545n0009wluvq2avjh7x","tag_id":"cj81l545j0007wluvtc3xsm5q","_id":"cj81l545r000dwluv2ne9vzjx"},{"post_id":"cj81l54580002wluvhp43jb7w","tag_id":"cj81l545j0007wluvtc3xsm5q","_id":"cj81l545t000fwluvwbjziukm"},{"post_id":"cj81l545c0004wluvlry474dl","tag_id":"cj81l545j0007wluvtc3xsm5q","_id":"cj81l545w000kwluvellg20jz"},{"post_id":"cj81l545k0008wluvkcf0ew2d","tag_id":"cj81l545j0007wluvtc3xsm5q","_id":"cj81l5461000rwluvjmkkqf2g"},{"post_id":"cj81l545p000awluvjaz6jrva","tag_id":"cj81l545z000qwluvqvlif3y3","_id":"cj81l546a0013wluvb8wy8vg9"},{"post_id":"cj81l545p000awluvjaz6jrva","tag_id":"cj81l5467000wwluv1u9lpsyp","_id":"cj81l546a0015wluv0vqde6xm"},{"post_id":"cj81l545r000ewluvaqchwrc8","tag_id":"cj81l54690010wluvdccfqt59","_id":"cj81l546b0018wluva0tfnw2v"},{"post_id":"cj81l545t000gwluvkqv3g5lu","tag_id":"cj81l545z000qwluvqvlif3y3","_id":"cj81l546c001cwluvr6wqiqxl"},{"post_id":"cj81l545t000gwluvkqv3g5lu","tag_id":"cj81l546b0019wluvf4luln58","_id":"cj81l546c001dwluvn29hm16d"},{"post_id":"cj81l545w000lwluv8j2q0kws","tag_id":"cj81l546b001bwluv156n0p03","_id":"cj81l546c001fwluvug2ymgcp"},{"post_id":"cj81l545x000nwluv4tufpnmt","tag_id":"cj81l546c001ewluvsw4861f3","_id":"cj81l546d001hwluv24wxxe6b"},{"post_id":"cj81l5461000swluvavmebn49","tag_id":"cj81l546b001bwluv156n0p03","_id":"cj81l546e001jwluv8oe2yzex"},{"post_id":"cj81l5465000uwluvduw0esdn","tag_id":"cj81l546b001bwluv156n0p03","_id":"cj81l546f001kwluvtrcnoala"}],"Tag":[{"name":"ARKit","_id":"cj81l545j0007wluvtc3xsm5q"},{"name":"iOS","_id":"cj81l545z000qwluvqvlif3y3"},{"name":"Core NFC","_id":"cj81l5467000wwluv1u9lpsyp"},{"name":"blog","_id":"cj81l54690010wluvdccfqt59"},{"name":"Bonjour","_id":"cj81l546b0019wluvf4luln58"},{"name":"安全","_id":"cj81l546b001bwluv156n0p03"},{"name":"iOS 11","_id":"cj81l546c001ewluvsw4861f3"}]}}